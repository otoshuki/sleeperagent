{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8361fdab-8f79-434a-bf49-f930c871e644",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33m[robosuite WARNING] \u001b[0mNo private macro file found! (macros.py:53)\n",
      "\u001b[1m\u001b[33m[robosuite WARNING] \u001b[0mIt is recommended to use a private macro file (macros.py:54)\n",
      "\u001b[1m\u001b[33m[robosuite WARNING] \u001b[0mTo setup, run: python /home/gp/anaconda3/envs/sleepnvs/lib/python3.10/site-packages/robosuite/scripts/setup_macros.py (macros.py:55)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import imageio\n",
    "import time\n",
    "import IPython.display as display\n",
    "from IPython.display import clear_output\n",
    "from PIL import Image\n",
    "from sheeprl.envs.robosuite_zero import RobosuiteEnvZero\n",
    "# from sheeprl.envs.robosuite_env import RobosuiteEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72bf47a4-529f-419d-a0bf-1247298c3250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============= Initialized Observation Utils with Obs Spec =============\n",
      "\n",
      "using obs modality: rgb with keys: ['robot0_eye_in_hand_image', 'agentview_image']\n",
      "using obs modality: low_dim with keys: ['robot0_joint_pos', 'robot0_eef_quat', 'robot0_gripper_qpos', 'object', 'robot0_eef_pos']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gp/.local/lib/python3.10/site-packages/torch/__init__.py:1117: FutureWarning: `torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead\n",
      "  return isinstance(obj, torch.Tensor)\n",
      "/home/gp/sleeperagent/ZeroNVS/zeronvs_diffusion/zero123/ldm/models/diffusion/ddpm.py:145: FutureWarning: `torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead\n",
      "  hasattr(obj, \"data\") and torch.is_tensor(obj.data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LatentDiffusion: Running in eps-prediction mode\n",
      "DiffusionWrapper has 859.53 M params.\n",
      "Keeping EMAs of 688.\n",
      "making attention of type 'vanilla' with 512 in_channels\n",
      "Working with z of shape (1, 4, 32, 32) = 4096 dimensions.\n",
      "making attention of type 'vanilla' with 512 in_channels\n"
     ]
    }
   ],
   "source": [
    "env = RobosuiteEnvZero(camera_height=128, camera_width=128, channels_first=False, observation_type='rgb_zero', ddim_steps=10, guidance_scale=5)\n",
    "# env = RobosuiteEnv(camera_height=128, camera_width=128, channels_first=False, observation_type='rgb_concat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa4b4f45-7279-4ac0-8d7d-0a5ba2989d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c63f757-386d-4821-8790-dc8c2e85323e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# env.default_camera_distance = 1.5\n",
    "# env.gen_azm = [-60]\n",
    "# env.gen_elv = 20\n",
    "# env.ddim_steps = 20\n",
    "# env.guidance_scale = 7.5\n",
    "env.diff_fps = 1/20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "95b556b7-0ee7-4120-97e1-39f53552d4ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FPS: 47.18037754412347\n"
     ]
    }
   ],
   "source": [
    "frames = []\n",
    "env.guidance_scale = 4.0\n",
    "start = time.time()\n",
    "obs = env.reset()\n",
    "print(f\"Initial Setup: {time.time() - start}\")\n",
    "start = time.time()\n",
    "for step in range(1000):\n",
    "    action = env.action_space.sample()\n",
    "    # action = np.array([0.6, 0.1, -0.5, 0, 0, 0, 0])\n",
    "    obs, reward, done, truncated, info = env.step(action)\n",
    "    frame = env.render()\n",
    "    if frame is not None:\n",
    "        img = Image.fromarray(frame)\n",
    "        display.display(img)\n",
    "        clear_output(wait=True)\n",
    "        frames.append(frame)\n",
    "    if done or truncated:\n",
    "        obs = env.reset()\n",
    "    # time.sleep(1/20)\n",
    "\n",
    "print(f\"FPS: {1000/(time.time() - start)}\")\n",
    "env.close()\n",
    "\n",
    "video_path = \"wrist_zero3.mp4\"\n",
    "imageio.mimsave(video_path, frames, fps=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f450ed8f-713d-48da-9b6d-7f92c7cc3df2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DiffusionWrapper(\n",
       "  (diffusion_model): UNetModel(\n",
       "    (time_embed): Sequential(\n",
       "      (0): Linear(in_features=320, out_features=1280, bias=True)\n",
       "      (1): SiLU()\n",
       "      (2): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "    )\n",
       "    (input_blocks): ModuleList(\n",
       "      (0): TimestepEmbedSequential(\n",
       "        (0): Conv2d(8, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (1-2): 2 x TimestepEmbedSequential(\n",
       "        (0): ResBlock(\n",
       "          (in_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (h_upd): Identity()\n",
       "          (x_upd): Identity()\n",
       "          (emb_layers): Sequential(\n",
       "            (0): SiLU()\n",
       "            (1): Linear(in_features=1280, out_features=320, bias=True)\n",
       "          )\n",
       "          (out_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Dropout(p=0, inplace=False)\n",
       "            (3): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (skip_connection): Identity()\n",
       "        )\n",
       "        (1): SpatialTransformer(\n",
       "          (norm): GroupNorm(32, 320, eps=1e-06, affine=True)\n",
       "          (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (attn1): CrossAttention(\n",
       "                (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_k): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_v): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (ff): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=320, out_features=2560, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (attn2): CrossAttention(\n",
       "                (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_k): Linear(in_features=768, out_features=320, bias=False)\n",
       "                (to_v): Linear(in_features=768, out_features=320, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (3): TimestepEmbedSequential(\n",
       "        (0): Downsample(\n",
       "          (op): Conv2d(320, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (4): TimestepEmbedSequential(\n",
       "        (0): ResBlock(\n",
       "          (in_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Conv2d(320, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (h_upd): Identity()\n",
       "          (x_upd): Identity()\n",
       "          (emb_layers): Sequential(\n",
       "            (0): SiLU()\n",
       "            (1): Linear(in_features=1280, out_features=640, bias=True)\n",
       "          )\n",
       "          (out_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Dropout(p=0, inplace=False)\n",
       "            (3): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (skip_connection): Conv2d(320, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (1): SpatialTransformer(\n",
       "          (norm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
       "          (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (attn1): CrossAttention(\n",
       "                (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (ff): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=2560, out_features=640, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (attn2): CrossAttention(\n",
       "                (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_k): Linear(in_features=768, out_features=640, bias=False)\n",
       "                (to_v): Linear(in_features=768, out_features=640, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (5): TimestepEmbedSequential(\n",
       "        (0): ResBlock(\n",
       "          (in_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (h_upd): Identity()\n",
       "          (x_upd): Identity()\n",
       "          (emb_layers): Sequential(\n",
       "            (0): SiLU()\n",
       "            (1): Linear(in_features=1280, out_features=640, bias=True)\n",
       "          )\n",
       "          (out_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Dropout(p=0, inplace=False)\n",
       "            (3): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (skip_connection): Identity()\n",
       "        )\n",
       "        (1): SpatialTransformer(\n",
       "          (norm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
       "          (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (attn1): CrossAttention(\n",
       "                (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (ff): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=2560, out_features=640, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (attn2): CrossAttention(\n",
       "                (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_k): Linear(in_features=768, out_features=640, bias=False)\n",
       "                (to_v): Linear(in_features=768, out_features=640, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (6): TimestepEmbedSequential(\n",
       "        (0): Downsample(\n",
       "          (op): Conv2d(640, 640, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (7): TimestepEmbedSequential(\n",
       "        (0): ResBlock(\n",
       "          (in_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Conv2d(640, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (h_upd): Identity()\n",
       "          (x_upd): Identity()\n",
       "          (emb_layers): Sequential(\n",
       "            (0): SiLU()\n",
       "            (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (out_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Dropout(p=0, inplace=False)\n",
       "            (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (skip_connection): Conv2d(640, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (1): SpatialTransformer(\n",
       "          (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
       "          (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (attn1): CrossAttention(\n",
       "                (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (ff): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (attn2): CrossAttention(\n",
       "                (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_k): Linear(in_features=768, out_features=1280, bias=False)\n",
       "                (to_v): Linear(in_features=768, out_features=1280, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (8): TimestepEmbedSequential(\n",
       "        (0): ResBlock(\n",
       "          (in_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (h_upd): Identity()\n",
       "          (x_upd): Identity()\n",
       "          (emb_layers): Sequential(\n",
       "            (0): SiLU()\n",
       "            (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (out_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Dropout(p=0, inplace=False)\n",
       "            (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (skip_connection): Identity()\n",
       "        )\n",
       "        (1): SpatialTransformer(\n",
       "          (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
       "          (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (attn1): CrossAttention(\n",
       "                (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (ff): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (attn2): CrossAttention(\n",
       "                (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_k): Linear(in_features=768, out_features=1280, bias=False)\n",
       "                (to_v): Linear(in_features=768, out_features=1280, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (9): TimestepEmbedSequential(\n",
       "        (0): Downsample(\n",
       "          (op): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (10-11): 2 x TimestepEmbedSequential(\n",
       "        (0): ResBlock(\n",
       "          (in_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (h_upd): Identity()\n",
       "          (x_upd): Identity()\n",
       "          (emb_layers): Sequential(\n",
       "            (0): SiLU()\n",
       "            (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (out_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Dropout(p=0, inplace=False)\n",
       "            (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (skip_connection): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (middle_block): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0, inplace=False)\n",
       "          (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Identity()\n",
       "      )\n",
       "      (1): SpatialTransformer(\n",
       "        (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
       "        (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (transformer_blocks): ModuleList(\n",
       "          (0): BasicTransformerBlock(\n",
       "            (attn1): CrossAttention(\n",
       "              (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "              (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "              (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (ff): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): GEGLU(\n",
       "                  (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
       "                )\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "                (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (attn2): CrossAttention(\n",
       "              (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "              (to_k): Linear(in_features=768, out_features=1280, bias=False)\n",
       "              (to_v): Linear(in_features=768, out_features=1280, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (2): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0, inplace=False)\n",
       "          (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Identity()\n",
       "      )\n",
       "    )\n",
       "    (output_blocks): ModuleList(\n",
       "      (0-1): 2 x TimestepEmbedSequential(\n",
       "        (0): ResBlock(\n",
       "          (in_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 2560, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (h_upd): Identity()\n",
       "          (x_upd): Identity()\n",
       "          (emb_layers): Sequential(\n",
       "            (0): SiLU()\n",
       "            (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (out_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Dropout(p=0, inplace=False)\n",
       "            (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (skip_connection): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (2): TimestepEmbedSequential(\n",
       "        (0): ResBlock(\n",
       "          (in_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 2560, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (h_upd): Identity()\n",
       "          (x_upd): Identity()\n",
       "          (emb_layers): Sequential(\n",
       "            (0): SiLU()\n",
       "            (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (out_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Dropout(p=0, inplace=False)\n",
       "            (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (skip_connection): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (1): Upsample(\n",
       "          (conv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (3-4): 2 x TimestepEmbedSequential(\n",
       "        (0): ResBlock(\n",
       "          (in_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 2560, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (h_upd): Identity()\n",
       "          (x_upd): Identity()\n",
       "          (emb_layers): Sequential(\n",
       "            (0): SiLU()\n",
       "            (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (out_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Dropout(p=0, inplace=False)\n",
       "            (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (skip_connection): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (1): SpatialTransformer(\n",
       "          (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
       "          (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (attn1): CrossAttention(\n",
       "                (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (ff): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (attn2): CrossAttention(\n",
       "                (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_k): Linear(in_features=768, out_features=1280, bias=False)\n",
       "                (to_v): Linear(in_features=768, out_features=1280, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (5): TimestepEmbedSequential(\n",
       "        (0): ResBlock(\n",
       "          (in_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 1920, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Conv2d(1920, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (h_upd): Identity()\n",
       "          (x_upd): Identity()\n",
       "          (emb_layers): Sequential(\n",
       "            (0): SiLU()\n",
       "            (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (out_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Dropout(p=0, inplace=False)\n",
       "            (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (skip_connection): Conv2d(1920, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (1): SpatialTransformer(\n",
       "          (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
       "          (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (attn1): CrossAttention(\n",
       "                (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (ff): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (attn2): CrossAttention(\n",
       "                (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_k): Linear(in_features=768, out_features=1280, bias=False)\n",
       "                (to_v): Linear(in_features=768, out_features=1280, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (2): Upsample(\n",
       "          (conv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (6): TimestepEmbedSequential(\n",
       "        (0): ResBlock(\n",
       "          (in_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 1920, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Conv2d(1920, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (h_upd): Identity()\n",
       "          (x_upd): Identity()\n",
       "          (emb_layers): Sequential(\n",
       "            (0): SiLU()\n",
       "            (1): Linear(in_features=1280, out_features=640, bias=True)\n",
       "          )\n",
       "          (out_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Dropout(p=0, inplace=False)\n",
       "            (3): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (skip_connection): Conv2d(1920, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (1): SpatialTransformer(\n",
       "          (norm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
       "          (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (attn1): CrossAttention(\n",
       "                (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (ff): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=2560, out_features=640, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (attn2): CrossAttention(\n",
       "                (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_k): Linear(in_features=768, out_features=640, bias=False)\n",
       "                (to_v): Linear(in_features=768, out_features=640, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (7): TimestepEmbedSequential(\n",
       "        (0): ResBlock(\n",
       "          (in_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Conv2d(1280, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (h_upd): Identity()\n",
       "          (x_upd): Identity()\n",
       "          (emb_layers): Sequential(\n",
       "            (0): SiLU()\n",
       "            (1): Linear(in_features=1280, out_features=640, bias=True)\n",
       "          )\n",
       "          (out_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Dropout(p=0, inplace=False)\n",
       "            (3): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (skip_connection): Conv2d(1280, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (1): SpatialTransformer(\n",
       "          (norm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
       "          (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (attn1): CrossAttention(\n",
       "                (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (ff): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=2560, out_features=640, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (attn2): CrossAttention(\n",
       "                (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_k): Linear(in_features=768, out_features=640, bias=False)\n",
       "                (to_v): Linear(in_features=768, out_features=640, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (8): TimestepEmbedSequential(\n",
       "        (0): ResBlock(\n",
       "          (in_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 960, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Conv2d(960, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (h_upd): Identity()\n",
       "          (x_upd): Identity()\n",
       "          (emb_layers): Sequential(\n",
       "            (0): SiLU()\n",
       "            (1): Linear(in_features=1280, out_features=640, bias=True)\n",
       "          )\n",
       "          (out_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Dropout(p=0, inplace=False)\n",
       "            (3): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (skip_connection): Conv2d(960, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (1): SpatialTransformer(\n",
       "          (norm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
       "          (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (attn1): CrossAttention(\n",
       "                (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (ff): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=2560, out_features=640, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (attn2): CrossAttention(\n",
       "                (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_k): Linear(in_features=768, out_features=640, bias=False)\n",
       "                (to_v): Linear(in_features=768, out_features=640, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (2): Upsample(\n",
       "          (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (9): TimestepEmbedSequential(\n",
       "        (0): ResBlock(\n",
       "          (in_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 960, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Conv2d(960, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (h_upd): Identity()\n",
       "          (x_upd): Identity()\n",
       "          (emb_layers): Sequential(\n",
       "            (0): SiLU()\n",
       "            (1): Linear(in_features=1280, out_features=320, bias=True)\n",
       "          )\n",
       "          (out_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Dropout(p=0, inplace=False)\n",
       "            (3): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (skip_connection): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (1): SpatialTransformer(\n",
       "          (norm): GroupNorm(32, 320, eps=1e-06, affine=True)\n",
       "          (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (attn1): CrossAttention(\n",
       "                (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_k): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_v): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (ff): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=320, out_features=2560, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (attn2): CrossAttention(\n",
       "                (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_k): Linear(in_features=768, out_features=320, bias=False)\n",
       "                (to_v): Linear(in_features=768, out_features=320, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (10-11): 2 x TimestepEmbedSequential(\n",
       "        (0): ResBlock(\n",
       "          (in_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Conv2d(640, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (h_upd): Identity()\n",
       "          (x_upd): Identity()\n",
       "          (emb_layers): Sequential(\n",
       "            (0): SiLU()\n",
       "            (1): Linear(in_features=1280, out_features=320, bias=True)\n",
       "          )\n",
       "          (out_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Dropout(p=0, inplace=False)\n",
       "            (3): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (skip_connection): Conv2d(640, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (1): SpatialTransformer(\n",
       "          (norm): GroupNorm(32, 320, eps=1e-06, affine=True)\n",
       "          (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (attn1): CrossAttention(\n",
       "                (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_k): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_v): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (ff): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=320, out_features=2560, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (attn2): CrossAttention(\n",
       "                (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_k): Linear(in_features=768, out_features=320, bias=False)\n",
       "                (to_v): Linear(in_features=768, out_features=320, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (out): Sequential(\n",
       "      (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
       "      (1): SiLU()\n",
       "      (2): Conv2d(320, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.generator.model.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "562cf75e-273e-49cd-ab11-8625f524c997",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Module: UNetModel(\n",
      "  (time_embed): Sequential(\n",
      "    (0): Linear(in_features=320, out_features=1280, bias=True)\n",
      "    (1): SiLU()\n",
      "    (2): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "  )\n",
      "  (input_blocks): ModuleList(\n",
      "    (0): TimestepEmbedSequential(\n",
      "      (0): Conv2d(8, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (1-2): 2 x TimestepEmbedSequential(\n",
      "      (0): ResBlock(\n",
      "        (in_layers): Sequential(\n",
      "          (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
      "          (1): SiLU()\n",
      "          (2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (h_upd): Identity()\n",
      "        (x_upd): Identity()\n",
      "        (emb_layers): Sequential(\n",
      "          (0): SiLU()\n",
      "          (1): Linear(in_features=1280, out_features=320, bias=True)\n",
      "        )\n",
      "        (out_layers): Sequential(\n",
      "          (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
      "          (1): SiLU()\n",
      "          (2): Dropout(p=0, inplace=False)\n",
      "          (3): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (skip_connection): Identity()\n",
      "      )\n",
      "      (1): SpatialTransformer(\n",
      "        (norm): GroupNorm(32, 320, eps=1e-06, affine=True)\n",
      "        (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (transformer_blocks): ModuleList(\n",
      "          (0): BasicTransformerBlock(\n",
      "            (attn1): CrossAttention(\n",
      "              (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
      "              (to_k): Linear(in_features=320, out_features=320, bias=False)\n",
      "              (to_v): Linear(in_features=320, out_features=320, bias=False)\n",
      "              (to_out): Sequential(\n",
      "                (0): Linear(in_features=320, out_features=320, bias=True)\n",
      "                (1): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (ff): FeedForward(\n",
      "              (net): Sequential(\n",
      "                (0): GEGLU(\n",
      "                  (proj): Linear(in_features=320, out_features=2560, bias=True)\n",
      "                )\n",
      "                (1): Dropout(p=0.0, inplace=False)\n",
      "                (2): Linear(in_features=1280, out_features=320, bias=True)\n",
      "              )\n",
      "            )\n",
      "            (attn2): CrossAttention(\n",
      "              (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
      "              (to_k): Linear(in_features=768, out_features=320, bias=False)\n",
      "              (to_v): Linear(in_features=768, out_features=320, bias=False)\n",
      "              (to_out): Sequential(\n",
      "                (0): Linear(in_features=320, out_features=320, bias=True)\n",
      "                (1): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "            (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "            (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "        (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (3): TimestepEmbedSequential(\n",
      "      (0): Downsample(\n",
      "        (op): Conv2d(320, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (4): TimestepEmbedSequential(\n",
      "      (0): ResBlock(\n",
      "        (in_layers): Sequential(\n",
      "          (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
      "          (1): SiLU()\n",
      "          (2): Conv2d(320, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (h_upd): Identity()\n",
      "        (x_upd): Identity()\n",
      "        (emb_layers): Sequential(\n",
      "          (0): SiLU()\n",
      "          (1): Linear(in_features=1280, out_features=640, bias=True)\n",
      "        )\n",
      "        (out_layers): Sequential(\n",
      "          (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
      "          (1): SiLU()\n",
      "          (2): Dropout(p=0, inplace=False)\n",
      "          (3): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (skip_connection): Conv2d(320, 640, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (1): SpatialTransformer(\n",
      "        (norm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
      "        (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (transformer_blocks): ModuleList(\n",
      "          (0): BasicTransformerBlock(\n",
      "            (attn1): CrossAttention(\n",
      "              (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
      "              (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
      "              (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
      "              (to_out): Sequential(\n",
      "                (0): Linear(in_features=640, out_features=640, bias=True)\n",
      "                (1): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (ff): FeedForward(\n",
      "              (net): Sequential(\n",
      "                (0): GEGLU(\n",
      "                  (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
      "                )\n",
      "                (1): Dropout(p=0.0, inplace=False)\n",
      "                (2): Linear(in_features=2560, out_features=640, bias=True)\n",
      "              )\n",
      "            )\n",
      "            (attn2): CrossAttention(\n",
      "              (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
      "              (to_k): Linear(in_features=768, out_features=640, bias=False)\n",
      "              (to_v): Linear(in_features=768, out_features=640, bias=False)\n",
      "              (to_out): Sequential(\n",
      "                (0): Linear(in_features=640, out_features=640, bias=True)\n",
      "                (1): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
      "            (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
      "            (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "        (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (5): TimestepEmbedSequential(\n",
      "      (0): ResBlock(\n",
      "        (in_layers): Sequential(\n",
      "          (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
      "          (1): SiLU()\n",
      "          (2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (h_upd): Identity()\n",
      "        (x_upd): Identity()\n",
      "        (emb_layers): Sequential(\n",
      "          (0): SiLU()\n",
      "          (1): Linear(in_features=1280, out_features=640, bias=True)\n",
      "        )\n",
      "        (out_layers): Sequential(\n",
      "          (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
      "          (1): SiLU()\n",
      "          (2): Dropout(p=0, inplace=False)\n",
      "          (3): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (skip_connection): Identity()\n",
      "      )\n",
      "      (1): SpatialTransformer(\n",
      "        (norm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
      "        (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (transformer_blocks): ModuleList(\n",
      "          (0): BasicTransformerBlock(\n",
      "            (attn1): CrossAttention(\n",
      "              (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
      "              (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
      "              (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
      "              (to_out): Sequential(\n",
      "                (0): Linear(in_features=640, out_features=640, bias=True)\n",
      "                (1): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (ff): FeedForward(\n",
      "              (net): Sequential(\n",
      "                (0): GEGLU(\n",
      "                  (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
      "                )\n",
      "                (1): Dropout(p=0.0, inplace=False)\n",
      "                (2): Linear(in_features=2560, out_features=640, bias=True)\n",
      "              )\n",
      "            )\n",
      "            (attn2): CrossAttention(\n",
      "              (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
      "              (to_k): Linear(in_features=768, out_features=640, bias=False)\n",
      "              (to_v): Linear(in_features=768, out_features=640, bias=False)\n",
      "              (to_out): Sequential(\n",
      "                (0): Linear(in_features=640, out_features=640, bias=True)\n",
      "                (1): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
      "            (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
      "            (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "        (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (6): TimestepEmbedSequential(\n",
      "      (0): Downsample(\n",
      "        (op): Conv2d(640, 640, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (7): TimestepEmbedSequential(\n",
      "      (0): ResBlock(\n",
      "        (in_layers): Sequential(\n",
      "          (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
      "          (1): SiLU()\n",
      "          (2): Conv2d(640, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (h_upd): Identity()\n",
      "        (x_upd): Identity()\n",
      "        (emb_layers): Sequential(\n",
      "          (0): SiLU()\n",
      "          (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "        )\n",
      "        (out_layers): Sequential(\n",
      "          (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
      "          (1): SiLU()\n",
      "          (2): Dropout(p=0, inplace=False)\n",
      "          (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (skip_connection): Conv2d(640, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (1): SpatialTransformer(\n",
      "        (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
      "        (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (transformer_blocks): ModuleList(\n",
      "          (0): BasicTransformerBlock(\n",
      "            (attn1): CrossAttention(\n",
      "              (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "              (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "              (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "              (to_out): Sequential(\n",
      "                (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "                (1): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (ff): FeedForward(\n",
      "              (net): Sequential(\n",
      "                (0): GEGLU(\n",
      "                  (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
      "                )\n",
      "                (1): Dropout(p=0.0, inplace=False)\n",
      "                (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
      "              )\n",
      "            )\n",
      "            (attn2): CrossAttention(\n",
      "              (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "              (to_k): Linear(in_features=768, out_features=1280, bias=False)\n",
      "              (to_v): Linear(in_features=768, out_features=1280, bias=False)\n",
      "              (to_out): Sequential(\n",
      "                (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "                (1): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "            (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "            (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "        (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (8): TimestepEmbedSequential(\n",
      "      (0): ResBlock(\n",
      "        (in_layers): Sequential(\n",
      "          (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
      "          (1): SiLU()\n",
      "          (2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (h_upd): Identity()\n",
      "        (x_upd): Identity()\n",
      "        (emb_layers): Sequential(\n",
      "          (0): SiLU()\n",
      "          (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "        )\n",
      "        (out_layers): Sequential(\n",
      "          (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
      "          (1): SiLU()\n",
      "          (2): Dropout(p=0, inplace=False)\n",
      "          (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (skip_connection): Identity()\n",
      "      )\n",
      "      (1): SpatialTransformer(\n",
      "        (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
      "        (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (transformer_blocks): ModuleList(\n",
      "          (0): BasicTransformerBlock(\n",
      "            (attn1): CrossAttention(\n",
      "              (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "              (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "              (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "              (to_out): Sequential(\n",
      "                (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "                (1): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (ff): FeedForward(\n",
      "              (net): Sequential(\n",
      "                (0): GEGLU(\n",
      "                  (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
      "                )\n",
      "                (1): Dropout(p=0.0, inplace=False)\n",
      "                (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
      "              )\n",
      "            )\n",
      "            (attn2): CrossAttention(\n",
      "              (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "              (to_k): Linear(in_features=768, out_features=1280, bias=False)\n",
      "              (to_v): Linear(in_features=768, out_features=1280, bias=False)\n",
      "              (to_out): Sequential(\n",
      "                (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "                (1): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "            (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "            (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "        (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (9): TimestepEmbedSequential(\n",
      "      (0): Downsample(\n",
      "        (op): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (10-11): 2 x TimestepEmbedSequential(\n",
      "      (0): ResBlock(\n",
      "        (in_layers): Sequential(\n",
      "          (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
      "          (1): SiLU()\n",
      "          (2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (h_upd): Identity()\n",
      "        (x_upd): Identity()\n",
      "        (emb_layers): Sequential(\n",
      "          (0): SiLU()\n",
      "          (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "        )\n",
      "        (out_layers): Sequential(\n",
      "          (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
      "          (1): SiLU()\n",
      "          (2): Dropout(p=0, inplace=False)\n",
      "          (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (skip_connection): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (middle_block): TimestepEmbedSequential(\n",
      "    (0): ResBlock(\n",
      "      (in_layers): Sequential(\n",
      "        (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
      "        (1): SiLU()\n",
      "        (2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (h_upd): Identity()\n",
      "      (x_upd): Identity()\n",
      "      (emb_layers): Sequential(\n",
      "        (0): SiLU()\n",
      "        (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "      )\n",
      "      (out_layers): Sequential(\n",
      "        (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
      "        (1): SiLU()\n",
      "        (2): Dropout(p=0, inplace=False)\n",
      "        (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (skip_connection): Identity()\n",
      "    )\n",
      "    (1): SpatialTransformer(\n",
      "      (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
      "      (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (transformer_blocks): ModuleList(\n",
      "        (0): BasicTransformerBlock(\n",
      "          (attn1): CrossAttention(\n",
      "            (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "            (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "            (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "            (to_out): Sequential(\n",
      "              (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "              (1): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (ff): FeedForward(\n",
      "            (net): Sequential(\n",
      "              (0): GEGLU(\n",
      "                (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
      "              )\n",
      "              (1): Dropout(p=0.0, inplace=False)\n",
      "              (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (attn2): CrossAttention(\n",
      "            (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "            (to_k): Linear(in_features=768, out_features=1280, bias=False)\n",
      "            (to_v): Linear(in_features=768, out_features=1280, bias=False)\n",
      "            (to_out): Sequential(\n",
      "              (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "              (1): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "      (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (2): ResBlock(\n",
      "      (in_layers): Sequential(\n",
      "        (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
      "        (1): SiLU()\n",
      "        (2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (h_upd): Identity()\n",
      "      (x_upd): Identity()\n",
      "      (emb_layers): Sequential(\n",
      "        (0): SiLU()\n",
      "        (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "      )\n",
      "      (out_layers): Sequential(\n",
      "        (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
      "        (1): SiLU()\n",
      "        (2): Dropout(p=0, inplace=False)\n",
      "        (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (skip_connection): Identity()\n",
      "    )\n",
      "  )\n",
      "  (output_blocks): ModuleList(\n",
      "    (0-1): 2 x TimestepEmbedSequential(\n",
      "      (0): ResBlock(\n",
      "        (in_layers): Sequential(\n",
      "          (0): GroupNorm32(32, 2560, eps=1e-05, affine=True)\n",
      "          (1): SiLU()\n",
      "          (2): Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (h_upd): Identity()\n",
      "        (x_upd): Identity()\n",
      "        (emb_layers): Sequential(\n",
      "          (0): SiLU()\n",
      "          (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "        )\n",
      "        (out_layers): Sequential(\n",
      "          (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
      "          (1): SiLU()\n",
      "          (2): Dropout(p=0, inplace=False)\n",
      "          (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (skip_connection): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (2): TimestepEmbedSequential(\n",
      "      (0): ResBlock(\n",
      "        (in_layers): Sequential(\n",
      "          (0): GroupNorm32(32, 2560, eps=1e-05, affine=True)\n",
      "          (1): SiLU()\n",
      "          (2): Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (h_upd): Identity()\n",
      "        (x_upd): Identity()\n",
      "        (emb_layers): Sequential(\n",
      "          (0): SiLU()\n",
      "          (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "        )\n",
      "        (out_layers): Sequential(\n",
      "          (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
      "          (1): SiLU()\n",
      "          (2): Dropout(p=0, inplace=False)\n",
      "          (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (skip_connection): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (1): Upsample(\n",
      "        (conv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (3-4): 2 x TimestepEmbedSequential(\n",
      "      (0): ResBlock(\n",
      "        (in_layers): Sequential(\n",
      "          (0): GroupNorm32(32, 2560, eps=1e-05, affine=True)\n",
      "          (1): SiLU()\n",
      "          (2): Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (h_upd): Identity()\n",
      "        (x_upd): Identity()\n",
      "        (emb_layers): Sequential(\n",
      "          (0): SiLU()\n",
      "          (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "        )\n",
      "        (out_layers): Sequential(\n",
      "          (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
      "          (1): SiLU()\n",
      "          (2): Dropout(p=0, inplace=False)\n",
      "          (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (skip_connection): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (1): SpatialTransformer(\n",
      "        (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
      "        (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (transformer_blocks): ModuleList(\n",
      "          (0): BasicTransformerBlock(\n",
      "            (attn1): CrossAttention(\n",
      "              (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "              (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "              (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "              (to_out): Sequential(\n",
      "                (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "                (1): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (ff): FeedForward(\n",
      "              (net): Sequential(\n",
      "                (0): GEGLU(\n",
      "                  (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
      "                )\n",
      "                (1): Dropout(p=0.0, inplace=False)\n",
      "                (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
      "              )\n",
      "            )\n",
      "            (attn2): CrossAttention(\n",
      "              (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "              (to_k): Linear(in_features=768, out_features=1280, bias=False)\n",
      "              (to_v): Linear(in_features=768, out_features=1280, bias=False)\n",
      "              (to_out): Sequential(\n",
      "                (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "                (1): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "            (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "            (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "        (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (5): TimestepEmbedSequential(\n",
      "      (0): ResBlock(\n",
      "        (in_layers): Sequential(\n",
      "          (0): GroupNorm32(32, 1920, eps=1e-05, affine=True)\n",
      "          (1): SiLU()\n",
      "          (2): Conv2d(1920, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (h_upd): Identity()\n",
      "        (x_upd): Identity()\n",
      "        (emb_layers): Sequential(\n",
      "          (0): SiLU()\n",
      "          (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "        )\n",
      "        (out_layers): Sequential(\n",
      "          (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
      "          (1): SiLU()\n",
      "          (2): Dropout(p=0, inplace=False)\n",
      "          (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (skip_connection): Conv2d(1920, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (1): SpatialTransformer(\n",
      "        (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
      "        (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (transformer_blocks): ModuleList(\n",
      "          (0): BasicTransformerBlock(\n",
      "            (attn1): CrossAttention(\n",
      "              (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "              (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "              (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "              (to_out): Sequential(\n",
      "                (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "                (1): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (ff): FeedForward(\n",
      "              (net): Sequential(\n",
      "                (0): GEGLU(\n",
      "                  (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
      "                )\n",
      "                (1): Dropout(p=0.0, inplace=False)\n",
      "                (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
      "              )\n",
      "            )\n",
      "            (attn2): CrossAttention(\n",
      "              (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "              (to_k): Linear(in_features=768, out_features=1280, bias=False)\n",
      "              (to_v): Linear(in_features=768, out_features=1280, bias=False)\n",
      "              (to_out): Sequential(\n",
      "                (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "                (1): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "            (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "            (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "        (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (2): Upsample(\n",
      "        (conv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (6): TimestepEmbedSequential(\n",
      "      (0): ResBlock(\n",
      "        (in_layers): Sequential(\n",
      "          (0): GroupNorm32(32, 1920, eps=1e-05, affine=True)\n",
      "          (1): SiLU()\n",
      "          (2): Conv2d(1920, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (h_upd): Identity()\n",
      "        (x_upd): Identity()\n",
      "        (emb_layers): Sequential(\n",
      "          (0): SiLU()\n",
      "          (1): Linear(in_features=1280, out_features=640, bias=True)\n",
      "        )\n",
      "        (out_layers): Sequential(\n",
      "          (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
      "          (1): SiLU()\n",
      "          (2): Dropout(p=0, inplace=False)\n",
      "          (3): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (skip_connection): Conv2d(1920, 640, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (1): SpatialTransformer(\n",
      "        (norm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
      "        (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (transformer_blocks): ModuleList(\n",
      "          (0): BasicTransformerBlock(\n",
      "            (attn1): CrossAttention(\n",
      "              (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
      "              (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
      "              (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
      "              (to_out): Sequential(\n",
      "                (0): Linear(in_features=640, out_features=640, bias=True)\n",
      "                (1): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (ff): FeedForward(\n",
      "              (net): Sequential(\n",
      "                (0): GEGLU(\n",
      "                  (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
      "                )\n",
      "                (1): Dropout(p=0.0, inplace=False)\n",
      "                (2): Linear(in_features=2560, out_features=640, bias=True)\n",
      "              )\n",
      "            )\n",
      "            (attn2): CrossAttention(\n",
      "              (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
      "              (to_k): Linear(in_features=768, out_features=640, bias=False)\n",
      "              (to_v): Linear(in_features=768, out_features=640, bias=False)\n",
      "              (to_out): Sequential(\n",
      "                (0): Linear(in_features=640, out_features=640, bias=True)\n",
      "                (1): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
      "            (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
      "            (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "        (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (7): TimestepEmbedSequential(\n",
      "      (0): ResBlock(\n",
      "        (in_layers): Sequential(\n",
      "          (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
      "          (1): SiLU()\n",
      "          (2): Conv2d(1280, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (h_upd): Identity()\n",
      "        (x_upd): Identity()\n",
      "        (emb_layers): Sequential(\n",
      "          (0): SiLU()\n",
      "          (1): Linear(in_features=1280, out_features=640, bias=True)\n",
      "        )\n",
      "        (out_layers): Sequential(\n",
      "          (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
      "          (1): SiLU()\n",
      "          (2): Dropout(p=0, inplace=False)\n",
      "          (3): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (skip_connection): Conv2d(1280, 640, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (1): SpatialTransformer(\n",
      "        (norm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
      "        (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (transformer_blocks): ModuleList(\n",
      "          (0): BasicTransformerBlock(\n",
      "            (attn1): CrossAttention(\n",
      "              (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
      "              (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
      "              (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
      "              (to_out): Sequential(\n",
      "                (0): Linear(in_features=640, out_features=640, bias=True)\n",
      "                (1): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (ff): FeedForward(\n",
      "              (net): Sequential(\n",
      "                (0): GEGLU(\n",
      "                  (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
      "                )\n",
      "                (1): Dropout(p=0.0, inplace=False)\n",
      "                (2): Linear(in_features=2560, out_features=640, bias=True)\n",
      "              )\n",
      "            )\n",
      "            (attn2): CrossAttention(\n",
      "              (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
      "              (to_k): Linear(in_features=768, out_features=640, bias=False)\n",
      "              (to_v): Linear(in_features=768, out_features=640, bias=False)\n",
      "              (to_out): Sequential(\n",
      "                (0): Linear(in_features=640, out_features=640, bias=True)\n",
      "                (1): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
      "            (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
      "            (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "        (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (8): TimestepEmbedSequential(\n",
      "      (0): ResBlock(\n",
      "        (in_layers): Sequential(\n",
      "          (0): GroupNorm32(32, 960, eps=1e-05, affine=True)\n",
      "          (1): SiLU()\n",
      "          (2): Conv2d(960, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (h_upd): Identity()\n",
      "        (x_upd): Identity()\n",
      "        (emb_layers): Sequential(\n",
      "          (0): SiLU()\n",
      "          (1): Linear(in_features=1280, out_features=640, bias=True)\n",
      "        )\n",
      "        (out_layers): Sequential(\n",
      "          (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
      "          (1): SiLU()\n",
      "          (2): Dropout(p=0, inplace=False)\n",
      "          (3): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (skip_connection): Conv2d(960, 640, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (1): SpatialTransformer(\n",
      "        (norm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
      "        (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (transformer_blocks): ModuleList(\n",
      "          (0): BasicTransformerBlock(\n",
      "            (attn1): CrossAttention(\n",
      "              (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
      "              (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
      "              (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
      "              (to_out): Sequential(\n",
      "                (0): Linear(in_features=640, out_features=640, bias=True)\n",
      "                (1): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (ff): FeedForward(\n",
      "              (net): Sequential(\n",
      "                (0): GEGLU(\n",
      "                  (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
      "                )\n",
      "                (1): Dropout(p=0.0, inplace=False)\n",
      "                (2): Linear(in_features=2560, out_features=640, bias=True)\n",
      "              )\n",
      "            )\n",
      "            (attn2): CrossAttention(\n",
      "              (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
      "              (to_k): Linear(in_features=768, out_features=640, bias=False)\n",
      "              (to_v): Linear(in_features=768, out_features=640, bias=False)\n",
      "              (to_out): Sequential(\n",
      "                (0): Linear(in_features=640, out_features=640, bias=True)\n",
      "                (1): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
      "            (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
      "            (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "        (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (2): Upsample(\n",
      "        (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (9): TimestepEmbedSequential(\n",
      "      (0): ResBlock(\n",
      "        (in_layers): Sequential(\n",
      "          (0): GroupNorm32(32, 960, eps=1e-05, affine=True)\n",
      "          (1): SiLU()\n",
      "          (2): Conv2d(960, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (h_upd): Identity()\n",
      "        (x_upd): Identity()\n",
      "        (emb_layers): Sequential(\n",
      "          (0): SiLU()\n",
      "          (1): Linear(in_features=1280, out_features=320, bias=True)\n",
      "        )\n",
      "        (out_layers): Sequential(\n",
      "          (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
      "          (1): SiLU()\n",
      "          (2): Dropout(p=0, inplace=False)\n",
      "          (3): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (skip_connection): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (1): SpatialTransformer(\n",
      "        (norm): GroupNorm(32, 320, eps=1e-06, affine=True)\n",
      "        (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (transformer_blocks): ModuleList(\n",
      "          (0): BasicTransformerBlock(\n",
      "            (attn1): CrossAttention(\n",
      "              (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
      "              (to_k): Linear(in_features=320, out_features=320, bias=False)\n",
      "              (to_v): Linear(in_features=320, out_features=320, bias=False)\n",
      "              (to_out): Sequential(\n",
      "                (0): Linear(in_features=320, out_features=320, bias=True)\n",
      "                (1): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (ff): FeedForward(\n",
      "              (net): Sequential(\n",
      "                (0): GEGLU(\n",
      "                  (proj): Linear(in_features=320, out_features=2560, bias=True)\n",
      "                )\n",
      "                (1): Dropout(p=0.0, inplace=False)\n",
      "                (2): Linear(in_features=1280, out_features=320, bias=True)\n",
      "              )\n",
      "            )\n",
      "            (attn2): CrossAttention(\n",
      "              (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
      "              (to_k): Linear(in_features=768, out_features=320, bias=False)\n",
      "              (to_v): Linear(in_features=768, out_features=320, bias=False)\n",
      "              (to_out): Sequential(\n",
      "                (0): Linear(in_features=320, out_features=320, bias=True)\n",
      "                (1): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "            (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "            (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "        (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (10-11): 2 x TimestepEmbedSequential(\n",
      "      (0): ResBlock(\n",
      "        (in_layers): Sequential(\n",
      "          (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
      "          (1): SiLU()\n",
      "          (2): Conv2d(640, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (h_upd): Identity()\n",
      "        (x_upd): Identity()\n",
      "        (emb_layers): Sequential(\n",
      "          (0): SiLU()\n",
      "          (1): Linear(in_features=1280, out_features=320, bias=True)\n",
      "        )\n",
      "        (out_layers): Sequential(\n",
      "          (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
      "          (1): SiLU()\n",
      "          (2): Dropout(p=0, inplace=False)\n",
      "          (3): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (skip_connection): Conv2d(640, 320, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (1): SpatialTransformer(\n",
      "        (norm): GroupNorm(32, 320, eps=1e-06, affine=True)\n",
      "        (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (transformer_blocks): ModuleList(\n",
      "          (0): BasicTransformerBlock(\n",
      "            (attn1): CrossAttention(\n",
      "              (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
      "              (to_k): Linear(in_features=320, out_features=320, bias=False)\n",
      "              (to_v): Linear(in_features=320, out_features=320, bias=False)\n",
      "              (to_out): Sequential(\n",
      "                (0): Linear(in_features=320, out_features=320, bias=True)\n",
      "                (1): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (ff): FeedForward(\n",
      "              (net): Sequential(\n",
      "                (0): GEGLU(\n",
      "                  (proj): Linear(in_features=320, out_features=2560, bias=True)\n",
      "                )\n",
      "                (1): Dropout(p=0.0, inplace=False)\n",
      "                (2): Linear(in_features=1280, out_features=320, bias=True)\n",
      "              )\n",
      "            )\n",
      "            (attn2): CrossAttention(\n",
      "              (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
      "              (to_k): Linear(in_features=768, out_features=320, bias=False)\n",
      "              (to_v): Linear(in_features=768, out_features=320, bias=False)\n",
      "              (to_out): Sequential(\n",
      "                (0): Linear(in_features=320, out_features=320, bias=True)\n",
      "                (1): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "            (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "            (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "        (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (out): Sequential(\n",
      "    (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
      "    (1): SiLU()\n",
      "    (2): Conv2d(320, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      ")\n",
      "Module: Sequential(\n",
      "  (0): Linear(in_features=320, out_features=1280, bias=True)\n",
      "  (1): SiLU()\n",
      "  (2): Linear(in_features=1280, out_features=1280, bias=True)\n",
      ")\n",
      "Module: Linear(in_features=320, out_features=1280, bias=True)\n",
      "Module: SiLU()\n",
      "Module: Linear(in_features=1280, out_features=1280, bias=True)\n",
      "Module: ModuleList(\n",
      "  (0): TimestepEmbedSequential(\n",
      "    (0): Conv2d(8, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (1-2): 2 x TimestepEmbedSequential(\n",
      "    (0): ResBlock(\n",
      "      (in_layers): Sequential(\n",
      "        (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
      "        (1): SiLU()\n",
      "        (2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (h_upd): Identity()\n",
      "      (x_upd): Identity()\n",
      "      (emb_layers): Sequential(\n",
      "        (0): SiLU()\n",
      "        (1): Linear(in_features=1280, out_features=320, bias=True)\n",
      "      )\n",
      "      (out_layers): Sequential(\n",
      "        (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
      "        (1): SiLU()\n",
      "        (2): Dropout(p=0, inplace=False)\n",
      "        (3): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (skip_connection): Identity()\n",
      "    )\n",
      "    (1): SpatialTransformer(\n",
      "      (norm): GroupNorm(32, 320, eps=1e-06, affine=True)\n",
      "      (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (transformer_blocks): ModuleList(\n",
      "        (0): BasicTransformerBlock(\n",
      "          (attn1): CrossAttention(\n",
      "            (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
      "            (to_k): Linear(in_features=320, out_features=320, bias=False)\n",
      "            (to_v): Linear(in_features=320, out_features=320, bias=False)\n",
      "            (to_out): Sequential(\n",
      "              (0): Linear(in_features=320, out_features=320, bias=True)\n",
      "              (1): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (ff): FeedForward(\n",
      "            (net): Sequential(\n",
      "              (0): GEGLU(\n",
      "                (proj): Linear(in_features=320, out_features=2560, bias=True)\n",
      "              )\n",
      "              (1): Dropout(p=0.0, inplace=False)\n",
      "              (2): Linear(in_features=1280, out_features=320, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (attn2): CrossAttention(\n",
      "            (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
      "            (to_k): Linear(in_features=768, out_features=320, bias=False)\n",
      "            (to_v): Linear(in_features=768, out_features=320, bias=False)\n",
      "            (to_out): Sequential(\n",
      "              (0): Linear(in_features=320, out_features=320, bias=True)\n",
      "              (1): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "      (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  (3): TimestepEmbedSequential(\n",
      "    (0): Downsample(\n",
      "      (op): Conv2d(320, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  (4): TimestepEmbedSequential(\n",
      "    (0): ResBlock(\n",
      "      (in_layers): Sequential(\n",
      "        (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
      "        (1): SiLU()\n",
      "        (2): Conv2d(320, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (h_upd): Identity()\n",
      "      (x_upd): Identity()\n",
      "      (emb_layers): Sequential(\n",
      "        (0): SiLU()\n",
      "        (1): Linear(in_features=1280, out_features=640, bias=True)\n",
      "      )\n",
      "      (out_layers): Sequential(\n",
      "        (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
      "        (1): SiLU()\n",
      "        (2): Dropout(p=0, inplace=False)\n",
      "        (3): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (skip_connection): Conv2d(320, 640, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (1): SpatialTransformer(\n",
      "      (norm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
      "      (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (transformer_blocks): ModuleList(\n",
      "        (0): BasicTransformerBlock(\n",
      "          (attn1): CrossAttention(\n",
      "            (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
      "            (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
      "            (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
      "            (to_out): Sequential(\n",
      "              (0): Linear(in_features=640, out_features=640, bias=True)\n",
      "              (1): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (ff): FeedForward(\n",
      "            (net): Sequential(\n",
      "              (0): GEGLU(\n",
      "                (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
      "              )\n",
      "              (1): Dropout(p=0.0, inplace=False)\n",
      "              (2): Linear(in_features=2560, out_features=640, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (attn2): CrossAttention(\n",
      "            (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
      "            (to_k): Linear(in_features=768, out_features=640, bias=False)\n",
      "            (to_v): Linear(in_features=768, out_features=640, bias=False)\n",
      "            (to_out): Sequential(\n",
      "              (0): Linear(in_features=640, out_features=640, bias=True)\n",
      "              (1): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "      (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  (5): TimestepEmbedSequential(\n",
      "    (0): ResBlock(\n",
      "      (in_layers): Sequential(\n",
      "        (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
      "        (1): SiLU()\n",
      "        (2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (h_upd): Identity()\n",
      "      (x_upd): Identity()\n",
      "      (emb_layers): Sequential(\n",
      "        (0): SiLU()\n",
      "        (1): Linear(in_features=1280, out_features=640, bias=True)\n",
      "      )\n",
      "      (out_layers): Sequential(\n",
      "        (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
      "        (1): SiLU()\n",
      "        (2): Dropout(p=0, inplace=False)\n",
      "        (3): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (skip_connection): Identity()\n",
      "    )\n",
      "    (1): SpatialTransformer(\n",
      "      (norm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
      "      (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (transformer_blocks): ModuleList(\n",
      "        (0): BasicTransformerBlock(\n",
      "          (attn1): CrossAttention(\n",
      "            (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
      "            (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
      "            (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
      "            (to_out): Sequential(\n",
      "              (0): Linear(in_features=640, out_features=640, bias=True)\n",
      "              (1): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (ff): FeedForward(\n",
      "            (net): Sequential(\n",
      "              (0): GEGLU(\n",
      "                (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
      "              )\n",
      "              (1): Dropout(p=0.0, inplace=False)\n",
      "              (2): Linear(in_features=2560, out_features=640, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (attn2): CrossAttention(\n",
      "            (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
      "            (to_k): Linear(in_features=768, out_features=640, bias=False)\n",
      "            (to_v): Linear(in_features=768, out_features=640, bias=False)\n",
      "            (to_out): Sequential(\n",
      "              (0): Linear(in_features=640, out_features=640, bias=True)\n",
      "              (1): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "      (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  (6): TimestepEmbedSequential(\n",
      "    (0): Downsample(\n",
      "      (op): Conv2d(640, 640, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  (7): TimestepEmbedSequential(\n",
      "    (0): ResBlock(\n",
      "      (in_layers): Sequential(\n",
      "        (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
      "        (1): SiLU()\n",
      "        (2): Conv2d(640, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (h_upd): Identity()\n",
      "      (x_upd): Identity()\n",
      "      (emb_layers): Sequential(\n",
      "        (0): SiLU()\n",
      "        (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "      )\n",
      "      (out_layers): Sequential(\n",
      "        (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
      "        (1): SiLU()\n",
      "        (2): Dropout(p=0, inplace=False)\n",
      "        (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (skip_connection): Conv2d(640, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (1): SpatialTransformer(\n",
      "      (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
      "      (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (transformer_blocks): ModuleList(\n",
      "        (0): BasicTransformerBlock(\n",
      "          (attn1): CrossAttention(\n",
      "            (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "            (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "            (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "            (to_out): Sequential(\n",
      "              (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "              (1): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (ff): FeedForward(\n",
      "            (net): Sequential(\n",
      "              (0): GEGLU(\n",
      "                (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
      "              )\n",
      "              (1): Dropout(p=0.0, inplace=False)\n",
      "              (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (attn2): CrossAttention(\n",
      "            (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "            (to_k): Linear(in_features=768, out_features=1280, bias=False)\n",
      "            (to_v): Linear(in_features=768, out_features=1280, bias=False)\n",
      "            (to_out): Sequential(\n",
      "              (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "              (1): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "      (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  (8): TimestepEmbedSequential(\n",
      "    (0): ResBlock(\n",
      "      (in_layers): Sequential(\n",
      "        (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
      "        (1): SiLU()\n",
      "        (2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (h_upd): Identity()\n",
      "      (x_upd): Identity()\n",
      "      (emb_layers): Sequential(\n",
      "        (0): SiLU()\n",
      "        (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "      )\n",
      "      (out_layers): Sequential(\n",
      "        (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
      "        (1): SiLU()\n",
      "        (2): Dropout(p=0, inplace=False)\n",
      "        (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (skip_connection): Identity()\n",
      "    )\n",
      "    (1): SpatialTransformer(\n",
      "      (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
      "      (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (transformer_blocks): ModuleList(\n",
      "        (0): BasicTransformerBlock(\n",
      "          (attn1): CrossAttention(\n",
      "            (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "            (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "            (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "            (to_out): Sequential(\n",
      "              (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "              (1): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (ff): FeedForward(\n",
      "            (net): Sequential(\n",
      "              (0): GEGLU(\n",
      "                (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
      "              )\n",
      "              (1): Dropout(p=0.0, inplace=False)\n",
      "              (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (attn2): CrossAttention(\n",
      "            (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "            (to_k): Linear(in_features=768, out_features=1280, bias=False)\n",
      "            (to_v): Linear(in_features=768, out_features=1280, bias=False)\n",
      "            (to_out): Sequential(\n",
      "              (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "              (1): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "      (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  (9): TimestepEmbedSequential(\n",
      "    (0): Downsample(\n",
      "      (op): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  (10-11): 2 x TimestepEmbedSequential(\n",
      "    (0): ResBlock(\n",
      "      (in_layers): Sequential(\n",
      "        (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
      "        (1): SiLU()\n",
      "        (2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (h_upd): Identity()\n",
      "      (x_upd): Identity()\n",
      "      (emb_layers): Sequential(\n",
      "        (0): SiLU()\n",
      "        (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "      )\n",
      "      (out_layers): Sequential(\n",
      "        (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
      "        (1): SiLU()\n",
      "        (2): Dropout(p=0, inplace=False)\n",
      "        (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (skip_connection): Identity()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Module: TimestepEmbedSequential(\n",
      "  (0): Conv2d(8, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")\n",
      "Module: Conv2d(8, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "Module: TimestepEmbedSequential(\n",
      "  (0): ResBlock(\n",
      "    (in_layers): Sequential(\n",
      "      (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
      "      (1): SiLU()\n",
      "      (2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (h_upd): Identity()\n",
      "    (x_upd): Identity()\n",
      "    (emb_layers): Sequential(\n",
      "      (0): SiLU()\n",
      "      (1): Linear(in_features=1280, out_features=320, bias=True)\n",
      "    )\n",
      "    (out_layers): Sequential(\n",
      "      (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
      "      (1): SiLU()\n",
      "      (2): Dropout(p=0, inplace=False)\n",
      "      (3): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (skip_connection): Identity()\n",
      "  )\n",
      "  (1): SpatialTransformer(\n",
      "    (norm): GroupNorm(32, 320, eps=1e-06, affine=True)\n",
      "    (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (transformer_blocks): ModuleList(\n",
      "      (0): BasicTransformerBlock(\n",
      "        (attn1): CrossAttention(\n",
      "          (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
      "          (to_k): Linear(in_features=320, out_features=320, bias=False)\n",
      "          (to_v): Linear(in_features=320, out_features=320, bias=False)\n",
      "          (to_out): Sequential(\n",
      "            (0): Linear(in_features=320, out_features=320, bias=True)\n",
      "            (1): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (ff): FeedForward(\n",
      "          (net): Sequential(\n",
      "            (0): GEGLU(\n",
      "              (proj): Linear(in_features=320, out_features=2560, bias=True)\n",
      "            )\n",
      "            (1): Dropout(p=0.0, inplace=False)\n",
      "            (2): Linear(in_features=1280, out_features=320, bias=True)\n",
      "          )\n",
      "        )\n",
      "        (attn2): CrossAttention(\n",
      "          (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
      "          (to_k): Linear(in_features=768, out_features=320, bias=False)\n",
      "          (to_v): Linear(in_features=768, out_features=320, bias=False)\n",
      "          (to_out): Sequential(\n",
      "            (0): Linear(in_features=320, out_features=320, bias=True)\n",
      "            (1): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n",
      "Module: ResBlock(\n",
      "  (in_layers): Sequential(\n",
      "    (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
      "    (1): SiLU()\n",
      "    (2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (h_upd): Identity()\n",
      "  (x_upd): Identity()\n",
      "  (emb_layers): Sequential(\n",
      "    (0): SiLU()\n",
      "    (1): Linear(in_features=1280, out_features=320, bias=True)\n",
      "  )\n",
      "  (out_layers): Sequential(\n",
      "    (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
      "    (1): SiLU()\n",
      "    (2): Dropout(p=0, inplace=False)\n",
      "    (3): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (skip_connection): Identity()\n",
      ")\n",
      "Module: Sequential(\n",
      "  (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
      "  (1): SiLU()\n",
      "  (2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")\n",
      "Module: GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
      "Module: SiLU()\n",
      "Module: Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "Module: Identity()\n",
      "Module: Sequential(\n",
      "  (0): SiLU()\n",
      "  (1): Linear(in_features=1280, out_features=320, bias=True)\n",
      ")\n",
      "Module: SiLU()\n",
      "Module: Linear(in_features=1280, out_features=320, bias=True)\n",
      "Module: Sequential(\n",
      "  (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
      "  (1): SiLU()\n",
      "  (2): Dropout(p=0, inplace=False)\n",
      "  (3): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")\n",
      "Module: GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
      "Module: SiLU()\n",
      "Module: Dropout(p=0, inplace=False)\n",
      "Module: Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "Module: Identity()\n",
      "Module: SpatialTransformer(\n",
      "  (norm): GroupNorm(32, 320, eps=1e-06, affine=True)\n",
      "  (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (transformer_blocks): ModuleList(\n",
      "    (0): BasicTransformerBlock(\n",
      "      (attn1): CrossAttention(\n",
      "        (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
      "        (to_k): Linear(in_features=320, out_features=320, bias=False)\n",
      "        (to_v): Linear(in_features=320, out_features=320, bias=False)\n",
      "        (to_out): Sequential(\n",
      "          (0): Linear(in_features=320, out_features=320, bias=True)\n",
      "          (1): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (net): Sequential(\n",
      "          (0): GEGLU(\n",
      "            (proj): Linear(in_features=320, out_features=2560, bias=True)\n",
      "          )\n",
      "          (1): Dropout(p=0.0, inplace=False)\n",
      "          (2): Linear(in_features=1280, out_features=320, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (attn2): CrossAttention(\n",
      "        (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
      "        (to_k): Linear(in_features=768, out_features=320, bias=False)\n",
      "        (to_v): Linear(in_features=768, out_features=320, bias=False)\n",
      "        (to_out): Sequential(\n",
      "          (0): Linear(in_features=320, out_features=320, bias=True)\n",
      "          (1): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "      (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
      ")\n",
      "Module: GroupNorm(32, 320, eps=1e-06, affine=True)\n",
      "Module: Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
      "Module: ModuleList(\n",
      "  (0): BasicTransformerBlock(\n",
      "    (attn1): CrossAttention(\n",
      "      (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
      "      (to_k): Linear(in_features=320, out_features=320, bias=False)\n",
      "      (to_v): Linear(in_features=320, out_features=320, bias=False)\n",
      "      (to_out): Sequential(\n",
      "        (0): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (1): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (ff): FeedForward(\n",
      "      (net): Sequential(\n",
      "        (0): GEGLU(\n",
      "          (proj): Linear(in_features=320, out_features=2560, bias=True)\n",
      "        )\n",
      "        (1): Dropout(p=0.0, inplace=False)\n",
      "        (2): Linear(in_features=1280, out_features=320, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (attn2): CrossAttention(\n",
      "      (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
      "      (to_k): Linear(in_features=768, out_features=320, bias=False)\n",
      "      (to_v): Linear(in_features=768, out_features=320, bias=False)\n",
      "      (to_out): Sequential(\n",
      "        (0): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (1): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "    (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "    (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      ")\n",
      "Module: BasicTransformerBlock(\n",
      "  (attn1): CrossAttention(\n",
      "    (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
      "    (to_k): Linear(in_features=320, out_features=320, bias=False)\n",
      "    (to_v): Linear(in_features=320, out_features=320, bias=False)\n",
      "    (to_out): Sequential(\n",
      "      (0): Linear(in_features=320, out_features=320, bias=True)\n",
      "      (1): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (ff): FeedForward(\n",
      "    (net): Sequential(\n",
      "      (0): GEGLU(\n",
      "        (proj): Linear(in_features=320, out_features=2560, bias=True)\n",
      "      )\n",
      "      (1): Dropout(p=0.0, inplace=False)\n",
      "      (2): Linear(in_features=1280, out_features=320, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (attn2): CrossAttention(\n",
      "    (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
      "    (to_k): Linear(in_features=768, out_features=320, bias=False)\n",
      "    (to_v): Linear(in_features=768, out_features=320, bias=False)\n",
      "    (to_out): Sequential(\n",
      "      (0): Linear(in_features=320, out_features=320, bias=True)\n",
      "      (1): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "  (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "  (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      ")\n",
      "Module: CrossAttention(\n",
      "  (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
      "  (to_k): Linear(in_features=320, out_features=320, bias=False)\n",
      "  (to_v): Linear(in_features=320, out_features=320, bias=False)\n",
      "  (to_out): Sequential(\n",
      "    (0): Linear(in_features=320, out_features=320, bias=True)\n",
      "    (1): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      ")\n",
      "Module: Linear(in_features=320, out_features=320, bias=False)\n",
      "Module: Linear(in_features=320, out_features=320, bias=False)\n",
      "Module: Linear(in_features=320, out_features=320, bias=False)\n",
      "Module: Sequential(\n",
      "  (0): Linear(in_features=320, out_features=320, bias=True)\n",
      "  (1): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "Module: Linear(in_features=320, out_features=320, bias=True)\n",
      "Module: Dropout(p=0.0, inplace=False)\n",
      "Module: FeedForward(\n",
      "  (net): Sequential(\n",
      "    (0): GEGLU(\n",
      "      (proj): Linear(in_features=320, out_features=2560, bias=True)\n",
      "    )\n",
      "    (1): Dropout(p=0.0, inplace=False)\n",
      "    (2): Linear(in_features=1280, out_features=320, bias=True)\n",
      "  )\n",
      ")\n",
      "Module: Sequential(\n",
      "  (0): GEGLU(\n",
      "    (proj): Linear(in_features=320, out_features=2560, bias=True)\n",
      "  )\n",
      "  (1): Dropout(p=0.0, inplace=False)\n",
      "  (2): Linear(in_features=1280, out_features=320, bias=True)\n",
      ")\n",
      "Module: GEGLU(\n",
      "  (proj): Linear(in_features=320, out_features=2560, bias=True)\n",
      ")\n",
      "Module: Linear(in_features=320, out_features=2560, bias=True)\n",
      "Module: Dropout(p=0.0, inplace=False)\n",
      "Module: Linear(in_features=1280, out_features=320, bias=True)\n",
      "Module: CrossAttention(\n",
      "  (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
      "  (to_k): Linear(in_features=768, out_features=320, bias=False)\n",
      "  (to_v): Linear(in_features=768, out_features=320, bias=False)\n",
      "  (to_out): Sequential(\n",
      "    (0): Linear(in_features=320, out_features=320, bias=True)\n",
      "    (1): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      ")\n",
      "Module: Linear(in_features=320, out_features=320, bias=False)\n",
      "Module: Linear(in_features=768, out_features=320, bias=False)\n",
      "Module: Linear(in_features=768, out_features=320, bias=False)\n",
      "Module: Sequential(\n",
      "  (0): Linear(in_features=320, out_features=320, bias=True)\n",
      "  (1): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "Module: Linear(in_features=320, out_features=320, bias=True)\n",
      "Module: Dropout(p=0.0, inplace=False)\n",
      "Module: LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "Module: LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "Module: LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "Module: Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
      "Module: TimestepEmbedSequential(\n",
      "  (0): ResBlock(\n",
      "    (in_layers): Sequential(\n",
      "      (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
      "      (1): SiLU()\n",
      "      (2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (h_upd): Identity()\n",
      "    (x_upd): Identity()\n",
      "    (emb_layers): Sequential(\n",
      "      (0): SiLU()\n",
      "      (1): Linear(in_features=1280, out_features=320, bias=True)\n",
      "    )\n",
      "    (out_layers): Sequential(\n",
      "      (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
      "      (1): SiLU()\n",
      "      (2): Dropout(p=0, inplace=False)\n",
      "      (3): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (skip_connection): Identity()\n",
      "  )\n",
      "  (1): SpatialTransformer(\n",
      "    (norm): GroupNorm(32, 320, eps=1e-06, affine=True)\n",
      "    (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (transformer_blocks): ModuleList(\n",
      "      (0): BasicTransformerBlock(\n",
      "        (attn1): CrossAttention(\n",
      "          (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
      "          (to_k): Linear(in_features=320, out_features=320, bias=False)\n",
      "          (to_v): Linear(in_features=320, out_features=320, bias=False)\n",
      "          (to_out): Sequential(\n",
      "            (0): Linear(in_features=320, out_features=320, bias=True)\n",
      "            (1): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (ff): FeedForward(\n",
      "          (net): Sequential(\n",
      "            (0): GEGLU(\n",
      "              (proj): Linear(in_features=320, out_features=2560, bias=True)\n",
      "            )\n",
      "            (1): Dropout(p=0.0, inplace=False)\n",
      "            (2): Linear(in_features=1280, out_features=320, bias=True)\n",
      "          )\n",
      "        )\n",
      "        (attn2): CrossAttention(\n",
      "          (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
      "          (to_k): Linear(in_features=768, out_features=320, bias=False)\n",
      "          (to_v): Linear(in_features=768, out_features=320, bias=False)\n",
      "          (to_out): Sequential(\n",
      "            (0): Linear(in_features=320, out_features=320, bias=True)\n",
      "            (1): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n",
      "Module: ResBlock(\n",
      "  (in_layers): Sequential(\n",
      "    (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
      "    (1): SiLU()\n",
      "    (2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (h_upd): Identity()\n",
      "  (x_upd): Identity()\n",
      "  (emb_layers): Sequential(\n",
      "    (0): SiLU()\n",
      "    (1): Linear(in_features=1280, out_features=320, bias=True)\n",
      "  )\n",
      "  (out_layers): Sequential(\n",
      "    (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
      "    (1): SiLU()\n",
      "    (2): Dropout(p=0, inplace=False)\n",
      "    (3): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (skip_connection): Identity()\n",
      ")\n",
      "Module: Sequential(\n",
      "  (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
      "  (1): SiLU()\n",
      "  (2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")\n",
      "Module: GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
      "Module: SiLU()\n",
      "Module: Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "Module: Identity()\n",
      "Module: Sequential(\n",
      "  (0): SiLU()\n",
      "  (1): Linear(in_features=1280, out_features=320, bias=True)\n",
      ")\n",
      "Module: SiLU()\n",
      "Module: Linear(in_features=1280, out_features=320, bias=True)\n",
      "Module: Sequential(\n",
      "  (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
      "  (1): SiLU()\n",
      "  (2): Dropout(p=0, inplace=False)\n",
      "  (3): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")\n",
      "Module: GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
      "Module: SiLU()\n",
      "Module: Dropout(p=0, inplace=False)\n",
      "Module: Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "Module: Identity()\n",
      "Module: SpatialTransformer(\n",
      "  (norm): GroupNorm(32, 320, eps=1e-06, affine=True)\n",
      "  (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (transformer_blocks): ModuleList(\n",
      "    (0): BasicTransformerBlock(\n",
      "      (attn1): CrossAttention(\n",
      "        (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
      "        (to_k): Linear(in_features=320, out_features=320, bias=False)\n",
      "        (to_v): Linear(in_features=320, out_features=320, bias=False)\n",
      "        (to_out): Sequential(\n",
      "          (0): Linear(in_features=320, out_features=320, bias=True)\n",
      "          (1): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (net): Sequential(\n",
      "          (0): GEGLU(\n",
      "            (proj): Linear(in_features=320, out_features=2560, bias=True)\n",
      "          )\n",
      "          (1): Dropout(p=0.0, inplace=False)\n",
      "          (2): Linear(in_features=1280, out_features=320, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (attn2): CrossAttention(\n",
      "        (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
      "        (to_k): Linear(in_features=768, out_features=320, bias=False)\n",
      "        (to_v): Linear(in_features=768, out_features=320, bias=False)\n",
      "        (to_out): Sequential(\n",
      "          (0): Linear(in_features=320, out_features=320, bias=True)\n",
      "          (1): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "      (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
      ")\n",
      "Module: GroupNorm(32, 320, eps=1e-06, affine=True)\n",
      "Module: Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
      "Module: ModuleList(\n",
      "  (0): BasicTransformerBlock(\n",
      "    (attn1): CrossAttention(\n",
      "      (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
      "      (to_k): Linear(in_features=320, out_features=320, bias=False)\n",
      "      (to_v): Linear(in_features=320, out_features=320, bias=False)\n",
      "      (to_out): Sequential(\n",
      "        (0): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (1): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (ff): FeedForward(\n",
      "      (net): Sequential(\n",
      "        (0): GEGLU(\n",
      "          (proj): Linear(in_features=320, out_features=2560, bias=True)\n",
      "        )\n",
      "        (1): Dropout(p=0.0, inplace=False)\n",
      "        (2): Linear(in_features=1280, out_features=320, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (attn2): CrossAttention(\n",
      "      (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
      "      (to_k): Linear(in_features=768, out_features=320, bias=False)\n",
      "      (to_v): Linear(in_features=768, out_features=320, bias=False)\n",
      "      (to_out): Sequential(\n",
      "        (0): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (1): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "    (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "    (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      ")\n",
      "Module: BasicTransformerBlock(\n",
      "  (attn1): CrossAttention(\n",
      "    (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
      "    (to_k): Linear(in_features=320, out_features=320, bias=False)\n",
      "    (to_v): Linear(in_features=320, out_features=320, bias=False)\n",
      "    (to_out): Sequential(\n",
      "      (0): Linear(in_features=320, out_features=320, bias=True)\n",
      "      (1): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (ff): FeedForward(\n",
      "    (net): Sequential(\n",
      "      (0): GEGLU(\n",
      "        (proj): Linear(in_features=320, out_features=2560, bias=True)\n",
      "      )\n",
      "      (1): Dropout(p=0.0, inplace=False)\n",
      "      (2): Linear(in_features=1280, out_features=320, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (attn2): CrossAttention(\n",
      "    (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
      "    (to_k): Linear(in_features=768, out_features=320, bias=False)\n",
      "    (to_v): Linear(in_features=768, out_features=320, bias=False)\n",
      "    (to_out): Sequential(\n",
      "      (0): Linear(in_features=320, out_features=320, bias=True)\n",
      "      (1): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "  (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "  (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      ")\n",
      "Module: CrossAttention(\n",
      "  (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
      "  (to_k): Linear(in_features=320, out_features=320, bias=False)\n",
      "  (to_v): Linear(in_features=320, out_features=320, bias=False)\n",
      "  (to_out): Sequential(\n",
      "    (0): Linear(in_features=320, out_features=320, bias=True)\n",
      "    (1): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      ")\n",
      "Module: Linear(in_features=320, out_features=320, bias=False)\n",
      "Module: Linear(in_features=320, out_features=320, bias=False)\n",
      "Module: Linear(in_features=320, out_features=320, bias=False)\n",
      "Module: Sequential(\n",
      "  (0): Linear(in_features=320, out_features=320, bias=True)\n",
      "  (1): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "Module: Linear(in_features=320, out_features=320, bias=True)\n",
      "Module: Dropout(p=0.0, inplace=False)\n",
      "Module: FeedForward(\n",
      "  (net): Sequential(\n",
      "    (0): GEGLU(\n",
      "      (proj): Linear(in_features=320, out_features=2560, bias=True)\n",
      "    )\n",
      "    (1): Dropout(p=0.0, inplace=False)\n",
      "    (2): Linear(in_features=1280, out_features=320, bias=True)\n",
      "  )\n",
      ")\n",
      "Module: Sequential(\n",
      "  (0): GEGLU(\n",
      "    (proj): Linear(in_features=320, out_features=2560, bias=True)\n",
      "  )\n",
      "  (1): Dropout(p=0.0, inplace=False)\n",
      "  (2): Linear(in_features=1280, out_features=320, bias=True)\n",
      ")\n",
      "Module: GEGLU(\n",
      "  (proj): Linear(in_features=320, out_features=2560, bias=True)\n",
      ")\n",
      "Module: Linear(in_features=320, out_features=2560, bias=True)\n",
      "Module: Dropout(p=0.0, inplace=False)\n",
      "Module: Linear(in_features=1280, out_features=320, bias=True)\n",
      "Module: CrossAttention(\n",
      "  (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
      "  (to_k): Linear(in_features=768, out_features=320, bias=False)\n",
      "  (to_v): Linear(in_features=768, out_features=320, bias=False)\n",
      "  (to_out): Sequential(\n",
      "    (0): Linear(in_features=320, out_features=320, bias=True)\n",
      "    (1): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      ")\n",
      "Module: Linear(in_features=320, out_features=320, bias=False)\n",
      "Module: Linear(in_features=768, out_features=320, bias=False)\n",
      "Module: Linear(in_features=768, out_features=320, bias=False)\n",
      "Module: Sequential(\n",
      "  (0): Linear(in_features=320, out_features=320, bias=True)\n",
      "  (1): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "Module: Linear(in_features=320, out_features=320, bias=True)\n",
      "Module: Dropout(p=0.0, inplace=False)\n",
      "Module: LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "Module: LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "Module: LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "Module: Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
      "Module: TimestepEmbedSequential(\n",
      "  (0): Downsample(\n",
      "    (op): Conv2d(320, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "  )\n",
      ")\n",
      "Module: Downsample(\n",
      "  (op): Conv2d(320, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      ")\n",
      "Module: Conv2d(320, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "Module: TimestepEmbedSequential(\n",
      "  (0): ResBlock(\n",
      "    (in_layers): Sequential(\n",
      "      (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
      "      (1): SiLU()\n",
      "      (2): Conv2d(320, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (h_upd): Identity()\n",
      "    (x_upd): Identity()\n",
      "    (emb_layers): Sequential(\n",
      "      (0): SiLU()\n",
      "      (1): Linear(in_features=1280, out_features=640, bias=True)\n",
      "    )\n",
      "    (out_layers): Sequential(\n",
      "      (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
      "      (1): SiLU()\n",
      "      (2): Dropout(p=0, inplace=False)\n",
      "      (3): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (skip_connection): Conv2d(320, 640, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (1): SpatialTransformer(\n",
      "    (norm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
      "    (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (transformer_blocks): ModuleList(\n",
      "      (0): BasicTransformerBlock(\n",
      "        (attn1): CrossAttention(\n",
      "          (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
      "          (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
      "          (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
      "          (to_out): Sequential(\n",
      "            (0): Linear(in_features=640, out_features=640, bias=True)\n",
      "            (1): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (ff): FeedForward(\n",
      "          (net): Sequential(\n",
      "            (0): GEGLU(\n",
      "              (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
      "            )\n",
      "            (1): Dropout(p=0.0, inplace=False)\n",
      "            (2): Linear(in_features=2560, out_features=640, bias=True)\n",
      "          )\n",
      "        )\n",
      "        (attn2): CrossAttention(\n",
      "          (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
      "          (to_k): Linear(in_features=768, out_features=640, bias=False)\n",
      "          (to_v): Linear(in_features=768, out_features=640, bias=False)\n",
      "          (to_out): Sequential(\n",
      "            (0): Linear(in_features=640, out_features=640, bias=True)\n",
      "            (1): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n",
      "Module: ResBlock(\n",
      "  (in_layers): Sequential(\n",
      "    (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
      "    (1): SiLU()\n",
      "    (2): Conv2d(320, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (h_upd): Identity()\n",
      "  (x_upd): Identity()\n",
      "  (emb_layers): Sequential(\n",
      "    (0): SiLU()\n",
      "    (1): Linear(in_features=1280, out_features=640, bias=True)\n",
      "  )\n",
      "  (out_layers): Sequential(\n",
      "    (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
      "    (1): SiLU()\n",
      "    (2): Dropout(p=0, inplace=False)\n",
      "    (3): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (skip_connection): Conv2d(320, 640, kernel_size=(1, 1), stride=(1, 1))\n",
      ")\n",
      "Module: Sequential(\n",
      "  (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
      "  (1): SiLU()\n",
      "  (2): Conv2d(320, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")\n",
      "Module: GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
      "Module: SiLU()\n",
      "Module: Conv2d(320, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "Module: Identity()\n",
      "Module: Sequential(\n",
      "  (0): SiLU()\n",
      "  (1): Linear(in_features=1280, out_features=640, bias=True)\n",
      ")\n",
      "Module: SiLU()\n",
      "Module: Linear(in_features=1280, out_features=640, bias=True)\n",
      "Module: Sequential(\n",
      "  (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
      "  (1): SiLU()\n",
      "  (2): Dropout(p=0, inplace=False)\n",
      "  (3): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")\n",
      "Module: GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
      "Module: SiLU()\n",
      "Module: Dropout(p=0, inplace=False)\n",
      "Module: Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "Module: Conv2d(320, 640, kernel_size=(1, 1), stride=(1, 1))\n",
      "Module: SpatialTransformer(\n",
      "  (norm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
      "  (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (transformer_blocks): ModuleList(\n",
      "    (0): BasicTransformerBlock(\n",
      "      (attn1): CrossAttention(\n",
      "        (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
      "        (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
      "        (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
      "        (to_out): Sequential(\n",
      "          (0): Linear(in_features=640, out_features=640, bias=True)\n",
      "          (1): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (net): Sequential(\n",
      "          (0): GEGLU(\n",
      "            (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
      "          )\n",
      "          (1): Dropout(p=0.0, inplace=False)\n",
      "          (2): Linear(in_features=2560, out_features=640, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (attn2): CrossAttention(\n",
      "        (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
      "        (to_k): Linear(in_features=768, out_features=640, bias=False)\n",
      "        (to_v): Linear(in_features=768, out_features=640, bias=False)\n",
      "        (to_out): Sequential(\n",
      "          (0): Linear(in_features=640, out_features=640, bias=True)\n",
      "          (1): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
      "      (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
      ")\n",
      "Module: GroupNorm(32, 640, eps=1e-06, affine=True)\n",
      "Module: Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
      "Module: ModuleList(\n",
      "  (0): BasicTransformerBlock(\n",
      "    (attn1): CrossAttention(\n",
      "      (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
      "      (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
      "      (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
      "      (to_out): Sequential(\n",
      "        (0): Linear(in_features=640, out_features=640, bias=True)\n",
      "        (1): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (ff): FeedForward(\n",
      "      (net): Sequential(\n",
      "        (0): GEGLU(\n",
      "          (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
      "        )\n",
      "        (1): Dropout(p=0.0, inplace=False)\n",
      "        (2): Linear(in_features=2560, out_features=640, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (attn2): CrossAttention(\n",
      "      (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
      "      (to_k): Linear(in_features=768, out_features=640, bias=False)\n",
      "      (to_v): Linear(in_features=768, out_features=640, bias=False)\n",
      "      (to_out): Sequential(\n",
      "        (0): Linear(in_features=640, out_features=640, bias=True)\n",
      "        (1): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
      "    (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
      "    (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      ")\n",
      "Module: BasicTransformerBlock(\n",
      "  (attn1): CrossAttention(\n",
      "    (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
      "    (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
      "    (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
      "    (to_out): Sequential(\n",
      "      (0): Linear(in_features=640, out_features=640, bias=True)\n",
      "      (1): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (ff): FeedForward(\n",
      "    (net): Sequential(\n",
      "      (0): GEGLU(\n",
      "        (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
      "      )\n",
      "      (1): Dropout(p=0.0, inplace=False)\n",
      "      (2): Linear(in_features=2560, out_features=640, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (attn2): CrossAttention(\n",
      "    (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
      "    (to_k): Linear(in_features=768, out_features=640, bias=False)\n",
      "    (to_v): Linear(in_features=768, out_features=640, bias=False)\n",
      "    (to_out): Sequential(\n",
      "      (0): Linear(in_features=640, out_features=640, bias=True)\n",
      "      (1): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
      "  (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
      "  (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
      ")\n",
      "Module: CrossAttention(\n",
      "  (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
      "  (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
      "  (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
      "  (to_out): Sequential(\n",
      "    (0): Linear(in_features=640, out_features=640, bias=True)\n",
      "    (1): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      ")\n",
      "Module: Linear(in_features=640, out_features=640, bias=False)\n",
      "Module: Linear(in_features=640, out_features=640, bias=False)\n",
      "Module: Linear(in_features=640, out_features=640, bias=False)\n",
      "Module: Sequential(\n",
      "  (0): Linear(in_features=640, out_features=640, bias=True)\n",
      "  (1): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "Module: Linear(in_features=640, out_features=640, bias=True)\n",
      "Module: Dropout(p=0.0, inplace=False)\n",
      "Module: FeedForward(\n",
      "  (net): Sequential(\n",
      "    (0): GEGLU(\n",
      "      (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
      "    )\n",
      "    (1): Dropout(p=0.0, inplace=False)\n",
      "    (2): Linear(in_features=2560, out_features=640, bias=True)\n",
      "  )\n",
      ")\n",
      "Module: Sequential(\n",
      "  (0): GEGLU(\n",
      "    (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
      "  )\n",
      "  (1): Dropout(p=0.0, inplace=False)\n",
      "  (2): Linear(in_features=2560, out_features=640, bias=True)\n",
      ")\n",
      "Module: GEGLU(\n",
      "  (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
      ")\n",
      "Module: Linear(in_features=640, out_features=5120, bias=True)\n",
      "Module: Dropout(p=0.0, inplace=False)\n",
      "Module: Linear(in_features=2560, out_features=640, bias=True)\n",
      "Module: CrossAttention(\n",
      "  (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
      "  (to_k): Linear(in_features=768, out_features=640, bias=False)\n",
      "  (to_v): Linear(in_features=768, out_features=640, bias=False)\n",
      "  (to_out): Sequential(\n",
      "    (0): Linear(in_features=640, out_features=640, bias=True)\n",
      "    (1): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      ")\n",
      "Module: Linear(in_features=640, out_features=640, bias=False)\n",
      "Module: Linear(in_features=768, out_features=640, bias=False)\n",
      "Module: Linear(in_features=768, out_features=640, bias=False)\n",
      "Module: Sequential(\n",
      "  (0): Linear(in_features=640, out_features=640, bias=True)\n",
      "  (1): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "Module: Linear(in_features=640, out_features=640, bias=True)\n",
      "Module: Dropout(p=0.0, inplace=False)\n",
      "Module: LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
      "Module: LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
      "Module: LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
      "Module: Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
      "Module: TimestepEmbedSequential(\n",
      "  (0): ResBlock(\n",
      "    (in_layers): Sequential(\n",
      "      (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
      "      (1): SiLU()\n",
      "      (2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (h_upd): Identity()\n",
      "    (x_upd): Identity()\n",
      "    (emb_layers): Sequential(\n",
      "      (0): SiLU()\n",
      "      (1): Linear(in_features=1280, out_features=640, bias=True)\n",
      "    )\n",
      "    (out_layers): Sequential(\n",
      "      (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
      "      (1): SiLU()\n",
      "      (2): Dropout(p=0, inplace=False)\n",
      "      (3): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (skip_connection): Identity()\n",
      "  )\n",
      "  (1): SpatialTransformer(\n",
      "    (norm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
      "    (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (transformer_blocks): ModuleList(\n",
      "      (0): BasicTransformerBlock(\n",
      "        (attn1): CrossAttention(\n",
      "          (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
      "          (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
      "          (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
      "          (to_out): Sequential(\n",
      "            (0): Linear(in_features=640, out_features=640, bias=True)\n",
      "            (1): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (ff): FeedForward(\n",
      "          (net): Sequential(\n",
      "            (0): GEGLU(\n",
      "              (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
      "            )\n",
      "            (1): Dropout(p=0.0, inplace=False)\n",
      "            (2): Linear(in_features=2560, out_features=640, bias=True)\n",
      "          )\n",
      "        )\n",
      "        (attn2): CrossAttention(\n",
      "          (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
      "          (to_k): Linear(in_features=768, out_features=640, bias=False)\n",
      "          (to_v): Linear(in_features=768, out_features=640, bias=False)\n",
      "          (to_out): Sequential(\n",
      "            (0): Linear(in_features=640, out_features=640, bias=True)\n",
      "            (1): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n",
      "Module: ResBlock(\n",
      "  (in_layers): Sequential(\n",
      "    (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
      "    (1): SiLU()\n",
      "    (2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (h_upd): Identity()\n",
      "  (x_upd): Identity()\n",
      "  (emb_layers): Sequential(\n",
      "    (0): SiLU()\n",
      "    (1): Linear(in_features=1280, out_features=640, bias=True)\n",
      "  )\n",
      "  (out_layers): Sequential(\n",
      "    (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
      "    (1): SiLU()\n",
      "    (2): Dropout(p=0, inplace=False)\n",
      "    (3): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (skip_connection): Identity()\n",
      ")\n",
      "Module: Sequential(\n",
      "  (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
      "  (1): SiLU()\n",
      "  (2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")\n",
      "Module: GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
      "Module: SiLU()\n",
      "Module: Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "Module: Identity()\n",
      "Module: Sequential(\n",
      "  (0): SiLU()\n",
      "  (1): Linear(in_features=1280, out_features=640, bias=True)\n",
      ")\n",
      "Module: SiLU()\n",
      "Module: Linear(in_features=1280, out_features=640, bias=True)\n",
      "Module: Sequential(\n",
      "  (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
      "  (1): SiLU()\n",
      "  (2): Dropout(p=0, inplace=False)\n",
      "  (3): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")\n",
      "Module: GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
      "Module: SiLU()\n",
      "Module: Dropout(p=0, inplace=False)\n",
      "Module: Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "Module: Identity()\n",
      "Module: SpatialTransformer(\n",
      "  (norm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
      "  (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (transformer_blocks): ModuleList(\n",
      "    (0): BasicTransformerBlock(\n",
      "      (attn1): CrossAttention(\n",
      "        (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
      "        (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
      "        (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
      "        (to_out): Sequential(\n",
      "          (0): Linear(in_features=640, out_features=640, bias=True)\n",
      "          (1): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (net): Sequential(\n",
      "          (0): GEGLU(\n",
      "            (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
      "          )\n",
      "          (1): Dropout(p=0.0, inplace=False)\n",
      "          (2): Linear(in_features=2560, out_features=640, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (attn2): CrossAttention(\n",
      "        (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
      "        (to_k): Linear(in_features=768, out_features=640, bias=False)\n",
      "        (to_v): Linear(in_features=768, out_features=640, bias=False)\n",
      "        (to_out): Sequential(\n",
      "          (0): Linear(in_features=640, out_features=640, bias=True)\n",
      "          (1): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
      "      (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
      ")\n",
      "Module: GroupNorm(32, 640, eps=1e-06, affine=True)\n",
      "Module: Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
      "Module: ModuleList(\n",
      "  (0): BasicTransformerBlock(\n",
      "    (attn1): CrossAttention(\n",
      "      (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
      "      (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
      "      (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
      "      (to_out): Sequential(\n",
      "        (0): Linear(in_features=640, out_features=640, bias=True)\n",
      "        (1): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (ff): FeedForward(\n",
      "      (net): Sequential(\n",
      "        (0): GEGLU(\n",
      "          (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
      "        )\n",
      "        (1): Dropout(p=0.0, inplace=False)\n",
      "        (2): Linear(in_features=2560, out_features=640, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (attn2): CrossAttention(\n",
      "      (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
      "      (to_k): Linear(in_features=768, out_features=640, bias=False)\n",
      "      (to_v): Linear(in_features=768, out_features=640, bias=False)\n",
      "      (to_out): Sequential(\n",
      "        (0): Linear(in_features=640, out_features=640, bias=True)\n",
      "        (1): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
      "    (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
      "    (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      ")\n",
      "Module: BasicTransformerBlock(\n",
      "  (attn1): CrossAttention(\n",
      "    (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
      "    (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
      "    (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
      "    (to_out): Sequential(\n",
      "      (0): Linear(in_features=640, out_features=640, bias=True)\n",
      "      (1): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (ff): FeedForward(\n",
      "    (net): Sequential(\n",
      "      (0): GEGLU(\n",
      "        (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
      "      )\n",
      "      (1): Dropout(p=0.0, inplace=False)\n",
      "      (2): Linear(in_features=2560, out_features=640, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (attn2): CrossAttention(\n",
      "    (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
      "    (to_k): Linear(in_features=768, out_features=640, bias=False)\n",
      "    (to_v): Linear(in_features=768, out_features=640, bias=False)\n",
      "    (to_out): Sequential(\n",
      "      (0): Linear(in_features=640, out_features=640, bias=True)\n",
      "      (1): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
      "  (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
      "  (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
      ")\n",
      "Module: CrossAttention(\n",
      "  (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
      "  (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
      "  (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
      "  (to_out): Sequential(\n",
      "    (0): Linear(in_features=640, out_features=640, bias=True)\n",
      "    (1): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      ")\n",
      "Module: Linear(in_features=640, out_features=640, bias=False)\n",
      "Module: Linear(in_features=640, out_features=640, bias=False)\n",
      "Module: Linear(in_features=640, out_features=640, bias=False)\n",
      "Module: Sequential(\n",
      "  (0): Linear(in_features=640, out_features=640, bias=True)\n",
      "  (1): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "Module: Linear(in_features=640, out_features=640, bias=True)\n",
      "Module: Dropout(p=0.0, inplace=False)\n",
      "Module: FeedForward(\n",
      "  (net): Sequential(\n",
      "    (0): GEGLU(\n",
      "      (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
      "    )\n",
      "    (1): Dropout(p=0.0, inplace=False)\n",
      "    (2): Linear(in_features=2560, out_features=640, bias=True)\n",
      "  )\n",
      ")\n",
      "Module: Sequential(\n",
      "  (0): GEGLU(\n",
      "    (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
      "  )\n",
      "  (1): Dropout(p=0.0, inplace=False)\n",
      "  (2): Linear(in_features=2560, out_features=640, bias=True)\n",
      ")\n",
      "Module: GEGLU(\n",
      "  (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
      ")\n",
      "Module: Linear(in_features=640, out_features=5120, bias=True)\n",
      "Module: Dropout(p=0.0, inplace=False)\n",
      "Module: Linear(in_features=2560, out_features=640, bias=True)\n",
      "Module: CrossAttention(\n",
      "  (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
      "  (to_k): Linear(in_features=768, out_features=640, bias=False)\n",
      "  (to_v): Linear(in_features=768, out_features=640, bias=False)\n",
      "  (to_out): Sequential(\n",
      "    (0): Linear(in_features=640, out_features=640, bias=True)\n",
      "    (1): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      ")\n",
      "Module: Linear(in_features=640, out_features=640, bias=False)\n",
      "Module: Linear(in_features=768, out_features=640, bias=False)\n",
      "Module: Linear(in_features=768, out_features=640, bias=False)\n",
      "Module: Sequential(\n",
      "  (0): Linear(in_features=640, out_features=640, bias=True)\n",
      "  (1): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "Module: Linear(in_features=640, out_features=640, bias=True)\n",
      "Module: Dropout(p=0.0, inplace=False)\n",
      "Module: LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
      "Module: LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
      "Module: LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
      "Module: Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
      "Module: TimestepEmbedSequential(\n",
      "  (0): Downsample(\n",
      "    (op): Conv2d(640, 640, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "  )\n",
      ")\n",
      "Module: Downsample(\n",
      "  (op): Conv2d(640, 640, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      ")\n",
      "Module: Conv2d(640, 640, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "Module: TimestepEmbedSequential(\n",
      "  (0): ResBlock(\n",
      "    (in_layers): Sequential(\n",
      "      (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
      "      (1): SiLU()\n",
      "      (2): Conv2d(640, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (h_upd): Identity()\n",
      "    (x_upd): Identity()\n",
      "    (emb_layers): Sequential(\n",
      "      (0): SiLU()\n",
      "      (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "    )\n",
      "    (out_layers): Sequential(\n",
      "      (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
      "      (1): SiLU()\n",
      "      (2): Dropout(p=0, inplace=False)\n",
      "      (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (skip_connection): Conv2d(640, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (1): SpatialTransformer(\n",
      "    (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
      "    (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (transformer_blocks): ModuleList(\n",
      "      (0): BasicTransformerBlock(\n",
      "        (attn1): CrossAttention(\n",
      "          (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "          (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "          (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "          (to_out): Sequential(\n",
      "            (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "            (1): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (ff): FeedForward(\n",
      "          (net): Sequential(\n",
      "            (0): GEGLU(\n",
      "              (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
      "            )\n",
      "            (1): Dropout(p=0.0, inplace=False)\n",
      "            (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
      "          )\n",
      "        )\n",
      "        (attn2): CrossAttention(\n",
      "          (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "          (to_k): Linear(in_features=768, out_features=1280, bias=False)\n",
      "          (to_v): Linear(in_features=768, out_features=1280, bias=False)\n",
      "          (to_out): Sequential(\n",
      "            (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "            (1): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n",
      "Module: ResBlock(\n",
      "  (in_layers): Sequential(\n",
      "    (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
      "    (1): SiLU()\n",
      "    (2): Conv2d(640, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (h_upd): Identity()\n",
      "  (x_upd): Identity()\n",
      "  (emb_layers): Sequential(\n",
      "    (0): SiLU()\n",
      "    (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "  )\n",
      "  (out_layers): Sequential(\n",
      "    (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
      "    (1): SiLU()\n",
      "    (2): Dropout(p=0, inplace=False)\n",
      "    (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (skip_connection): Conv2d(640, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
      ")\n",
      "Module: Sequential(\n",
      "  (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
      "  (1): SiLU()\n",
      "  (2): Conv2d(640, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")\n",
      "Module: GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
      "Module: SiLU()\n",
      "Module: Conv2d(640, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "Module: Identity()\n",
      "Module: Sequential(\n",
      "  (0): SiLU()\n",
      "  (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
      ")\n",
      "Module: SiLU()\n",
      "Module: Linear(in_features=1280, out_features=1280, bias=True)\n",
      "Module: Sequential(\n",
      "  (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
      "  (1): SiLU()\n",
      "  (2): Dropout(p=0, inplace=False)\n",
      "  (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")\n",
      "Module: GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
      "Module: SiLU()\n",
      "Module: Dropout(p=0, inplace=False)\n",
      "Module: Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "Module: Conv2d(640, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
      "Module: SpatialTransformer(\n",
      "  (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
      "  (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (transformer_blocks): ModuleList(\n",
      "    (0): BasicTransformerBlock(\n",
      "      (attn1): CrossAttention(\n",
      "        (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "        (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "        (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "        (to_out): Sequential(\n",
      "          (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (1): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (net): Sequential(\n",
      "          (0): GEGLU(\n",
      "            (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
      "          )\n",
      "          (1): Dropout(p=0.0, inplace=False)\n",
      "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (attn2): CrossAttention(\n",
      "        (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "        (to_k): Linear(in_features=768, out_features=1280, bias=False)\n",
      "        (to_v): Linear(in_features=768, out_features=1280, bias=False)\n",
      "        (to_out): Sequential(\n",
      "          (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (1): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "      (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
      ")\n",
      "Module: GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
      "Module: Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
      "Module: ModuleList(\n",
      "  (0): BasicTransformerBlock(\n",
      "    (attn1): CrossAttention(\n",
      "      (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "      (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "      (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "      (to_out): Sequential(\n",
      "        (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "        (1): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (ff): FeedForward(\n",
      "      (net): Sequential(\n",
      "        (0): GEGLU(\n",
      "          (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
      "        )\n",
      "        (1): Dropout(p=0.0, inplace=False)\n",
      "        (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (attn2): CrossAttention(\n",
      "      (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "      (to_k): Linear(in_features=768, out_features=1280, bias=False)\n",
      "      (to_v): Linear(in_features=768, out_features=1280, bias=False)\n",
      "      (to_out): Sequential(\n",
      "        (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "        (1): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "    (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "    (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      ")\n",
      "Module: BasicTransformerBlock(\n",
      "  (attn1): CrossAttention(\n",
      "    (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "    (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "    (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "    (to_out): Sequential(\n",
      "      (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "      (1): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (ff): FeedForward(\n",
      "    (net): Sequential(\n",
      "      (0): GEGLU(\n",
      "        (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
      "      )\n",
      "      (1): Dropout(p=0.0, inplace=False)\n",
      "      (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (attn2): CrossAttention(\n",
      "    (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "    (to_k): Linear(in_features=768, out_features=1280, bias=False)\n",
      "    (to_v): Linear(in_features=768, out_features=1280, bias=False)\n",
      "    (to_out): Sequential(\n",
      "      (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "      (1): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "  (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "  (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      ")\n",
      "Module: CrossAttention(\n",
      "  (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "  (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "  (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "  (to_out): Sequential(\n",
      "    (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "    (1): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      ")\n",
      "Module: Linear(in_features=1280, out_features=1280, bias=False)\n",
      "Module: Linear(in_features=1280, out_features=1280, bias=False)\n",
      "Module: Linear(in_features=1280, out_features=1280, bias=False)\n",
      "Module: Sequential(\n",
      "  (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "  (1): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "Module: Linear(in_features=1280, out_features=1280, bias=True)\n",
      "Module: Dropout(p=0.0, inplace=False)\n",
      "Module: FeedForward(\n",
      "  (net): Sequential(\n",
      "    (0): GEGLU(\n",
      "      (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
      "    )\n",
      "    (1): Dropout(p=0.0, inplace=False)\n",
      "    (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
      "  )\n",
      ")\n",
      "Module: Sequential(\n",
      "  (0): GEGLU(\n",
      "    (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
      "  )\n",
      "  (1): Dropout(p=0.0, inplace=False)\n",
      "  (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
      ")\n",
      "Module: GEGLU(\n",
      "  (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
      ")\n",
      "Module: Linear(in_features=1280, out_features=10240, bias=True)\n",
      "Module: Dropout(p=0.0, inplace=False)\n",
      "Module: Linear(in_features=5120, out_features=1280, bias=True)\n",
      "Module: CrossAttention(\n",
      "  (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "  (to_k): Linear(in_features=768, out_features=1280, bias=False)\n",
      "  (to_v): Linear(in_features=768, out_features=1280, bias=False)\n",
      "  (to_out): Sequential(\n",
      "    (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "    (1): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      ")\n",
      "Module: Linear(in_features=1280, out_features=1280, bias=False)\n",
      "Module: Linear(in_features=768, out_features=1280, bias=False)\n",
      "Module: Linear(in_features=768, out_features=1280, bias=False)\n",
      "Module: Sequential(\n",
      "  (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "  (1): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "Module: Linear(in_features=1280, out_features=1280, bias=True)\n",
      "Module: Dropout(p=0.0, inplace=False)\n",
      "Module: LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "Module: LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "Module: LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "Module: Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
      "Module: TimestepEmbedSequential(\n",
      "  (0): ResBlock(\n",
      "    (in_layers): Sequential(\n",
      "      (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
      "      (1): SiLU()\n",
      "      (2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (h_upd): Identity()\n",
      "    (x_upd): Identity()\n",
      "    (emb_layers): Sequential(\n",
      "      (0): SiLU()\n",
      "      (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "    )\n",
      "    (out_layers): Sequential(\n",
      "      (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
      "      (1): SiLU()\n",
      "      (2): Dropout(p=0, inplace=False)\n",
      "      (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (skip_connection): Identity()\n",
      "  )\n",
      "  (1): SpatialTransformer(\n",
      "    (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
      "    (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (transformer_blocks): ModuleList(\n",
      "      (0): BasicTransformerBlock(\n",
      "        (attn1): CrossAttention(\n",
      "          (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "          (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "          (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "          (to_out): Sequential(\n",
      "            (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "            (1): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (ff): FeedForward(\n",
      "          (net): Sequential(\n",
      "            (0): GEGLU(\n",
      "              (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
      "            )\n",
      "            (1): Dropout(p=0.0, inplace=False)\n",
      "            (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
      "          )\n",
      "        )\n",
      "        (attn2): CrossAttention(\n",
      "          (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "          (to_k): Linear(in_features=768, out_features=1280, bias=False)\n",
      "          (to_v): Linear(in_features=768, out_features=1280, bias=False)\n",
      "          (to_out): Sequential(\n",
      "            (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "            (1): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n",
      "Module: ResBlock(\n",
      "  (in_layers): Sequential(\n",
      "    (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
      "    (1): SiLU()\n",
      "    (2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (h_upd): Identity()\n",
      "  (x_upd): Identity()\n",
      "  (emb_layers): Sequential(\n",
      "    (0): SiLU()\n",
      "    (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "  )\n",
      "  (out_layers): Sequential(\n",
      "    (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
      "    (1): SiLU()\n",
      "    (2): Dropout(p=0, inplace=False)\n",
      "    (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (skip_connection): Identity()\n",
      ")\n",
      "Module: Sequential(\n",
      "  (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
      "  (1): SiLU()\n",
      "  (2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")\n",
      "Module: GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
      "Module: SiLU()\n",
      "Module: Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "Module: Identity()\n",
      "Module: Sequential(\n",
      "  (0): SiLU()\n",
      "  (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
      ")\n",
      "Module: SiLU()\n",
      "Module: Linear(in_features=1280, out_features=1280, bias=True)\n",
      "Module: Sequential(\n",
      "  (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
      "  (1): SiLU()\n",
      "  (2): Dropout(p=0, inplace=False)\n",
      "  (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")\n",
      "Module: GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
      "Module: SiLU()\n",
      "Module: Dropout(p=0, inplace=False)\n",
      "Module: Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "Module: Identity()\n",
      "Module: SpatialTransformer(\n",
      "  (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
      "  (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (transformer_blocks): ModuleList(\n",
      "    (0): BasicTransformerBlock(\n",
      "      (attn1): CrossAttention(\n",
      "        (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "        (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "        (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "        (to_out): Sequential(\n",
      "          (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (1): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (net): Sequential(\n",
      "          (0): GEGLU(\n",
      "            (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
      "          )\n",
      "          (1): Dropout(p=0.0, inplace=False)\n",
      "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (attn2): CrossAttention(\n",
      "        (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "        (to_k): Linear(in_features=768, out_features=1280, bias=False)\n",
      "        (to_v): Linear(in_features=768, out_features=1280, bias=False)\n",
      "        (to_out): Sequential(\n",
      "          (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (1): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "      (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
      ")\n",
      "Module: GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
      "Module: Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
      "Module: ModuleList(\n",
      "  (0): BasicTransformerBlock(\n",
      "    (attn1): CrossAttention(\n",
      "      (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "      (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "      (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "      (to_out): Sequential(\n",
      "        (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "        (1): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (ff): FeedForward(\n",
      "      (net): Sequential(\n",
      "        (0): GEGLU(\n",
      "          (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
      "        )\n",
      "        (1): Dropout(p=0.0, inplace=False)\n",
      "        (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (attn2): CrossAttention(\n",
      "      (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "      (to_k): Linear(in_features=768, out_features=1280, bias=False)\n",
      "      (to_v): Linear(in_features=768, out_features=1280, bias=False)\n",
      "      (to_out): Sequential(\n",
      "        (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "        (1): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "    (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "    (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      ")\n",
      "Module: BasicTransformerBlock(\n",
      "  (attn1): CrossAttention(\n",
      "    (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "    (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "    (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "    (to_out): Sequential(\n",
      "      (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "      (1): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (ff): FeedForward(\n",
      "    (net): Sequential(\n",
      "      (0): GEGLU(\n",
      "        (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
      "      )\n",
      "      (1): Dropout(p=0.0, inplace=False)\n",
      "      (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (attn2): CrossAttention(\n",
      "    (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "    (to_k): Linear(in_features=768, out_features=1280, bias=False)\n",
      "    (to_v): Linear(in_features=768, out_features=1280, bias=False)\n",
      "    (to_out): Sequential(\n",
      "      (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "      (1): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "  (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "  (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      ")\n",
      "Module: CrossAttention(\n",
      "  (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "  (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "  (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "  (to_out): Sequential(\n",
      "    (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "    (1): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      ")\n",
      "Module: Linear(in_features=1280, out_features=1280, bias=False)\n",
      "Module: Linear(in_features=1280, out_features=1280, bias=False)\n",
      "Module: Linear(in_features=1280, out_features=1280, bias=False)\n",
      "Module: Sequential(\n",
      "  (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "  (1): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "Module: Linear(in_features=1280, out_features=1280, bias=True)\n",
      "Module: Dropout(p=0.0, inplace=False)\n",
      "Module: FeedForward(\n",
      "  (net): Sequential(\n",
      "    (0): GEGLU(\n",
      "      (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
      "    )\n",
      "    (1): Dropout(p=0.0, inplace=False)\n",
      "    (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
      "  )\n",
      ")\n",
      "Module: Sequential(\n",
      "  (0): GEGLU(\n",
      "    (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
      "  )\n",
      "  (1): Dropout(p=0.0, inplace=False)\n",
      "  (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
      ")\n",
      "Module: GEGLU(\n",
      "  (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
      ")\n",
      "Module: Linear(in_features=1280, out_features=10240, bias=True)\n",
      "Module: Dropout(p=0.0, inplace=False)\n",
      "Module: Linear(in_features=5120, out_features=1280, bias=True)\n",
      "Module: CrossAttention(\n",
      "  (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "  (to_k): Linear(in_features=768, out_features=1280, bias=False)\n",
      "  (to_v): Linear(in_features=768, out_features=1280, bias=False)\n",
      "  (to_out): Sequential(\n",
      "    (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "    (1): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      ")\n",
      "Module: Linear(in_features=1280, out_features=1280, bias=False)\n",
      "Module: Linear(in_features=768, out_features=1280, bias=False)\n",
      "Module: Linear(in_features=768, out_features=1280, bias=False)\n",
      "Module: Sequential(\n",
      "  (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "  (1): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "Module: Linear(in_features=1280, out_features=1280, bias=True)\n",
      "Module: Dropout(p=0.0, inplace=False)\n",
      "Module: LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "Module: LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "Module: LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "Module: Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
      "Module: TimestepEmbedSequential(\n",
      "  (0): Downsample(\n",
      "    (op): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "  )\n",
      ")\n",
      "Module: Downsample(\n",
      "  (op): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      ")\n",
      "Module: Conv2d(1280, 1280, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "Module: TimestepEmbedSequential(\n",
      "  (0): ResBlock(\n",
      "    (in_layers): Sequential(\n",
      "      (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
      "      (1): SiLU()\n",
      "      (2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (h_upd): Identity()\n",
      "    (x_upd): Identity()\n",
      "    (emb_layers): Sequential(\n",
      "      (0): SiLU()\n",
      "      (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "    )\n",
      "    (out_layers): Sequential(\n",
      "      (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
      "      (1): SiLU()\n",
      "      (2): Dropout(p=0, inplace=False)\n",
      "      (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (skip_connection): Identity()\n",
      "  )\n",
      ")\n",
      "Module: ResBlock(\n",
      "  (in_layers): Sequential(\n",
      "    (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
      "    (1): SiLU()\n",
      "    (2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (h_upd): Identity()\n",
      "  (x_upd): Identity()\n",
      "  (emb_layers): Sequential(\n",
      "    (0): SiLU()\n",
      "    (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "  )\n",
      "  (out_layers): Sequential(\n",
      "    (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
      "    (1): SiLU()\n",
      "    (2): Dropout(p=0, inplace=False)\n",
      "    (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (skip_connection): Identity()\n",
      ")\n",
      "Module: Sequential(\n",
      "  (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
      "  (1): SiLU()\n",
      "  (2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")\n",
      "Module: GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
      "Module: SiLU()\n",
      "Module: Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "Module: Identity()\n",
      "Module: Sequential(\n",
      "  (0): SiLU()\n",
      "  (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
      ")\n",
      "Module: SiLU()\n",
      "Module: Linear(in_features=1280, out_features=1280, bias=True)\n",
      "Module: Sequential(\n",
      "  (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
      "  (1): SiLU()\n",
      "  (2): Dropout(p=0, inplace=False)\n",
      "  (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")\n",
      "Module: GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
      "Module: SiLU()\n",
      "Module: Dropout(p=0, inplace=False)\n",
      "Module: Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "Module: Identity()\n",
      "Module: TimestepEmbedSequential(\n",
      "  (0): ResBlock(\n",
      "    (in_layers): Sequential(\n",
      "      (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
      "      (1): SiLU()\n",
      "      (2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (h_upd): Identity()\n",
      "    (x_upd): Identity()\n",
      "    (emb_layers): Sequential(\n",
      "      (0): SiLU()\n",
      "      (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "    )\n",
      "    (out_layers): Sequential(\n",
      "      (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
      "      (1): SiLU()\n",
      "      (2): Dropout(p=0, inplace=False)\n",
      "      (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (skip_connection): Identity()\n",
      "  )\n",
      ")\n",
      "Module: ResBlock(\n",
      "  (in_layers): Sequential(\n",
      "    (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
      "    (1): SiLU()\n",
      "    (2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (h_upd): Identity()\n",
      "  (x_upd): Identity()\n",
      "  (emb_layers): Sequential(\n",
      "    (0): SiLU()\n",
      "    (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "  )\n",
      "  (out_layers): Sequential(\n",
      "    (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
      "    (1): SiLU()\n",
      "    (2): Dropout(p=0, inplace=False)\n",
      "    (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (skip_connection): Identity()\n",
      ")\n",
      "Module: Sequential(\n",
      "  (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
      "  (1): SiLU()\n",
      "  (2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")\n",
      "Module: GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
      "Module: SiLU()\n",
      "Module: Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "Module: Identity()\n",
      "Module: Sequential(\n",
      "  (0): SiLU()\n",
      "  (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
      ")\n",
      "Module: SiLU()\n",
      "Module: Linear(in_features=1280, out_features=1280, bias=True)\n",
      "Module: Sequential(\n",
      "  (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
      "  (1): SiLU()\n",
      "  (2): Dropout(p=0, inplace=False)\n",
      "  (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")\n",
      "Module: GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
      "Module: SiLU()\n",
      "Module: Dropout(p=0, inplace=False)\n",
      "Module: Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "Module: Identity()\n",
      "Module: TimestepEmbedSequential(\n",
      "  (0): ResBlock(\n",
      "    (in_layers): Sequential(\n",
      "      (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
      "      (1): SiLU()\n",
      "      (2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (h_upd): Identity()\n",
      "    (x_upd): Identity()\n",
      "    (emb_layers): Sequential(\n",
      "      (0): SiLU()\n",
      "      (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "    )\n",
      "    (out_layers): Sequential(\n",
      "      (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
      "      (1): SiLU()\n",
      "      (2): Dropout(p=0, inplace=False)\n",
      "      (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (skip_connection): Identity()\n",
      "  )\n",
      "  (1): SpatialTransformer(\n",
      "    (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
      "    (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (transformer_blocks): ModuleList(\n",
      "      (0): BasicTransformerBlock(\n",
      "        (attn1): CrossAttention(\n",
      "          (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "          (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "          (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "          (to_out): Sequential(\n",
      "            (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "            (1): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (ff): FeedForward(\n",
      "          (net): Sequential(\n",
      "            (0): GEGLU(\n",
      "              (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
      "            )\n",
      "            (1): Dropout(p=0.0, inplace=False)\n",
      "            (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
      "          )\n",
      "        )\n",
      "        (attn2): CrossAttention(\n",
      "          (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "          (to_k): Linear(in_features=768, out_features=1280, bias=False)\n",
      "          (to_v): Linear(in_features=768, out_features=1280, bias=False)\n",
      "          (to_out): Sequential(\n",
      "            (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "            (1): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (2): ResBlock(\n",
      "    (in_layers): Sequential(\n",
      "      (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
      "      (1): SiLU()\n",
      "      (2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (h_upd): Identity()\n",
      "    (x_upd): Identity()\n",
      "    (emb_layers): Sequential(\n",
      "      (0): SiLU()\n",
      "      (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "    )\n",
      "    (out_layers): Sequential(\n",
      "      (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
      "      (1): SiLU()\n",
      "      (2): Dropout(p=0, inplace=False)\n",
      "      (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (skip_connection): Identity()\n",
      "  )\n",
      ")\n",
      "Module: ResBlock(\n",
      "  (in_layers): Sequential(\n",
      "    (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
      "    (1): SiLU()\n",
      "    (2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (h_upd): Identity()\n",
      "  (x_upd): Identity()\n",
      "  (emb_layers): Sequential(\n",
      "    (0): SiLU()\n",
      "    (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "  )\n",
      "  (out_layers): Sequential(\n",
      "    (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
      "    (1): SiLU()\n",
      "    (2): Dropout(p=0, inplace=False)\n",
      "    (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (skip_connection): Identity()\n",
      ")\n",
      "Module: Sequential(\n",
      "  (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
      "  (1): SiLU()\n",
      "  (2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")\n",
      "Module: GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
      "Module: SiLU()\n",
      "Module: Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "Module: Identity()\n",
      "Module: Sequential(\n",
      "  (0): SiLU()\n",
      "  (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
      ")\n",
      "Module: SiLU()\n",
      "Module: Linear(in_features=1280, out_features=1280, bias=True)\n",
      "Module: Sequential(\n",
      "  (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
      "  (1): SiLU()\n",
      "  (2): Dropout(p=0, inplace=False)\n",
      "  (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")\n",
      "Module: GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
      "Module: SiLU()\n",
      "Module: Dropout(p=0, inplace=False)\n",
      "Module: Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "Module: Identity()\n",
      "Module: SpatialTransformer(\n",
      "  (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
      "  (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (transformer_blocks): ModuleList(\n",
      "    (0): BasicTransformerBlock(\n",
      "      (attn1): CrossAttention(\n",
      "        (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "        (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "        (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "        (to_out): Sequential(\n",
      "          (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (1): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (net): Sequential(\n",
      "          (0): GEGLU(\n",
      "            (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
      "          )\n",
      "          (1): Dropout(p=0.0, inplace=False)\n",
      "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (attn2): CrossAttention(\n",
      "        (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "        (to_k): Linear(in_features=768, out_features=1280, bias=False)\n",
      "        (to_v): Linear(in_features=768, out_features=1280, bias=False)\n",
      "        (to_out): Sequential(\n",
      "          (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (1): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "      (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
      ")\n",
      "Module: GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
      "Module: Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
      "Module: ModuleList(\n",
      "  (0): BasicTransformerBlock(\n",
      "    (attn1): CrossAttention(\n",
      "      (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "      (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "      (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "      (to_out): Sequential(\n",
      "        (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "        (1): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (ff): FeedForward(\n",
      "      (net): Sequential(\n",
      "        (0): GEGLU(\n",
      "          (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
      "        )\n",
      "        (1): Dropout(p=0.0, inplace=False)\n",
      "        (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (attn2): CrossAttention(\n",
      "      (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "      (to_k): Linear(in_features=768, out_features=1280, bias=False)\n",
      "      (to_v): Linear(in_features=768, out_features=1280, bias=False)\n",
      "      (to_out): Sequential(\n",
      "        (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "        (1): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "    (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "    (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      ")\n",
      "Module: BasicTransformerBlock(\n",
      "  (attn1): CrossAttention(\n",
      "    (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "    (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "    (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "    (to_out): Sequential(\n",
      "      (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "      (1): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (ff): FeedForward(\n",
      "    (net): Sequential(\n",
      "      (0): GEGLU(\n",
      "        (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
      "      )\n",
      "      (1): Dropout(p=0.0, inplace=False)\n",
      "      (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (attn2): CrossAttention(\n",
      "    (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "    (to_k): Linear(in_features=768, out_features=1280, bias=False)\n",
      "    (to_v): Linear(in_features=768, out_features=1280, bias=False)\n",
      "    (to_out): Sequential(\n",
      "      (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "      (1): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "  (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "  (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      ")\n",
      "Module: CrossAttention(\n",
      "  (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "  (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "  (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "  (to_out): Sequential(\n",
      "    (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "    (1): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      ")\n",
      "Module: Linear(in_features=1280, out_features=1280, bias=False)\n",
      "Module: Linear(in_features=1280, out_features=1280, bias=False)\n",
      "Module: Linear(in_features=1280, out_features=1280, bias=False)\n",
      "Module: Sequential(\n",
      "  (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "  (1): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "Module: Linear(in_features=1280, out_features=1280, bias=True)\n",
      "Module: Dropout(p=0.0, inplace=False)\n",
      "Module: FeedForward(\n",
      "  (net): Sequential(\n",
      "    (0): GEGLU(\n",
      "      (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
      "    )\n",
      "    (1): Dropout(p=0.0, inplace=False)\n",
      "    (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
      "  )\n",
      ")\n",
      "Module: Sequential(\n",
      "  (0): GEGLU(\n",
      "    (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
      "  )\n",
      "  (1): Dropout(p=0.0, inplace=False)\n",
      "  (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
      ")\n",
      "Module: GEGLU(\n",
      "  (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
      ")\n",
      "Module: Linear(in_features=1280, out_features=10240, bias=True)\n",
      "Module: Dropout(p=0.0, inplace=False)\n",
      "Module: Linear(in_features=5120, out_features=1280, bias=True)\n",
      "Module: CrossAttention(\n",
      "  (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "  (to_k): Linear(in_features=768, out_features=1280, bias=False)\n",
      "  (to_v): Linear(in_features=768, out_features=1280, bias=False)\n",
      "  (to_out): Sequential(\n",
      "    (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "    (1): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      ")\n",
      "Module: Linear(in_features=1280, out_features=1280, bias=False)\n",
      "Module: Linear(in_features=768, out_features=1280, bias=False)\n",
      "Module: Linear(in_features=768, out_features=1280, bias=False)\n",
      "Module: Sequential(\n",
      "  (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "  (1): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "Module: Linear(in_features=1280, out_features=1280, bias=True)\n",
      "Module: Dropout(p=0.0, inplace=False)\n",
      "Module: LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "Module: LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "Module: LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "Module: Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
      "Module: ResBlock(\n",
      "  (in_layers): Sequential(\n",
      "    (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
      "    (1): SiLU()\n",
      "    (2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (h_upd): Identity()\n",
      "  (x_upd): Identity()\n",
      "  (emb_layers): Sequential(\n",
      "    (0): SiLU()\n",
      "    (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "  )\n",
      "  (out_layers): Sequential(\n",
      "    (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
      "    (1): SiLU()\n",
      "    (2): Dropout(p=0, inplace=False)\n",
      "    (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (skip_connection): Identity()\n",
      ")\n",
      "Module: Sequential(\n",
      "  (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
      "  (1): SiLU()\n",
      "  (2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")\n",
      "Module: GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
      "Module: SiLU()\n",
      "Module: Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "Module: Identity()\n",
      "Module: Sequential(\n",
      "  (0): SiLU()\n",
      "  (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
      ")\n",
      "Module: SiLU()\n",
      "Module: Linear(in_features=1280, out_features=1280, bias=True)\n",
      "Module: Sequential(\n",
      "  (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
      "  (1): SiLU()\n",
      "  (2): Dropout(p=0, inplace=False)\n",
      "  (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")\n",
      "Module: GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
      "Module: SiLU()\n",
      "Module: Dropout(p=0, inplace=False)\n",
      "Module: Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "Module: Identity()\n",
      "Module: ModuleList(\n",
      "  (0-1): 2 x TimestepEmbedSequential(\n",
      "    (0): ResBlock(\n",
      "      (in_layers): Sequential(\n",
      "        (0): GroupNorm32(32, 2560, eps=1e-05, affine=True)\n",
      "        (1): SiLU()\n",
      "        (2): Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (h_upd): Identity()\n",
      "      (x_upd): Identity()\n",
      "      (emb_layers): Sequential(\n",
      "        (0): SiLU()\n",
      "        (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "      )\n",
      "      (out_layers): Sequential(\n",
      "        (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
      "        (1): SiLU()\n",
      "        (2): Dropout(p=0, inplace=False)\n",
      "        (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (skip_connection): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  (2): TimestepEmbedSequential(\n",
      "    (0): ResBlock(\n",
      "      (in_layers): Sequential(\n",
      "        (0): GroupNorm32(32, 2560, eps=1e-05, affine=True)\n",
      "        (1): SiLU()\n",
      "        (2): Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (h_upd): Identity()\n",
      "      (x_upd): Identity()\n",
      "      (emb_layers): Sequential(\n",
      "        (0): SiLU()\n",
      "        (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "      )\n",
      "      (out_layers): Sequential(\n",
      "        (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
      "        (1): SiLU()\n",
      "        (2): Dropout(p=0, inplace=False)\n",
      "        (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (skip_connection): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (1): Upsample(\n",
      "      (conv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  (3-4): 2 x TimestepEmbedSequential(\n",
      "    (0): ResBlock(\n",
      "      (in_layers): Sequential(\n",
      "        (0): GroupNorm32(32, 2560, eps=1e-05, affine=True)\n",
      "        (1): SiLU()\n",
      "        (2): Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (h_upd): Identity()\n",
      "      (x_upd): Identity()\n",
      "      (emb_layers): Sequential(\n",
      "        (0): SiLU()\n",
      "        (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "      )\n",
      "      (out_layers): Sequential(\n",
      "        (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
      "        (1): SiLU()\n",
      "        (2): Dropout(p=0, inplace=False)\n",
      "        (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (skip_connection): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (1): SpatialTransformer(\n",
      "      (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
      "      (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (transformer_blocks): ModuleList(\n",
      "        (0): BasicTransformerBlock(\n",
      "          (attn1): CrossAttention(\n",
      "            (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "            (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "            (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "            (to_out): Sequential(\n",
      "              (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "              (1): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (ff): FeedForward(\n",
      "            (net): Sequential(\n",
      "              (0): GEGLU(\n",
      "                (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
      "              )\n",
      "              (1): Dropout(p=0.0, inplace=False)\n",
      "              (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (attn2): CrossAttention(\n",
      "            (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "            (to_k): Linear(in_features=768, out_features=1280, bias=False)\n",
      "            (to_v): Linear(in_features=768, out_features=1280, bias=False)\n",
      "            (to_out): Sequential(\n",
      "              (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "              (1): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "      (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  (5): TimestepEmbedSequential(\n",
      "    (0): ResBlock(\n",
      "      (in_layers): Sequential(\n",
      "        (0): GroupNorm32(32, 1920, eps=1e-05, affine=True)\n",
      "        (1): SiLU()\n",
      "        (2): Conv2d(1920, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (h_upd): Identity()\n",
      "      (x_upd): Identity()\n",
      "      (emb_layers): Sequential(\n",
      "        (0): SiLU()\n",
      "        (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "      )\n",
      "      (out_layers): Sequential(\n",
      "        (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
      "        (1): SiLU()\n",
      "        (2): Dropout(p=0, inplace=False)\n",
      "        (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (skip_connection): Conv2d(1920, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (1): SpatialTransformer(\n",
      "      (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
      "      (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (transformer_blocks): ModuleList(\n",
      "        (0): BasicTransformerBlock(\n",
      "          (attn1): CrossAttention(\n",
      "            (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "            (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "            (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "            (to_out): Sequential(\n",
      "              (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "              (1): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (ff): FeedForward(\n",
      "            (net): Sequential(\n",
      "              (0): GEGLU(\n",
      "                (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
      "              )\n",
      "              (1): Dropout(p=0.0, inplace=False)\n",
      "              (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (attn2): CrossAttention(\n",
      "            (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "            (to_k): Linear(in_features=768, out_features=1280, bias=False)\n",
      "            (to_v): Linear(in_features=768, out_features=1280, bias=False)\n",
      "            (to_out): Sequential(\n",
      "              (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "              (1): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "      (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (2): Upsample(\n",
      "      (conv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  (6): TimestepEmbedSequential(\n",
      "    (0): ResBlock(\n",
      "      (in_layers): Sequential(\n",
      "        (0): GroupNorm32(32, 1920, eps=1e-05, affine=True)\n",
      "        (1): SiLU()\n",
      "        (2): Conv2d(1920, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (h_upd): Identity()\n",
      "      (x_upd): Identity()\n",
      "      (emb_layers): Sequential(\n",
      "        (0): SiLU()\n",
      "        (1): Linear(in_features=1280, out_features=640, bias=True)\n",
      "      )\n",
      "      (out_layers): Sequential(\n",
      "        (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
      "        (1): SiLU()\n",
      "        (2): Dropout(p=0, inplace=False)\n",
      "        (3): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (skip_connection): Conv2d(1920, 640, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (1): SpatialTransformer(\n",
      "      (norm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
      "      (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (transformer_blocks): ModuleList(\n",
      "        (0): BasicTransformerBlock(\n",
      "          (attn1): CrossAttention(\n",
      "            (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
      "            (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
      "            (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
      "            (to_out): Sequential(\n",
      "              (0): Linear(in_features=640, out_features=640, bias=True)\n",
      "              (1): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (ff): FeedForward(\n",
      "            (net): Sequential(\n",
      "              (0): GEGLU(\n",
      "                (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
      "              )\n",
      "              (1): Dropout(p=0.0, inplace=False)\n",
      "              (2): Linear(in_features=2560, out_features=640, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (attn2): CrossAttention(\n",
      "            (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
      "            (to_k): Linear(in_features=768, out_features=640, bias=False)\n",
      "            (to_v): Linear(in_features=768, out_features=640, bias=False)\n",
      "            (to_out): Sequential(\n",
      "              (0): Linear(in_features=640, out_features=640, bias=True)\n",
      "              (1): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "      (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  (7): TimestepEmbedSequential(\n",
      "    (0): ResBlock(\n",
      "      (in_layers): Sequential(\n",
      "        (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
      "        (1): SiLU()\n",
      "        (2): Conv2d(1280, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (h_upd): Identity()\n",
      "      (x_upd): Identity()\n",
      "      (emb_layers): Sequential(\n",
      "        (0): SiLU()\n",
      "        (1): Linear(in_features=1280, out_features=640, bias=True)\n",
      "      )\n",
      "      (out_layers): Sequential(\n",
      "        (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
      "        (1): SiLU()\n",
      "        (2): Dropout(p=0, inplace=False)\n",
      "        (3): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (skip_connection): Conv2d(1280, 640, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (1): SpatialTransformer(\n",
      "      (norm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
      "      (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (transformer_blocks): ModuleList(\n",
      "        (0): BasicTransformerBlock(\n",
      "          (attn1): CrossAttention(\n",
      "            (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
      "            (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
      "            (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
      "            (to_out): Sequential(\n",
      "              (0): Linear(in_features=640, out_features=640, bias=True)\n",
      "              (1): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (ff): FeedForward(\n",
      "            (net): Sequential(\n",
      "              (0): GEGLU(\n",
      "                (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
      "              )\n",
      "              (1): Dropout(p=0.0, inplace=False)\n",
      "              (2): Linear(in_features=2560, out_features=640, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (attn2): CrossAttention(\n",
      "            (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
      "            (to_k): Linear(in_features=768, out_features=640, bias=False)\n",
      "            (to_v): Linear(in_features=768, out_features=640, bias=False)\n",
      "            (to_out): Sequential(\n",
      "              (0): Linear(in_features=640, out_features=640, bias=True)\n",
      "              (1): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "      (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  (8): TimestepEmbedSequential(\n",
      "    (0): ResBlock(\n",
      "      (in_layers): Sequential(\n",
      "        (0): GroupNorm32(32, 960, eps=1e-05, affine=True)\n",
      "        (1): SiLU()\n",
      "        (2): Conv2d(960, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (h_upd): Identity()\n",
      "      (x_upd): Identity()\n",
      "      (emb_layers): Sequential(\n",
      "        (0): SiLU()\n",
      "        (1): Linear(in_features=1280, out_features=640, bias=True)\n",
      "      )\n",
      "      (out_layers): Sequential(\n",
      "        (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
      "        (1): SiLU()\n",
      "        (2): Dropout(p=0, inplace=False)\n",
      "        (3): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (skip_connection): Conv2d(960, 640, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (1): SpatialTransformer(\n",
      "      (norm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
      "      (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (transformer_blocks): ModuleList(\n",
      "        (0): BasicTransformerBlock(\n",
      "          (attn1): CrossAttention(\n",
      "            (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
      "            (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
      "            (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
      "            (to_out): Sequential(\n",
      "              (0): Linear(in_features=640, out_features=640, bias=True)\n",
      "              (1): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (ff): FeedForward(\n",
      "            (net): Sequential(\n",
      "              (0): GEGLU(\n",
      "                (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
      "              )\n",
      "              (1): Dropout(p=0.0, inplace=False)\n",
      "              (2): Linear(in_features=2560, out_features=640, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (attn2): CrossAttention(\n",
      "            (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
      "            (to_k): Linear(in_features=768, out_features=640, bias=False)\n",
      "            (to_v): Linear(in_features=768, out_features=640, bias=False)\n",
      "            (to_out): Sequential(\n",
      "              (0): Linear(in_features=640, out_features=640, bias=True)\n",
      "              (1): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "      (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (2): Upsample(\n",
      "      (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  (9): TimestepEmbedSequential(\n",
      "    (0): ResBlock(\n",
      "      (in_layers): Sequential(\n",
      "        (0): GroupNorm32(32, 960, eps=1e-05, affine=True)\n",
      "        (1): SiLU()\n",
      "        (2): Conv2d(960, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (h_upd): Identity()\n",
      "      (x_upd): Identity()\n",
      "      (emb_layers): Sequential(\n",
      "        (0): SiLU()\n",
      "        (1): Linear(in_features=1280, out_features=320, bias=True)\n",
      "      )\n",
      "      (out_layers): Sequential(\n",
      "        (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
      "        (1): SiLU()\n",
      "        (2): Dropout(p=0, inplace=False)\n",
      "        (3): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (skip_connection): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (1): SpatialTransformer(\n",
      "      (norm): GroupNorm(32, 320, eps=1e-06, affine=True)\n",
      "      (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (transformer_blocks): ModuleList(\n",
      "        (0): BasicTransformerBlock(\n",
      "          (attn1): CrossAttention(\n",
      "            (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
      "            (to_k): Linear(in_features=320, out_features=320, bias=False)\n",
      "            (to_v): Linear(in_features=320, out_features=320, bias=False)\n",
      "            (to_out): Sequential(\n",
      "              (0): Linear(in_features=320, out_features=320, bias=True)\n",
      "              (1): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (ff): FeedForward(\n",
      "            (net): Sequential(\n",
      "              (0): GEGLU(\n",
      "                (proj): Linear(in_features=320, out_features=2560, bias=True)\n",
      "              )\n",
      "              (1): Dropout(p=0.0, inplace=False)\n",
      "              (2): Linear(in_features=1280, out_features=320, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (attn2): CrossAttention(\n",
      "            (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
      "            (to_k): Linear(in_features=768, out_features=320, bias=False)\n",
      "            (to_v): Linear(in_features=768, out_features=320, bias=False)\n",
      "            (to_out): Sequential(\n",
      "              (0): Linear(in_features=320, out_features=320, bias=True)\n",
      "              (1): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "      (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  (10-11): 2 x TimestepEmbedSequential(\n",
      "    (0): ResBlock(\n",
      "      (in_layers): Sequential(\n",
      "        (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
      "        (1): SiLU()\n",
      "        (2): Conv2d(640, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (h_upd): Identity()\n",
      "      (x_upd): Identity()\n",
      "      (emb_layers): Sequential(\n",
      "        (0): SiLU()\n",
      "        (1): Linear(in_features=1280, out_features=320, bias=True)\n",
      "      )\n",
      "      (out_layers): Sequential(\n",
      "        (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
      "        (1): SiLU()\n",
      "        (2): Dropout(p=0, inplace=False)\n",
      "        (3): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (skip_connection): Conv2d(640, 320, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (1): SpatialTransformer(\n",
      "      (norm): GroupNorm(32, 320, eps=1e-06, affine=True)\n",
      "      (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (transformer_blocks): ModuleList(\n",
      "        (0): BasicTransformerBlock(\n",
      "          (attn1): CrossAttention(\n",
      "            (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
      "            (to_k): Linear(in_features=320, out_features=320, bias=False)\n",
      "            (to_v): Linear(in_features=320, out_features=320, bias=False)\n",
      "            (to_out): Sequential(\n",
      "              (0): Linear(in_features=320, out_features=320, bias=True)\n",
      "              (1): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (ff): FeedForward(\n",
      "            (net): Sequential(\n",
      "              (0): GEGLU(\n",
      "                (proj): Linear(in_features=320, out_features=2560, bias=True)\n",
      "              )\n",
      "              (1): Dropout(p=0.0, inplace=False)\n",
      "              (2): Linear(in_features=1280, out_features=320, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (attn2): CrossAttention(\n",
      "            (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
      "            (to_k): Linear(in_features=768, out_features=320, bias=False)\n",
      "            (to_v): Linear(in_features=768, out_features=320, bias=False)\n",
      "            (to_out): Sequential(\n",
      "              (0): Linear(in_features=320, out_features=320, bias=True)\n",
      "              (1): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "      (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Module: TimestepEmbedSequential(\n",
      "  (0): ResBlock(\n",
      "    (in_layers): Sequential(\n",
      "      (0): GroupNorm32(32, 2560, eps=1e-05, affine=True)\n",
      "      (1): SiLU()\n",
      "      (2): Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (h_upd): Identity()\n",
      "    (x_upd): Identity()\n",
      "    (emb_layers): Sequential(\n",
      "      (0): SiLU()\n",
      "      (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "    )\n",
      "    (out_layers): Sequential(\n",
      "      (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
      "      (1): SiLU()\n",
      "      (2): Dropout(p=0, inplace=False)\n",
      "      (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (skip_connection): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n",
      "Module: ResBlock(\n",
      "  (in_layers): Sequential(\n",
      "    (0): GroupNorm32(32, 2560, eps=1e-05, affine=True)\n",
      "    (1): SiLU()\n",
      "    (2): Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (h_upd): Identity()\n",
      "  (x_upd): Identity()\n",
      "  (emb_layers): Sequential(\n",
      "    (0): SiLU()\n",
      "    (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "  )\n",
      "  (out_layers): Sequential(\n",
      "    (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
      "    (1): SiLU()\n",
      "    (2): Dropout(p=0, inplace=False)\n",
      "    (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (skip_connection): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
      ")\n",
      "Module: Sequential(\n",
      "  (0): GroupNorm32(32, 2560, eps=1e-05, affine=True)\n",
      "  (1): SiLU()\n",
      "  (2): Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")\n",
      "Module: GroupNorm32(32, 2560, eps=1e-05, affine=True)\n",
      "Module: SiLU()\n",
      "Module: Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "Module: Identity()\n",
      "Module: Sequential(\n",
      "  (0): SiLU()\n",
      "  (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
      ")\n",
      "Module: SiLU()\n",
      "Module: Linear(in_features=1280, out_features=1280, bias=True)\n",
      "Module: Sequential(\n",
      "  (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
      "  (1): SiLU()\n",
      "  (2): Dropout(p=0, inplace=False)\n",
      "  (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")\n",
      "Module: GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
      "Module: SiLU()\n",
      "Module: Dropout(p=0, inplace=False)\n",
      "Module: Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "Module: Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
      "Module: TimestepEmbedSequential(\n",
      "  (0): ResBlock(\n",
      "    (in_layers): Sequential(\n",
      "      (0): GroupNorm32(32, 2560, eps=1e-05, affine=True)\n",
      "      (1): SiLU()\n",
      "      (2): Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (h_upd): Identity()\n",
      "    (x_upd): Identity()\n",
      "    (emb_layers): Sequential(\n",
      "      (0): SiLU()\n",
      "      (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "    )\n",
      "    (out_layers): Sequential(\n",
      "      (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
      "      (1): SiLU()\n",
      "      (2): Dropout(p=0, inplace=False)\n",
      "      (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (skip_connection): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n",
      "Module: ResBlock(\n",
      "  (in_layers): Sequential(\n",
      "    (0): GroupNorm32(32, 2560, eps=1e-05, affine=True)\n",
      "    (1): SiLU()\n",
      "    (2): Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (h_upd): Identity()\n",
      "  (x_upd): Identity()\n",
      "  (emb_layers): Sequential(\n",
      "    (0): SiLU()\n",
      "    (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "  )\n",
      "  (out_layers): Sequential(\n",
      "    (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
      "    (1): SiLU()\n",
      "    (2): Dropout(p=0, inplace=False)\n",
      "    (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (skip_connection): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
      ")\n",
      "Module: Sequential(\n",
      "  (0): GroupNorm32(32, 2560, eps=1e-05, affine=True)\n",
      "  (1): SiLU()\n",
      "  (2): Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")\n",
      "Module: GroupNorm32(32, 2560, eps=1e-05, affine=True)\n",
      "Module: SiLU()\n",
      "Module: Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "Module: Identity()\n",
      "Module: Sequential(\n",
      "  (0): SiLU()\n",
      "  (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
      ")\n",
      "Module: SiLU()\n",
      "Module: Linear(in_features=1280, out_features=1280, bias=True)\n",
      "Module: Sequential(\n",
      "  (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
      "  (1): SiLU()\n",
      "  (2): Dropout(p=0, inplace=False)\n",
      "  (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")\n",
      "Module: GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
      "Module: SiLU()\n",
      "Module: Dropout(p=0, inplace=False)\n",
      "Module: Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "Module: Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
      "Module: TimestepEmbedSequential(\n",
      "  (0): ResBlock(\n",
      "    (in_layers): Sequential(\n",
      "      (0): GroupNorm32(32, 2560, eps=1e-05, affine=True)\n",
      "      (1): SiLU()\n",
      "      (2): Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (h_upd): Identity()\n",
      "    (x_upd): Identity()\n",
      "    (emb_layers): Sequential(\n",
      "      (0): SiLU()\n",
      "      (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "    )\n",
      "    (out_layers): Sequential(\n",
      "      (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
      "      (1): SiLU()\n",
      "      (2): Dropout(p=0, inplace=False)\n",
      "      (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (skip_connection): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (1): Upsample(\n",
      "    (conv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      ")\n",
      "Module: ResBlock(\n",
      "  (in_layers): Sequential(\n",
      "    (0): GroupNorm32(32, 2560, eps=1e-05, affine=True)\n",
      "    (1): SiLU()\n",
      "    (2): Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (h_upd): Identity()\n",
      "  (x_upd): Identity()\n",
      "  (emb_layers): Sequential(\n",
      "    (0): SiLU()\n",
      "    (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "  )\n",
      "  (out_layers): Sequential(\n",
      "    (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
      "    (1): SiLU()\n",
      "    (2): Dropout(p=0, inplace=False)\n",
      "    (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (skip_connection): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
      ")\n",
      "Module: Sequential(\n",
      "  (0): GroupNorm32(32, 2560, eps=1e-05, affine=True)\n",
      "  (1): SiLU()\n",
      "  (2): Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")\n",
      "Module: GroupNorm32(32, 2560, eps=1e-05, affine=True)\n",
      "Module: SiLU()\n",
      "Module: Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "Module: Identity()\n",
      "Module: Sequential(\n",
      "  (0): SiLU()\n",
      "  (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
      ")\n",
      "Module: SiLU()\n",
      "Module: Linear(in_features=1280, out_features=1280, bias=True)\n",
      "Module: Sequential(\n",
      "  (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
      "  (1): SiLU()\n",
      "  (2): Dropout(p=0, inplace=False)\n",
      "  (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")\n",
      "Module: GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
      "Module: SiLU()\n",
      "Module: Dropout(p=0, inplace=False)\n",
      "Module: Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "Module: Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
      "Module: Upsample(\n",
      "  (conv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")\n",
      "Module: Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "Module: TimestepEmbedSequential(\n",
      "  (0): ResBlock(\n",
      "    (in_layers): Sequential(\n",
      "      (0): GroupNorm32(32, 2560, eps=1e-05, affine=True)\n",
      "      (1): SiLU()\n",
      "      (2): Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (h_upd): Identity()\n",
      "    (x_upd): Identity()\n",
      "    (emb_layers): Sequential(\n",
      "      (0): SiLU()\n",
      "      (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "    )\n",
      "    (out_layers): Sequential(\n",
      "      (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
      "      (1): SiLU()\n",
      "      (2): Dropout(p=0, inplace=False)\n",
      "      (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (skip_connection): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (1): SpatialTransformer(\n",
      "    (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
      "    (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (transformer_blocks): ModuleList(\n",
      "      (0): BasicTransformerBlock(\n",
      "        (attn1): CrossAttention(\n",
      "          (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "          (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "          (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "          (to_out): Sequential(\n",
      "            (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "            (1): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (ff): FeedForward(\n",
      "          (net): Sequential(\n",
      "            (0): GEGLU(\n",
      "              (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
      "            )\n",
      "            (1): Dropout(p=0.0, inplace=False)\n",
      "            (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
      "          )\n",
      "        )\n",
      "        (attn2): CrossAttention(\n",
      "          (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "          (to_k): Linear(in_features=768, out_features=1280, bias=False)\n",
      "          (to_v): Linear(in_features=768, out_features=1280, bias=False)\n",
      "          (to_out): Sequential(\n",
      "            (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "            (1): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n",
      "Module: ResBlock(\n",
      "  (in_layers): Sequential(\n",
      "    (0): GroupNorm32(32, 2560, eps=1e-05, affine=True)\n",
      "    (1): SiLU()\n",
      "    (2): Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (h_upd): Identity()\n",
      "  (x_upd): Identity()\n",
      "  (emb_layers): Sequential(\n",
      "    (0): SiLU()\n",
      "    (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "  )\n",
      "  (out_layers): Sequential(\n",
      "    (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
      "    (1): SiLU()\n",
      "    (2): Dropout(p=0, inplace=False)\n",
      "    (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (skip_connection): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
      ")\n",
      "Module: Sequential(\n",
      "  (0): GroupNorm32(32, 2560, eps=1e-05, affine=True)\n",
      "  (1): SiLU()\n",
      "  (2): Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")\n",
      "Module: GroupNorm32(32, 2560, eps=1e-05, affine=True)\n",
      "Module: SiLU()\n",
      "Module: Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "Module: Identity()\n",
      "Module: Sequential(\n",
      "  (0): SiLU()\n",
      "  (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
      ")\n",
      "Module: SiLU()\n",
      "Module: Linear(in_features=1280, out_features=1280, bias=True)\n",
      "Module: Sequential(\n",
      "  (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
      "  (1): SiLU()\n",
      "  (2): Dropout(p=0, inplace=False)\n",
      "  (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")\n",
      "Module: GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
      "Module: SiLU()\n",
      "Module: Dropout(p=0, inplace=False)\n",
      "Module: Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "Module: Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
      "Module: SpatialTransformer(\n",
      "  (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
      "  (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (transformer_blocks): ModuleList(\n",
      "    (0): BasicTransformerBlock(\n",
      "      (attn1): CrossAttention(\n",
      "        (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "        (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "        (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "        (to_out): Sequential(\n",
      "          (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (1): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (net): Sequential(\n",
      "          (0): GEGLU(\n",
      "            (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
      "          )\n",
      "          (1): Dropout(p=0.0, inplace=False)\n",
      "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (attn2): CrossAttention(\n",
      "        (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "        (to_k): Linear(in_features=768, out_features=1280, bias=False)\n",
      "        (to_v): Linear(in_features=768, out_features=1280, bias=False)\n",
      "        (to_out): Sequential(\n",
      "          (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (1): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "      (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
      ")\n",
      "Module: GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
      "Module: Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
      "Module: ModuleList(\n",
      "  (0): BasicTransformerBlock(\n",
      "    (attn1): CrossAttention(\n",
      "      (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "      (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "      (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "      (to_out): Sequential(\n",
      "        (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "        (1): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (ff): FeedForward(\n",
      "      (net): Sequential(\n",
      "        (0): GEGLU(\n",
      "          (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
      "        )\n",
      "        (1): Dropout(p=0.0, inplace=False)\n",
      "        (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (attn2): CrossAttention(\n",
      "      (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "      (to_k): Linear(in_features=768, out_features=1280, bias=False)\n",
      "      (to_v): Linear(in_features=768, out_features=1280, bias=False)\n",
      "      (to_out): Sequential(\n",
      "        (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "        (1): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "    (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "    (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      ")\n",
      "Module: BasicTransformerBlock(\n",
      "  (attn1): CrossAttention(\n",
      "    (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "    (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "    (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "    (to_out): Sequential(\n",
      "      (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "      (1): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (ff): FeedForward(\n",
      "    (net): Sequential(\n",
      "      (0): GEGLU(\n",
      "        (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
      "      )\n",
      "      (1): Dropout(p=0.0, inplace=False)\n",
      "      (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (attn2): CrossAttention(\n",
      "    (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "    (to_k): Linear(in_features=768, out_features=1280, bias=False)\n",
      "    (to_v): Linear(in_features=768, out_features=1280, bias=False)\n",
      "    (to_out): Sequential(\n",
      "      (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "      (1): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "  (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "  (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      ")\n",
      "Module: CrossAttention(\n",
      "  (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "  (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "  (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "  (to_out): Sequential(\n",
      "    (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "    (1): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      ")\n",
      "Module: Linear(in_features=1280, out_features=1280, bias=False)\n",
      "Module: Linear(in_features=1280, out_features=1280, bias=False)\n",
      "Module: Linear(in_features=1280, out_features=1280, bias=False)\n",
      "Module: Sequential(\n",
      "  (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "  (1): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "Module: Linear(in_features=1280, out_features=1280, bias=True)\n",
      "Module: Dropout(p=0.0, inplace=False)\n",
      "Module: FeedForward(\n",
      "  (net): Sequential(\n",
      "    (0): GEGLU(\n",
      "      (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
      "    )\n",
      "    (1): Dropout(p=0.0, inplace=False)\n",
      "    (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
      "  )\n",
      ")\n",
      "Module: Sequential(\n",
      "  (0): GEGLU(\n",
      "    (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
      "  )\n",
      "  (1): Dropout(p=0.0, inplace=False)\n",
      "  (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
      ")\n",
      "Module: GEGLU(\n",
      "  (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
      ")\n",
      "Module: Linear(in_features=1280, out_features=10240, bias=True)\n",
      "Module: Dropout(p=0.0, inplace=False)\n",
      "Module: Linear(in_features=5120, out_features=1280, bias=True)\n",
      "Module: CrossAttention(\n",
      "  (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "  (to_k): Linear(in_features=768, out_features=1280, bias=False)\n",
      "  (to_v): Linear(in_features=768, out_features=1280, bias=False)\n",
      "  (to_out): Sequential(\n",
      "    (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "    (1): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      ")\n",
      "Module: Linear(in_features=1280, out_features=1280, bias=False)\n",
      "Module: Linear(in_features=768, out_features=1280, bias=False)\n",
      "Module: Linear(in_features=768, out_features=1280, bias=False)\n",
      "Module: Sequential(\n",
      "  (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "  (1): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "Module: Linear(in_features=1280, out_features=1280, bias=True)\n",
      "Module: Dropout(p=0.0, inplace=False)\n",
      "Module: LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "Module: LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "Module: LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "Module: Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
      "Module: TimestepEmbedSequential(\n",
      "  (0): ResBlock(\n",
      "    (in_layers): Sequential(\n",
      "      (0): GroupNorm32(32, 2560, eps=1e-05, affine=True)\n",
      "      (1): SiLU()\n",
      "      (2): Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (h_upd): Identity()\n",
      "    (x_upd): Identity()\n",
      "    (emb_layers): Sequential(\n",
      "      (0): SiLU()\n",
      "      (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "    )\n",
      "    (out_layers): Sequential(\n",
      "      (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
      "      (1): SiLU()\n",
      "      (2): Dropout(p=0, inplace=False)\n",
      "      (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (skip_connection): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (1): SpatialTransformer(\n",
      "    (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
      "    (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (transformer_blocks): ModuleList(\n",
      "      (0): BasicTransformerBlock(\n",
      "        (attn1): CrossAttention(\n",
      "          (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "          (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "          (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "          (to_out): Sequential(\n",
      "            (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "            (1): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (ff): FeedForward(\n",
      "          (net): Sequential(\n",
      "            (0): GEGLU(\n",
      "              (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
      "            )\n",
      "            (1): Dropout(p=0.0, inplace=False)\n",
      "            (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
      "          )\n",
      "        )\n",
      "        (attn2): CrossAttention(\n",
      "          (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "          (to_k): Linear(in_features=768, out_features=1280, bias=False)\n",
      "          (to_v): Linear(in_features=768, out_features=1280, bias=False)\n",
      "          (to_out): Sequential(\n",
      "            (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "            (1): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n",
      "Module: ResBlock(\n",
      "  (in_layers): Sequential(\n",
      "    (0): GroupNorm32(32, 2560, eps=1e-05, affine=True)\n",
      "    (1): SiLU()\n",
      "    (2): Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (h_upd): Identity()\n",
      "  (x_upd): Identity()\n",
      "  (emb_layers): Sequential(\n",
      "    (0): SiLU()\n",
      "    (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "  )\n",
      "  (out_layers): Sequential(\n",
      "    (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
      "    (1): SiLU()\n",
      "    (2): Dropout(p=0, inplace=False)\n",
      "    (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (skip_connection): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
      ")\n",
      "Module: Sequential(\n",
      "  (0): GroupNorm32(32, 2560, eps=1e-05, affine=True)\n",
      "  (1): SiLU()\n",
      "  (2): Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")\n",
      "Module: GroupNorm32(32, 2560, eps=1e-05, affine=True)\n",
      "Module: SiLU()\n",
      "Module: Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "Module: Identity()\n",
      "Module: Sequential(\n",
      "  (0): SiLU()\n",
      "  (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
      ")\n",
      "Module: SiLU()\n",
      "Module: Linear(in_features=1280, out_features=1280, bias=True)\n",
      "Module: Sequential(\n",
      "  (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
      "  (1): SiLU()\n",
      "  (2): Dropout(p=0, inplace=False)\n",
      "  (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")\n",
      "Module: GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
      "Module: SiLU()\n",
      "Module: Dropout(p=0, inplace=False)\n",
      "Module: Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "Module: Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
      "Module: SpatialTransformer(\n",
      "  (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
      "  (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (transformer_blocks): ModuleList(\n",
      "    (0): BasicTransformerBlock(\n",
      "      (attn1): CrossAttention(\n",
      "        (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "        (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "        (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "        (to_out): Sequential(\n",
      "          (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (1): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (net): Sequential(\n",
      "          (0): GEGLU(\n",
      "            (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
      "          )\n",
      "          (1): Dropout(p=0.0, inplace=False)\n",
      "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (attn2): CrossAttention(\n",
      "        (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "        (to_k): Linear(in_features=768, out_features=1280, bias=False)\n",
      "        (to_v): Linear(in_features=768, out_features=1280, bias=False)\n",
      "        (to_out): Sequential(\n",
      "          (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (1): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "      (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
      ")\n",
      "Module: GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
      "Module: Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
      "Module: ModuleList(\n",
      "  (0): BasicTransformerBlock(\n",
      "    (attn1): CrossAttention(\n",
      "      (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "      (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "      (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "      (to_out): Sequential(\n",
      "        (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "        (1): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (ff): FeedForward(\n",
      "      (net): Sequential(\n",
      "        (0): GEGLU(\n",
      "          (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
      "        )\n",
      "        (1): Dropout(p=0.0, inplace=False)\n",
      "        (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (attn2): CrossAttention(\n",
      "      (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "      (to_k): Linear(in_features=768, out_features=1280, bias=False)\n",
      "      (to_v): Linear(in_features=768, out_features=1280, bias=False)\n",
      "      (to_out): Sequential(\n",
      "        (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "        (1): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "    (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "    (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      ")\n",
      "Module: BasicTransformerBlock(\n",
      "  (attn1): CrossAttention(\n",
      "    (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "    (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "    (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "    (to_out): Sequential(\n",
      "      (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "      (1): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (ff): FeedForward(\n",
      "    (net): Sequential(\n",
      "      (0): GEGLU(\n",
      "        (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
      "      )\n",
      "      (1): Dropout(p=0.0, inplace=False)\n",
      "      (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (attn2): CrossAttention(\n",
      "    (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "    (to_k): Linear(in_features=768, out_features=1280, bias=False)\n",
      "    (to_v): Linear(in_features=768, out_features=1280, bias=False)\n",
      "    (to_out): Sequential(\n",
      "      (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "      (1): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "  (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "  (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      ")\n",
      "Module: CrossAttention(\n",
      "  (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "  (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "  (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "  (to_out): Sequential(\n",
      "    (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "    (1): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      ")\n",
      "Module: Linear(in_features=1280, out_features=1280, bias=False)\n",
      "Module: Linear(in_features=1280, out_features=1280, bias=False)\n",
      "Module: Linear(in_features=1280, out_features=1280, bias=False)\n",
      "Module: Sequential(\n",
      "  (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "  (1): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "Module: Linear(in_features=1280, out_features=1280, bias=True)\n",
      "Module: Dropout(p=0.0, inplace=False)\n",
      "Module: FeedForward(\n",
      "  (net): Sequential(\n",
      "    (0): GEGLU(\n",
      "      (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
      "    )\n",
      "    (1): Dropout(p=0.0, inplace=False)\n",
      "    (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
      "  )\n",
      ")\n",
      "Module: Sequential(\n",
      "  (0): GEGLU(\n",
      "    (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
      "  )\n",
      "  (1): Dropout(p=0.0, inplace=False)\n",
      "  (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
      ")\n",
      "Module: GEGLU(\n",
      "  (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
      ")\n",
      "Module: Linear(in_features=1280, out_features=10240, bias=True)\n",
      "Module: Dropout(p=0.0, inplace=False)\n",
      "Module: Linear(in_features=5120, out_features=1280, bias=True)\n",
      "Module: CrossAttention(\n",
      "  (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "  (to_k): Linear(in_features=768, out_features=1280, bias=False)\n",
      "  (to_v): Linear(in_features=768, out_features=1280, bias=False)\n",
      "  (to_out): Sequential(\n",
      "    (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "    (1): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      ")\n",
      "Module: Linear(in_features=1280, out_features=1280, bias=False)\n",
      "Module: Linear(in_features=768, out_features=1280, bias=False)\n",
      "Module: Linear(in_features=768, out_features=1280, bias=False)\n",
      "Module: Sequential(\n",
      "  (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "  (1): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "Module: Linear(in_features=1280, out_features=1280, bias=True)\n",
      "Module: Dropout(p=0.0, inplace=False)\n",
      "Module: LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "Module: LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "Module: LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "Module: Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
      "Module: TimestepEmbedSequential(\n",
      "  (0): ResBlock(\n",
      "    (in_layers): Sequential(\n",
      "      (0): GroupNorm32(32, 1920, eps=1e-05, affine=True)\n",
      "      (1): SiLU()\n",
      "      (2): Conv2d(1920, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (h_upd): Identity()\n",
      "    (x_upd): Identity()\n",
      "    (emb_layers): Sequential(\n",
      "      (0): SiLU()\n",
      "      (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "    )\n",
      "    (out_layers): Sequential(\n",
      "      (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
      "      (1): SiLU()\n",
      "      (2): Dropout(p=0, inplace=False)\n",
      "      (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (skip_connection): Conv2d(1920, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (1): SpatialTransformer(\n",
      "    (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
      "    (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (transformer_blocks): ModuleList(\n",
      "      (0): BasicTransformerBlock(\n",
      "        (attn1): CrossAttention(\n",
      "          (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "          (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "          (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "          (to_out): Sequential(\n",
      "            (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "            (1): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (ff): FeedForward(\n",
      "          (net): Sequential(\n",
      "            (0): GEGLU(\n",
      "              (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
      "            )\n",
      "            (1): Dropout(p=0.0, inplace=False)\n",
      "            (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
      "          )\n",
      "        )\n",
      "        (attn2): CrossAttention(\n",
      "          (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "          (to_k): Linear(in_features=768, out_features=1280, bias=False)\n",
      "          (to_v): Linear(in_features=768, out_features=1280, bias=False)\n",
      "          (to_out): Sequential(\n",
      "            (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "            (1): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (2): Upsample(\n",
      "    (conv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      ")\n",
      "Module: ResBlock(\n",
      "  (in_layers): Sequential(\n",
      "    (0): GroupNorm32(32, 1920, eps=1e-05, affine=True)\n",
      "    (1): SiLU()\n",
      "    (2): Conv2d(1920, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (h_upd): Identity()\n",
      "  (x_upd): Identity()\n",
      "  (emb_layers): Sequential(\n",
      "    (0): SiLU()\n",
      "    (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "  )\n",
      "  (out_layers): Sequential(\n",
      "    (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
      "    (1): SiLU()\n",
      "    (2): Dropout(p=0, inplace=False)\n",
      "    (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (skip_connection): Conv2d(1920, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
      ")\n",
      "Module: Sequential(\n",
      "  (0): GroupNorm32(32, 1920, eps=1e-05, affine=True)\n",
      "  (1): SiLU()\n",
      "  (2): Conv2d(1920, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")\n",
      "Module: GroupNorm32(32, 1920, eps=1e-05, affine=True)\n",
      "Module: SiLU()\n",
      "Module: Conv2d(1920, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "Module: Identity()\n",
      "Module: Sequential(\n",
      "  (0): SiLU()\n",
      "  (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
      ")\n",
      "Module: SiLU()\n",
      "Module: Linear(in_features=1280, out_features=1280, bias=True)\n",
      "Module: Sequential(\n",
      "  (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
      "  (1): SiLU()\n",
      "  (2): Dropout(p=0, inplace=False)\n",
      "  (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")\n",
      "Module: GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
      "Module: SiLU()\n",
      "Module: Dropout(p=0, inplace=False)\n",
      "Module: Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "Module: Conv2d(1920, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
      "Module: SpatialTransformer(\n",
      "  (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
      "  (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (transformer_blocks): ModuleList(\n",
      "    (0): BasicTransformerBlock(\n",
      "      (attn1): CrossAttention(\n",
      "        (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "        (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "        (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "        (to_out): Sequential(\n",
      "          (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (1): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (net): Sequential(\n",
      "          (0): GEGLU(\n",
      "            (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
      "          )\n",
      "          (1): Dropout(p=0.0, inplace=False)\n",
      "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (attn2): CrossAttention(\n",
      "        (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "        (to_k): Linear(in_features=768, out_features=1280, bias=False)\n",
      "        (to_v): Linear(in_features=768, out_features=1280, bias=False)\n",
      "        (to_out): Sequential(\n",
      "          (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (1): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "      (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
      ")\n",
      "Module: GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
      "Module: Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
      "Module: ModuleList(\n",
      "  (0): BasicTransformerBlock(\n",
      "    (attn1): CrossAttention(\n",
      "      (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "      (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "      (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "      (to_out): Sequential(\n",
      "        (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "        (1): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (ff): FeedForward(\n",
      "      (net): Sequential(\n",
      "        (0): GEGLU(\n",
      "          (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
      "        )\n",
      "        (1): Dropout(p=0.0, inplace=False)\n",
      "        (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (attn2): CrossAttention(\n",
      "      (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "      (to_k): Linear(in_features=768, out_features=1280, bias=False)\n",
      "      (to_v): Linear(in_features=768, out_features=1280, bias=False)\n",
      "      (to_out): Sequential(\n",
      "        (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "        (1): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "    (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "    (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      ")\n",
      "Module: BasicTransformerBlock(\n",
      "  (attn1): CrossAttention(\n",
      "    (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "    (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "    (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "    (to_out): Sequential(\n",
      "      (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "      (1): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (ff): FeedForward(\n",
      "    (net): Sequential(\n",
      "      (0): GEGLU(\n",
      "        (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
      "      )\n",
      "      (1): Dropout(p=0.0, inplace=False)\n",
      "      (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (attn2): CrossAttention(\n",
      "    (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "    (to_k): Linear(in_features=768, out_features=1280, bias=False)\n",
      "    (to_v): Linear(in_features=768, out_features=1280, bias=False)\n",
      "    (to_out): Sequential(\n",
      "      (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "      (1): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "  (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "  (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      ")\n",
      "Module: CrossAttention(\n",
      "  (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "  (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "  (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "  (to_out): Sequential(\n",
      "    (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "    (1): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      ")\n",
      "Module: Linear(in_features=1280, out_features=1280, bias=False)\n",
      "Module: Linear(in_features=1280, out_features=1280, bias=False)\n",
      "Module: Linear(in_features=1280, out_features=1280, bias=False)\n",
      "Module: Sequential(\n",
      "  (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "  (1): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "Module: Linear(in_features=1280, out_features=1280, bias=True)\n",
      "Module: Dropout(p=0.0, inplace=False)\n",
      "Module: FeedForward(\n",
      "  (net): Sequential(\n",
      "    (0): GEGLU(\n",
      "      (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
      "    )\n",
      "    (1): Dropout(p=0.0, inplace=False)\n",
      "    (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
      "  )\n",
      ")\n",
      "Module: Sequential(\n",
      "  (0): GEGLU(\n",
      "    (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
      "  )\n",
      "  (1): Dropout(p=0.0, inplace=False)\n",
      "  (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
      ")\n",
      "Module: GEGLU(\n",
      "  (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
      ")\n",
      "Module: Linear(in_features=1280, out_features=10240, bias=True)\n",
      "Module: Dropout(p=0.0, inplace=False)\n",
      "Module: Linear(in_features=5120, out_features=1280, bias=True)\n",
      "Module: CrossAttention(\n",
      "  (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "  (to_k): Linear(in_features=768, out_features=1280, bias=False)\n",
      "  (to_v): Linear(in_features=768, out_features=1280, bias=False)\n",
      "  (to_out): Sequential(\n",
      "    (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "    (1): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      ")\n",
      "Module: Linear(in_features=1280, out_features=1280, bias=False)\n",
      "Module: Linear(in_features=768, out_features=1280, bias=False)\n",
      "Module: Linear(in_features=768, out_features=1280, bias=False)\n",
      "Module: Sequential(\n",
      "  (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "  (1): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "Module: Linear(in_features=1280, out_features=1280, bias=True)\n",
      "Module: Dropout(p=0.0, inplace=False)\n",
      "Module: LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "Module: LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "Module: LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "Module: Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
      "Module: Upsample(\n",
      "  (conv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")\n",
      "Module: Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "Module: TimestepEmbedSequential(\n",
      "  (0): ResBlock(\n",
      "    (in_layers): Sequential(\n",
      "      (0): GroupNorm32(32, 1920, eps=1e-05, affine=True)\n",
      "      (1): SiLU()\n",
      "      (2): Conv2d(1920, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (h_upd): Identity()\n",
      "    (x_upd): Identity()\n",
      "    (emb_layers): Sequential(\n",
      "      (0): SiLU()\n",
      "      (1): Linear(in_features=1280, out_features=640, bias=True)\n",
      "    )\n",
      "    (out_layers): Sequential(\n",
      "      (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
      "      (1): SiLU()\n",
      "      (2): Dropout(p=0, inplace=False)\n",
      "      (3): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (skip_connection): Conv2d(1920, 640, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (1): SpatialTransformer(\n",
      "    (norm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
      "    (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (transformer_blocks): ModuleList(\n",
      "      (0): BasicTransformerBlock(\n",
      "        (attn1): CrossAttention(\n",
      "          (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
      "          (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
      "          (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
      "          (to_out): Sequential(\n",
      "            (0): Linear(in_features=640, out_features=640, bias=True)\n",
      "            (1): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (ff): FeedForward(\n",
      "          (net): Sequential(\n",
      "            (0): GEGLU(\n",
      "              (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
      "            )\n",
      "            (1): Dropout(p=0.0, inplace=False)\n",
      "            (2): Linear(in_features=2560, out_features=640, bias=True)\n",
      "          )\n",
      "        )\n",
      "        (attn2): CrossAttention(\n",
      "          (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
      "          (to_k): Linear(in_features=768, out_features=640, bias=False)\n",
      "          (to_v): Linear(in_features=768, out_features=640, bias=False)\n",
      "          (to_out): Sequential(\n",
      "            (0): Linear(in_features=640, out_features=640, bias=True)\n",
      "            (1): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n",
      "Module: ResBlock(\n",
      "  (in_layers): Sequential(\n",
      "    (0): GroupNorm32(32, 1920, eps=1e-05, affine=True)\n",
      "    (1): SiLU()\n",
      "    (2): Conv2d(1920, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (h_upd): Identity()\n",
      "  (x_upd): Identity()\n",
      "  (emb_layers): Sequential(\n",
      "    (0): SiLU()\n",
      "    (1): Linear(in_features=1280, out_features=640, bias=True)\n",
      "  )\n",
      "  (out_layers): Sequential(\n",
      "    (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
      "    (1): SiLU()\n",
      "    (2): Dropout(p=0, inplace=False)\n",
      "    (3): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (skip_connection): Conv2d(1920, 640, kernel_size=(1, 1), stride=(1, 1))\n",
      ")\n",
      "Module: Sequential(\n",
      "  (0): GroupNorm32(32, 1920, eps=1e-05, affine=True)\n",
      "  (1): SiLU()\n",
      "  (2): Conv2d(1920, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")\n",
      "Module: GroupNorm32(32, 1920, eps=1e-05, affine=True)\n",
      "Module: SiLU()\n",
      "Module: Conv2d(1920, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "Module: Identity()\n",
      "Module: Sequential(\n",
      "  (0): SiLU()\n",
      "  (1): Linear(in_features=1280, out_features=640, bias=True)\n",
      ")\n",
      "Module: SiLU()\n",
      "Module: Linear(in_features=1280, out_features=640, bias=True)\n",
      "Module: Sequential(\n",
      "  (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
      "  (1): SiLU()\n",
      "  (2): Dropout(p=0, inplace=False)\n",
      "  (3): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")\n",
      "Module: GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
      "Module: SiLU()\n",
      "Module: Dropout(p=0, inplace=False)\n",
      "Module: Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "Module: Conv2d(1920, 640, kernel_size=(1, 1), stride=(1, 1))\n",
      "Module: SpatialTransformer(\n",
      "  (norm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
      "  (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (transformer_blocks): ModuleList(\n",
      "    (0): BasicTransformerBlock(\n",
      "      (attn1): CrossAttention(\n",
      "        (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
      "        (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
      "        (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
      "        (to_out): Sequential(\n",
      "          (0): Linear(in_features=640, out_features=640, bias=True)\n",
      "          (1): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (net): Sequential(\n",
      "          (0): GEGLU(\n",
      "            (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
      "          )\n",
      "          (1): Dropout(p=0.0, inplace=False)\n",
      "          (2): Linear(in_features=2560, out_features=640, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (attn2): CrossAttention(\n",
      "        (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
      "        (to_k): Linear(in_features=768, out_features=640, bias=False)\n",
      "        (to_v): Linear(in_features=768, out_features=640, bias=False)\n",
      "        (to_out): Sequential(\n",
      "          (0): Linear(in_features=640, out_features=640, bias=True)\n",
      "          (1): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
      "      (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
      ")\n",
      "Module: GroupNorm(32, 640, eps=1e-06, affine=True)\n",
      "Module: Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
      "Module: ModuleList(\n",
      "  (0): BasicTransformerBlock(\n",
      "    (attn1): CrossAttention(\n",
      "      (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
      "      (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
      "      (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
      "      (to_out): Sequential(\n",
      "        (0): Linear(in_features=640, out_features=640, bias=True)\n",
      "        (1): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (ff): FeedForward(\n",
      "      (net): Sequential(\n",
      "        (0): GEGLU(\n",
      "          (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
      "        )\n",
      "        (1): Dropout(p=0.0, inplace=False)\n",
      "        (2): Linear(in_features=2560, out_features=640, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (attn2): CrossAttention(\n",
      "      (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
      "      (to_k): Linear(in_features=768, out_features=640, bias=False)\n",
      "      (to_v): Linear(in_features=768, out_features=640, bias=False)\n",
      "      (to_out): Sequential(\n",
      "        (0): Linear(in_features=640, out_features=640, bias=True)\n",
      "        (1): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
      "    (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
      "    (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      ")\n",
      "Module: BasicTransformerBlock(\n",
      "  (attn1): CrossAttention(\n",
      "    (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
      "    (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
      "    (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
      "    (to_out): Sequential(\n",
      "      (0): Linear(in_features=640, out_features=640, bias=True)\n",
      "      (1): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (ff): FeedForward(\n",
      "    (net): Sequential(\n",
      "      (0): GEGLU(\n",
      "        (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
      "      )\n",
      "      (1): Dropout(p=0.0, inplace=False)\n",
      "      (2): Linear(in_features=2560, out_features=640, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (attn2): CrossAttention(\n",
      "    (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
      "    (to_k): Linear(in_features=768, out_features=640, bias=False)\n",
      "    (to_v): Linear(in_features=768, out_features=640, bias=False)\n",
      "    (to_out): Sequential(\n",
      "      (0): Linear(in_features=640, out_features=640, bias=True)\n",
      "      (1): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
      "  (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
      "  (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
      ")\n",
      "Module: CrossAttention(\n",
      "  (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
      "  (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
      "  (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
      "  (to_out): Sequential(\n",
      "    (0): Linear(in_features=640, out_features=640, bias=True)\n",
      "    (1): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      ")\n",
      "Module: Linear(in_features=640, out_features=640, bias=False)\n",
      "Module: Linear(in_features=640, out_features=640, bias=False)\n",
      "Module: Linear(in_features=640, out_features=640, bias=False)\n",
      "Module: Sequential(\n",
      "  (0): Linear(in_features=640, out_features=640, bias=True)\n",
      "  (1): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "Module: Linear(in_features=640, out_features=640, bias=True)\n",
      "Module: Dropout(p=0.0, inplace=False)\n",
      "Module: FeedForward(\n",
      "  (net): Sequential(\n",
      "    (0): GEGLU(\n",
      "      (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
      "    )\n",
      "    (1): Dropout(p=0.0, inplace=False)\n",
      "    (2): Linear(in_features=2560, out_features=640, bias=True)\n",
      "  )\n",
      ")\n",
      "Module: Sequential(\n",
      "  (0): GEGLU(\n",
      "    (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
      "  )\n",
      "  (1): Dropout(p=0.0, inplace=False)\n",
      "  (2): Linear(in_features=2560, out_features=640, bias=True)\n",
      ")\n",
      "Module: GEGLU(\n",
      "  (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
      ")\n",
      "Module: Linear(in_features=640, out_features=5120, bias=True)\n",
      "Module: Dropout(p=0.0, inplace=False)\n",
      "Module: Linear(in_features=2560, out_features=640, bias=True)\n",
      "Module: CrossAttention(\n",
      "  (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
      "  (to_k): Linear(in_features=768, out_features=640, bias=False)\n",
      "  (to_v): Linear(in_features=768, out_features=640, bias=False)\n",
      "  (to_out): Sequential(\n",
      "    (0): Linear(in_features=640, out_features=640, bias=True)\n",
      "    (1): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      ")\n",
      "Module: Linear(in_features=640, out_features=640, bias=False)\n",
      "Module: Linear(in_features=768, out_features=640, bias=False)\n",
      "Module: Linear(in_features=768, out_features=640, bias=False)\n",
      "Module: Sequential(\n",
      "  (0): Linear(in_features=640, out_features=640, bias=True)\n",
      "  (1): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "Module: Linear(in_features=640, out_features=640, bias=True)\n",
      "Module: Dropout(p=0.0, inplace=False)\n",
      "Module: LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
      "Module: LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
      "Module: LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
      "Module: Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
      "Module: TimestepEmbedSequential(\n",
      "  (0): ResBlock(\n",
      "    (in_layers): Sequential(\n",
      "      (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
      "      (1): SiLU()\n",
      "      (2): Conv2d(1280, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (h_upd): Identity()\n",
      "    (x_upd): Identity()\n",
      "    (emb_layers): Sequential(\n",
      "      (0): SiLU()\n",
      "      (1): Linear(in_features=1280, out_features=640, bias=True)\n",
      "    )\n",
      "    (out_layers): Sequential(\n",
      "      (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
      "      (1): SiLU()\n",
      "      (2): Dropout(p=0, inplace=False)\n",
      "      (3): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (skip_connection): Conv2d(1280, 640, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (1): SpatialTransformer(\n",
      "    (norm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
      "    (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (transformer_blocks): ModuleList(\n",
      "      (0): BasicTransformerBlock(\n",
      "        (attn1): CrossAttention(\n",
      "          (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
      "          (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
      "          (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
      "          (to_out): Sequential(\n",
      "            (0): Linear(in_features=640, out_features=640, bias=True)\n",
      "            (1): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (ff): FeedForward(\n",
      "          (net): Sequential(\n",
      "            (0): GEGLU(\n",
      "              (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
      "            )\n",
      "            (1): Dropout(p=0.0, inplace=False)\n",
      "            (2): Linear(in_features=2560, out_features=640, bias=True)\n",
      "          )\n",
      "        )\n",
      "        (attn2): CrossAttention(\n",
      "          (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
      "          (to_k): Linear(in_features=768, out_features=640, bias=False)\n",
      "          (to_v): Linear(in_features=768, out_features=640, bias=False)\n",
      "          (to_out): Sequential(\n",
      "            (0): Linear(in_features=640, out_features=640, bias=True)\n",
      "            (1): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n",
      "Module: ResBlock(\n",
      "  (in_layers): Sequential(\n",
      "    (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
      "    (1): SiLU()\n",
      "    (2): Conv2d(1280, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (h_upd): Identity()\n",
      "  (x_upd): Identity()\n",
      "  (emb_layers): Sequential(\n",
      "    (0): SiLU()\n",
      "    (1): Linear(in_features=1280, out_features=640, bias=True)\n",
      "  )\n",
      "  (out_layers): Sequential(\n",
      "    (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
      "    (1): SiLU()\n",
      "    (2): Dropout(p=0, inplace=False)\n",
      "    (3): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (skip_connection): Conv2d(1280, 640, kernel_size=(1, 1), stride=(1, 1))\n",
      ")\n",
      "Module: Sequential(\n",
      "  (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
      "  (1): SiLU()\n",
      "  (2): Conv2d(1280, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")\n",
      "Module: GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
      "Module: SiLU()\n",
      "Module: Conv2d(1280, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "Module: Identity()\n",
      "Module: Sequential(\n",
      "  (0): SiLU()\n",
      "  (1): Linear(in_features=1280, out_features=640, bias=True)\n",
      ")\n",
      "Module: SiLU()\n",
      "Module: Linear(in_features=1280, out_features=640, bias=True)\n",
      "Module: Sequential(\n",
      "  (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
      "  (1): SiLU()\n",
      "  (2): Dropout(p=0, inplace=False)\n",
      "  (3): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")\n",
      "Module: GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
      "Module: SiLU()\n",
      "Module: Dropout(p=0, inplace=False)\n",
      "Module: Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "Module: Conv2d(1280, 640, kernel_size=(1, 1), stride=(1, 1))\n",
      "Module: SpatialTransformer(\n",
      "  (norm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
      "  (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (transformer_blocks): ModuleList(\n",
      "    (0): BasicTransformerBlock(\n",
      "      (attn1): CrossAttention(\n",
      "        (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
      "        (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
      "        (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
      "        (to_out): Sequential(\n",
      "          (0): Linear(in_features=640, out_features=640, bias=True)\n",
      "          (1): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (net): Sequential(\n",
      "          (0): GEGLU(\n",
      "            (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
      "          )\n",
      "          (1): Dropout(p=0.0, inplace=False)\n",
      "          (2): Linear(in_features=2560, out_features=640, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (attn2): CrossAttention(\n",
      "        (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
      "        (to_k): Linear(in_features=768, out_features=640, bias=False)\n",
      "        (to_v): Linear(in_features=768, out_features=640, bias=False)\n",
      "        (to_out): Sequential(\n",
      "          (0): Linear(in_features=640, out_features=640, bias=True)\n",
      "          (1): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
      "      (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
      ")\n",
      "Module: GroupNorm(32, 640, eps=1e-06, affine=True)\n",
      "Module: Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
      "Module: ModuleList(\n",
      "  (0): BasicTransformerBlock(\n",
      "    (attn1): CrossAttention(\n",
      "      (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
      "      (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
      "      (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
      "      (to_out): Sequential(\n",
      "        (0): Linear(in_features=640, out_features=640, bias=True)\n",
      "        (1): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (ff): FeedForward(\n",
      "      (net): Sequential(\n",
      "        (0): GEGLU(\n",
      "          (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
      "        )\n",
      "        (1): Dropout(p=0.0, inplace=False)\n",
      "        (2): Linear(in_features=2560, out_features=640, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (attn2): CrossAttention(\n",
      "      (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
      "      (to_k): Linear(in_features=768, out_features=640, bias=False)\n",
      "      (to_v): Linear(in_features=768, out_features=640, bias=False)\n",
      "      (to_out): Sequential(\n",
      "        (0): Linear(in_features=640, out_features=640, bias=True)\n",
      "        (1): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
      "    (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
      "    (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      ")\n",
      "Module: BasicTransformerBlock(\n",
      "  (attn1): CrossAttention(\n",
      "    (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
      "    (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
      "    (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
      "    (to_out): Sequential(\n",
      "      (0): Linear(in_features=640, out_features=640, bias=True)\n",
      "      (1): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (ff): FeedForward(\n",
      "    (net): Sequential(\n",
      "      (0): GEGLU(\n",
      "        (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
      "      )\n",
      "      (1): Dropout(p=0.0, inplace=False)\n",
      "      (2): Linear(in_features=2560, out_features=640, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (attn2): CrossAttention(\n",
      "    (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
      "    (to_k): Linear(in_features=768, out_features=640, bias=False)\n",
      "    (to_v): Linear(in_features=768, out_features=640, bias=False)\n",
      "    (to_out): Sequential(\n",
      "      (0): Linear(in_features=640, out_features=640, bias=True)\n",
      "      (1): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
      "  (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
      "  (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
      ")\n",
      "Module: CrossAttention(\n",
      "  (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
      "  (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
      "  (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
      "  (to_out): Sequential(\n",
      "    (0): Linear(in_features=640, out_features=640, bias=True)\n",
      "    (1): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      ")\n",
      "Module: Linear(in_features=640, out_features=640, bias=False)\n",
      "Module: Linear(in_features=640, out_features=640, bias=False)\n",
      "Module: Linear(in_features=640, out_features=640, bias=False)\n",
      "Module: Sequential(\n",
      "  (0): Linear(in_features=640, out_features=640, bias=True)\n",
      "  (1): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "Module: Linear(in_features=640, out_features=640, bias=True)\n",
      "Module: Dropout(p=0.0, inplace=False)\n",
      "Module: FeedForward(\n",
      "  (net): Sequential(\n",
      "    (0): GEGLU(\n",
      "      (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
      "    )\n",
      "    (1): Dropout(p=0.0, inplace=False)\n",
      "    (2): Linear(in_features=2560, out_features=640, bias=True)\n",
      "  )\n",
      ")\n",
      "Module: Sequential(\n",
      "  (0): GEGLU(\n",
      "    (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
      "  )\n",
      "  (1): Dropout(p=0.0, inplace=False)\n",
      "  (2): Linear(in_features=2560, out_features=640, bias=True)\n",
      ")\n",
      "Module: GEGLU(\n",
      "  (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
      ")\n",
      "Module: Linear(in_features=640, out_features=5120, bias=True)\n",
      "Module: Dropout(p=0.0, inplace=False)\n",
      "Module: Linear(in_features=2560, out_features=640, bias=True)\n",
      "Module: CrossAttention(\n",
      "  (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
      "  (to_k): Linear(in_features=768, out_features=640, bias=False)\n",
      "  (to_v): Linear(in_features=768, out_features=640, bias=False)\n",
      "  (to_out): Sequential(\n",
      "    (0): Linear(in_features=640, out_features=640, bias=True)\n",
      "    (1): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      ")\n",
      "Module: Linear(in_features=640, out_features=640, bias=False)\n",
      "Module: Linear(in_features=768, out_features=640, bias=False)\n",
      "Module: Linear(in_features=768, out_features=640, bias=False)\n",
      "Module: Sequential(\n",
      "  (0): Linear(in_features=640, out_features=640, bias=True)\n",
      "  (1): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "Module: Linear(in_features=640, out_features=640, bias=True)\n",
      "Module: Dropout(p=0.0, inplace=False)\n",
      "Module: LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
      "Module: LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
      "Module: LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
      "Module: Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
      "Module: TimestepEmbedSequential(\n",
      "  (0): ResBlock(\n",
      "    (in_layers): Sequential(\n",
      "      (0): GroupNorm32(32, 960, eps=1e-05, affine=True)\n",
      "      (1): SiLU()\n",
      "      (2): Conv2d(960, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (h_upd): Identity()\n",
      "    (x_upd): Identity()\n",
      "    (emb_layers): Sequential(\n",
      "      (0): SiLU()\n",
      "      (1): Linear(in_features=1280, out_features=640, bias=True)\n",
      "    )\n",
      "    (out_layers): Sequential(\n",
      "      (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
      "      (1): SiLU()\n",
      "      (2): Dropout(p=0, inplace=False)\n",
      "      (3): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (skip_connection): Conv2d(960, 640, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (1): SpatialTransformer(\n",
      "    (norm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
      "    (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (transformer_blocks): ModuleList(\n",
      "      (0): BasicTransformerBlock(\n",
      "        (attn1): CrossAttention(\n",
      "          (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
      "          (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
      "          (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
      "          (to_out): Sequential(\n",
      "            (0): Linear(in_features=640, out_features=640, bias=True)\n",
      "            (1): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (ff): FeedForward(\n",
      "          (net): Sequential(\n",
      "            (0): GEGLU(\n",
      "              (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
      "            )\n",
      "            (1): Dropout(p=0.0, inplace=False)\n",
      "            (2): Linear(in_features=2560, out_features=640, bias=True)\n",
      "          )\n",
      "        )\n",
      "        (attn2): CrossAttention(\n",
      "          (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
      "          (to_k): Linear(in_features=768, out_features=640, bias=False)\n",
      "          (to_v): Linear(in_features=768, out_features=640, bias=False)\n",
      "          (to_out): Sequential(\n",
      "            (0): Linear(in_features=640, out_features=640, bias=True)\n",
      "            (1): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (2): Upsample(\n",
      "    (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      ")\n",
      "Module: ResBlock(\n",
      "  (in_layers): Sequential(\n",
      "    (0): GroupNorm32(32, 960, eps=1e-05, affine=True)\n",
      "    (1): SiLU()\n",
      "    (2): Conv2d(960, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (h_upd): Identity()\n",
      "  (x_upd): Identity()\n",
      "  (emb_layers): Sequential(\n",
      "    (0): SiLU()\n",
      "    (1): Linear(in_features=1280, out_features=640, bias=True)\n",
      "  )\n",
      "  (out_layers): Sequential(\n",
      "    (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
      "    (1): SiLU()\n",
      "    (2): Dropout(p=0, inplace=False)\n",
      "    (3): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (skip_connection): Conv2d(960, 640, kernel_size=(1, 1), stride=(1, 1))\n",
      ")\n",
      "Module: Sequential(\n",
      "  (0): GroupNorm32(32, 960, eps=1e-05, affine=True)\n",
      "  (1): SiLU()\n",
      "  (2): Conv2d(960, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")\n",
      "Module: GroupNorm32(32, 960, eps=1e-05, affine=True)\n",
      "Module: SiLU()\n",
      "Module: Conv2d(960, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "Module: Identity()\n",
      "Module: Sequential(\n",
      "  (0): SiLU()\n",
      "  (1): Linear(in_features=1280, out_features=640, bias=True)\n",
      ")\n",
      "Module: SiLU()\n",
      "Module: Linear(in_features=1280, out_features=640, bias=True)\n",
      "Module: Sequential(\n",
      "  (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
      "  (1): SiLU()\n",
      "  (2): Dropout(p=0, inplace=False)\n",
      "  (3): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")\n",
      "Module: GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
      "Module: SiLU()\n",
      "Module: Dropout(p=0, inplace=False)\n",
      "Module: Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "Module: Conv2d(960, 640, kernel_size=(1, 1), stride=(1, 1))\n",
      "Module: SpatialTransformer(\n",
      "  (norm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
      "  (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (transformer_blocks): ModuleList(\n",
      "    (0): BasicTransformerBlock(\n",
      "      (attn1): CrossAttention(\n",
      "        (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
      "        (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
      "        (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
      "        (to_out): Sequential(\n",
      "          (0): Linear(in_features=640, out_features=640, bias=True)\n",
      "          (1): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (net): Sequential(\n",
      "          (0): GEGLU(\n",
      "            (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
      "          )\n",
      "          (1): Dropout(p=0.0, inplace=False)\n",
      "          (2): Linear(in_features=2560, out_features=640, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (attn2): CrossAttention(\n",
      "        (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
      "        (to_k): Linear(in_features=768, out_features=640, bias=False)\n",
      "        (to_v): Linear(in_features=768, out_features=640, bias=False)\n",
      "        (to_out): Sequential(\n",
      "          (0): Linear(in_features=640, out_features=640, bias=True)\n",
      "          (1): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
      "      (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
      ")\n",
      "Module: GroupNorm(32, 640, eps=1e-06, affine=True)\n",
      "Module: Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
      "Module: ModuleList(\n",
      "  (0): BasicTransformerBlock(\n",
      "    (attn1): CrossAttention(\n",
      "      (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
      "      (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
      "      (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
      "      (to_out): Sequential(\n",
      "        (0): Linear(in_features=640, out_features=640, bias=True)\n",
      "        (1): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (ff): FeedForward(\n",
      "      (net): Sequential(\n",
      "        (0): GEGLU(\n",
      "          (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
      "        )\n",
      "        (1): Dropout(p=0.0, inplace=False)\n",
      "        (2): Linear(in_features=2560, out_features=640, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (attn2): CrossAttention(\n",
      "      (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
      "      (to_k): Linear(in_features=768, out_features=640, bias=False)\n",
      "      (to_v): Linear(in_features=768, out_features=640, bias=False)\n",
      "      (to_out): Sequential(\n",
      "        (0): Linear(in_features=640, out_features=640, bias=True)\n",
      "        (1): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
      "    (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
      "    (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      ")\n",
      "Module: BasicTransformerBlock(\n",
      "  (attn1): CrossAttention(\n",
      "    (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
      "    (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
      "    (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
      "    (to_out): Sequential(\n",
      "      (0): Linear(in_features=640, out_features=640, bias=True)\n",
      "      (1): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (ff): FeedForward(\n",
      "    (net): Sequential(\n",
      "      (0): GEGLU(\n",
      "        (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
      "      )\n",
      "      (1): Dropout(p=0.0, inplace=False)\n",
      "      (2): Linear(in_features=2560, out_features=640, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (attn2): CrossAttention(\n",
      "    (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
      "    (to_k): Linear(in_features=768, out_features=640, bias=False)\n",
      "    (to_v): Linear(in_features=768, out_features=640, bias=False)\n",
      "    (to_out): Sequential(\n",
      "      (0): Linear(in_features=640, out_features=640, bias=True)\n",
      "      (1): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
      "  (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
      "  (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
      ")\n",
      "Module: CrossAttention(\n",
      "  (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
      "  (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
      "  (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
      "  (to_out): Sequential(\n",
      "    (0): Linear(in_features=640, out_features=640, bias=True)\n",
      "    (1): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      ")\n",
      "Module: Linear(in_features=640, out_features=640, bias=False)\n",
      "Module: Linear(in_features=640, out_features=640, bias=False)\n",
      "Module: Linear(in_features=640, out_features=640, bias=False)\n",
      "Module: Sequential(\n",
      "  (0): Linear(in_features=640, out_features=640, bias=True)\n",
      "  (1): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "Module: Linear(in_features=640, out_features=640, bias=True)\n",
      "Module: Dropout(p=0.0, inplace=False)\n",
      "Module: FeedForward(\n",
      "  (net): Sequential(\n",
      "    (0): GEGLU(\n",
      "      (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
      "    )\n",
      "    (1): Dropout(p=0.0, inplace=False)\n",
      "    (2): Linear(in_features=2560, out_features=640, bias=True)\n",
      "  )\n",
      ")\n",
      "Module: Sequential(\n",
      "  (0): GEGLU(\n",
      "    (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
      "  )\n",
      "  (1): Dropout(p=0.0, inplace=False)\n",
      "  (2): Linear(in_features=2560, out_features=640, bias=True)\n",
      ")\n",
      "Module: GEGLU(\n",
      "  (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
      ")\n",
      "Module: Linear(in_features=640, out_features=5120, bias=True)\n",
      "Module: Dropout(p=0.0, inplace=False)\n",
      "Module: Linear(in_features=2560, out_features=640, bias=True)\n",
      "Module: CrossAttention(\n",
      "  (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
      "  (to_k): Linear(in_features=768, out_features=640, bias=False)\n",
      "  (to_v): Linear(in_features=768, out_features=640, bias=False)\n",
      "  (to_out): Sequential(\n",
      "    (0): Linear(in_features=640, out_features=640, bias=True)\n",
      "    (1): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      ")\n",
      "Module: Linear(in_features=640, out_features=640, bias=False)\n",
      "Module: Linear(in_features=768, out_features=640, bias=False)\n",
      "Module: Linear(in_features=768, out_features=640, bias=False)\n",
      "Module: Sequential(\n",
      "  (0): Linear(in_features=640, out_features=640, bias=True)\n",
      "  (1): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "Module: Linear(in_features=640, out_features=640, bias=True)\n",
      "Module: Dropout(p=0.0, inplace=False)\n",
      "Module: LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
      "Module: LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
      "Module: LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
      "Module: Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
      "Module: Upsample(\n",
      "  (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")\n",
      "Module: Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "Module: TimestepEmbedSequential(\n",
      "  (0): ResBlock(\n",
      "    (in_layers): Sequential(\n",
      "      (0): GroupNorm32(32, 960, eps=1e-05, affine=True)\n",
      "      (1): SiLU()\n",
      "      (2): Conv2d(960, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (h_upd): Identity()\n",
      "    (x_upd): Identity()\n",
      "    (emb_layers): Sequential(\n",
      "      (0): SiLU()\n",
      "      (1): Linear(in_features=1280, out_features=320, bias=True)\n",
      "    )\n",
      "    (out_layers): Sequential(\n",
      "      (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
      "      (1): SiLU()\n",
      "      (2): Dropout(p=0, inplace=False)\n",
      "      (3): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (skip_connection): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (1): SpatialTransformer(\n",
      "    (norm): GroupNorm(32, 320, eps=1e-06, affine=True)\n",
      "    (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (transformer_blocks): ModuleList(\n",
      "      (0): BasicTransformerBlock(\n",
      "        (attn1): CrossAttention(\n",
      "          (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
      "          (to_k): Linear(in_features=320, out_features=320, bias=False)\n",
      "          (to_v): Linear(in_features=320, out_features=320, bias=False)\n",
      "          (to_out): Sequential(\n",
      "            (0): Linear(in_features=320, out_features=320, bias=True)\n",
      "            (1): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (ff): FeedForward(\n",
      "          (net): Sequential(\n",
      "            (0): GEGLU(\n",
      "              (proj): Linear(in_features=320, out_features=2560, bias=True)\n",
      "            )\n",
      "            (1): Dropout(p=0.0, inplace=False)\n",
      "            (2): Linear(in_features=1280, out_features=320, bias=True)\n",
      "          )\n",
      "        )\n",
      "        (attn2): CrossAttention(\n",
      "          (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
      "          (to_k): Linear(in_features=768, out_features=320, bias=False)\n",
      "          (to_v): Linear(in_features=768, out_features=320, bias=False)\n",
      "          (to_out): Sequential(\n",
      "            (0): Linear(in_features=320, out_features=320, bias=True)\n",
      "            (1): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n",
      "Module: ResBlock(\n",
      "  (in_layers): Sequential(\n",
      "    (0): GroupNorm32(32, 960, eps=1e-05, affine=True)\n",
      "    (1): SiLU()\n",
      "    (2): Conv2d(960, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (h_upd): Identity()\n",
      "  (x_upd): Identity()\n",
      "  (emb_layers): Sequential(\n",
      "    (0): SiLU()\n",
      "    (1): Linear(in_features=1280, out_features=320, bias=True)\n",
      "  )\n",
      "  (out_layers): Sequential(\n",
      "    (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
      "    (1): SiLU()\n",
      "    (2): Dropout(p=0, inplace=False)\n",
      "    (3): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (skip_connection): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1))\n",
      ")\n",
      "Module: Sequential(\n",
      "  (0): GroupNorm32(32, 960, eps=1e-05, affine=True)\n",
      "  (1): SiLU()\n",
      "  (2): Conv2d(960, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")\n",
      "Module: GroupNorm32(32, 960, eps=1e-05, affine=True)\n",
      "Module: SiLU()\n",
      "Module: Conv2d(960, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "Module: Identity()\n",
      "Module: Sequential(\n",
      "  (0): SiLU()\n",
      "  (1): Linear(in_features=1280, out_features=320, bias=True)\n",
      ")\n",
      "Module: SiLU()\n",
      "Module: Linear(in_features=1280, out_features=320, bias=True)\n",
      "Module: Sequential(\n",
      "  (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
      "  (1): SiLU()\n",
      "  (2): Dropout(p=0, inplace=False)\n",
      "  (3): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")\n",
      "Module: GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
      "Module: SiLU()\n",
      "Module: Dropout(p=0, inplace=False)\n",
      "Module: Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "Module: Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1))\n",
      "Module: SpatialTransformer(\n",
      "  (norm): GroupNorm(32, 320, eps=1e-06, affine=True)\n",
      "  (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (transformer_blocks): ModuleList(\n",
      "    (0): BasicTransformerBlock(\n",
      "      (attn1): CrossAttention(\n",
      "        (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
      "        (to_k): Linear(in_features=320, out_features=320, bias=False)\n",
      "        (to_v): Linear(in_features=320, out_features=320, bias=False)\n",
      "        (to_out): Sequential(\n",
      "          (0): Linear(in_features=320, out_features=320, bias=True)\n",
      "          (1): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (net): Sequential(\n",
      "          (0): GEGLU(\n",
      "            (proj): Linear(in_features=320, out_features=2560, bias=True)\n",
      "          )\n",
      "          (1): Dropout(p=0.0, inplace=False)\n",
      "          (2): Linear(in_features=1280, out_features=320, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (attn2): CrossAttention(\n",
      "        (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
      "        (to_k): Linear(in_features=768, out_features=320, bias=False)\n",
      "        (to_v): Linear(in_features=768, out_features=320, bias=False)\n",
      "        (to_out): Sequential(\n",
      "          (0): Linear(in_features=320, out_features=320, bias=True)\n",
      "          (1): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "      (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
      ")\n",
      "Module: GroupNorm(32, 320, eps=1e-06, affine=True)\n",
      "Module: Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
      "Module: ModuleList(\n",
      "  (0): BasicTransformerBlock(\n",
      "    (attn1): CrossAttention(\n",
      "      (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
      "      (to_k): Linear(in_features=320, out_features=320, bias=False)\n",
      "      (to_v): Linear(in_features=320, out_features=320, bias=False)\n",
      "      (to_out): Sequential(\n",
      "        (0): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (1): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (ff): FeedForward(\n",
      "      (net): Sequential(\n",
      "        (0): GEGLU(\n",
      "          (proj): Linear(in_features=320, out_features=2560, bias=True)\n",
      "        )\n",
      "        (1): Dropout(p=0.0, inplace=False)\n",
      "        (2): Linear(in_features=1280, out_features=320, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (attn2): CrossAttention(\n",
      "      (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
      "      (to_k): Linear(in_features=768, out_features=320, bias=False)\n",
      "      (to_v): Linear(in_features=768, out_features=320, bias=False)\n",
      "      (to_out): Sequential(\n",
      "        (0): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (1): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "    (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "    (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      ")\n",
      "Module: BasicTransformerBlock(\n",
      "  (attn1): CrossAttention(\n",
      "    (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
      "    (to_k): Linear(in_features=320, out_features=320, bias=False)\n",
      "    (to_v): Linear(in_features=320, out_features=320, bias=False)\n",
      "    (to_out): Sequential(\n",
      "      (0): Linear(in_features=320, out_features=320, bias=True)\n",
      "      (1): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (ff): FeedForward(\n",
      "    (net): Sequential(\n",
      "      (0): GEGLU(\n",
      "        (proj): Linear(in_features=320, out_features=2560, bias=True)\n",
      "      )\n",
      "      (1): Dropout(p=0.0, inplace=False)\n",
      "      (2): Linear(in_features=1280, out_features=320, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (attn2): CrossAttention(\n",
      "    (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
      "    (to_k): Linear(in_features=768, out_features=320, bias=False)\n",
      "    (to_v): Linear(in_features=768, out_features=320, bias=False)\n",
      "    (to_out): Sequential(\n",
      "      (0): Linear(in_features=320, out_features=320, bias=True)\n",
      "      (1): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "  (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "  (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      ")\n",
      "Module: CrossAttention(\n",
      "  (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
      "  (to_k): Linear(in_features=320, out_features=320, bias=False)\n",
      "  (to_v): Linear(in_features=320, out_features=320, bias=False)\n",
      "  (to_out): Sequential(\n",
      "    (0): Linear(in_features=320, out_features=320, bias=True)\n",
      "    (1): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      ")\n",
      "Module: Linear(in_features=320, out_features=320, bias=False)\n",
      "Module: Linear(in_features=320, out_features=320, bias=False)\n",
      "Module: Linear(in_features=320, out_features=320, bias=False)\n",
      "Module: Sequential(\n",
      "  (0): Linear(in_features=320, out_features=320, bias=True)\n",
      "  (1): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "Module: Linear(in_features=320, out_features=320, bias=True)\n",
      "Module: Dropout(p=0.0, inplace=False)\n",
      "Module: FeedForward(\n",
      "  (net): Sequential(\n",
      "    (0): GEGLU(\n",
      "      (proj): Linear(in_features=320, out_features=2560, bias=True)\n",
      "    )\n",
      "    (1): Dropout(p=0.0, inplace=False)\n",
      "    (2): Linear(in_features=1280, out_features=320, bias=True)\n",
      "  )\n",
      ")\n",
      "Module: Sequential(\n",
      "  (0): GEGLU(\n",
      "    (proj): Linear(in_features=320, out_features=2560, bias=True)\n",
      "  )\n",
      "  (1): Dropout(p=0.0, inplace=False)\n",
      "  (2): Linear(in_features=1280, out_features=320, bias=True)\n",
      ")\n",
      "Module: GEGLU(\n",
      "  (proj): Linear(in_features=320, out_features=2560, bias=True)\n",
      ")\n",
      "Module: Linear(in_features=320, out_features=2560, bias=True)\n",
      "Module: Dropout(p=0.0, inplace=False)\n",
      "Module: Linear(in_features=1280, out_features=320, bias=True)\n",
      "Module: CrossAttention(\n",
      "  (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
      "  (to_k): Linear(in_features=768, out_features=320, bias=False)\n",
      "  (to_v): Linear(in_features=768, out_features=320, bias=False)\n",
      "  (to_out): Sequential(\n",
      "    (0): Linear(in_features=320, out_features=320, bias=True)\n",
      "    (1): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      ")\n",
      "Module: Linear(in_features=320, out_features=320, bias=False)\n",
      "Module: Linear(in_features=768, out_features=320, bias=False)\n",
      "Module: Linear(in_features=768, out_features=320, bias=False)\n",
      "Module: Sequential(\n",
      "  (0): Linear(in_features=320, out_features=320, bias=True)\n",
      "  (1): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "Module: Linear(in_features=320, out_features=320, bias=True)\n",
      "Module: Dropout(p=0.0, inplace=False)\n",
      "Module: LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "Module: LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "Module: LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "Module: Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
      "Module: TimestepEmbedSequential(\n",
      "  (0): ResBlock(\n",
      "    (in_layers): Sequential(\n",
      "      (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
      "      (1): SiLU()\n",
      "      (2): Conv2d(640, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (h_upd): Identity()\n",
      "    (x_upd): Identity()\n",
      "    (emb_layers): Sequential(\n",
      "      (0): SiLU()\n",
      "      (1): Linear(in_features=1280, out_features=320, bias=True)\n",
      "    )\n",
      "    (out_layers): Sequential(\n",
      "      (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
      "      (1): SiLU()\n",
      "      (2): Dropout(p=0, inplace=False)\n",
      "      (3): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (skip_connection): Conv2d(640, 320, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (1): SpatialTransformer(\n",
      "    (norm): GroupNorm(32, 320, eps=1e-06, affine=True)\n",
      "    (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (transformer_blocks): ModuleList(\n",
      "      (0): BasicTransformerBlock(\n",
      "        (attn1): CrossAttention(\n",
      "          (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
      "          (to_k): Linear(in_features=320, out_features=320, bias=False)\n",
      "          (to_v): Linear(in_features=320, out_features=320, bias=False)\n",
      "          (to_out): Sequential(\n",
      "            (0): Linear(in_features=320, out_features=320, bias=True)\n",
      "            (1): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (ff): FeedForward(\n",
      "          (net): Sequential(\n",
      "            (0): GEGLU(\n",
      "              (proj): Linear(in_features=320, out_features=2560, bias=True)\n",
      "            )\n",
      "            (1): Dropout(p=0.0, inplace=False)\n",
      "            (2): Linear(in_features=1280, out_features=320, bias=True)\n",
      "          )\n",
      "        )\n",
      "        (attn2): CrossAttention(\n",
      "          (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
      "          (to_k): Linear(in_features=768, out_features=320, bias=False)\n",
      "          (to_v): Linear(in_features=768, out_features=320, bias=False)\n",
      "          (to_out): Sequential(\n",
      "            (0): Linear(in_features=320, out_features=320, bias=True)\n",
      "            (1): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n",
      "Module: ResBlock(\n",
      "  (in_layers): Sequential(\n",
      "    (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
      "    (1): SiLU()\n",
      "    (2): Conv2d(640, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (h_upd): Identity()\n",
      "  (x_upd): Identity()\n",
      "  (emb_layers): Sequential(\n",
      "    (0): SiLU()\n",
      "    (1): Linear(in_features=1280, out_features=320, bias=True)\n",
      "  )\n",
      "  (out_layers): Sequential(\n",
      "    (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
      "    (1): SiLU()\n",
      "    (2): Dropout(p=0, inplace=False)\n",
      "    (3): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (skip_connection): Conv2d(640, 320, kernel_size=(1, 1), stride=(1, 1))\n",
      ")\n",
      "Module: Sequential(\n",
      "  (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
      "  (1): SiLU()\n",
      "  (2): Conv2d(640, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")\n",
      "Module: GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
      "Module: SiLU()\n",
      "Module: Conv2d(640, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "Module: Identity()\n",
      "Module: Sequential(\n",
      "  (0): SiLU()\n",
      "  (1): Linear(in_features=1280, out_features=320, bias=True)\n",
      ")\n",
      "Module: SiLU()\n",
      "Module: Linear(in_features=1280, out_features=320, bias=True)\n",
      "Module: Sequential(\n",
      "  (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
      "  (1): SiLU()\n",
      "  (2): Dropout(p=0, inplace=False)\n",
      "  (3): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")\n",
      "Module: GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
      "Module: SiLU()\n",
      "Module: Dropout(p=0, inplace=False)\n",
      "Module: Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "Module: Conv2d(640, 320, kernel_size=(1, 1), stride=(1, 1))\n",
      "Module: SpatialTransformer(\n",
      "  (norm): GroupNorm(32, 320, eps=1e-06, affine=True)\n",
      "  (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (transformer_blocks): ModuleList(\n",
      "    (0): BasicTransformerBlock(\n",
      "      (attn1): CrossAttention(\n",
      "        (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
      "        (to_k): Linear(in_features=320, out_features=320, bias=False)\n",
      "        (to_v): Linear(in_features=320, out_features=320, bias=False)\n",
      "        (to_out): Sequential(\n",
      "          (0): Linear(in_features=320, out_features=320, bias=True)\n",
      "          (1): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (net): Sequential(\n",
      "          (0): GEGLU(\n",
      "            (proj): Linear(in_features=320, out_features=2560, bias=True)\n",
      "          )\n",
      "          (1): Dropout(p=0.0, inplace=False)\n",
      "          (2): Linear(in_features=1280, out_features=320, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (attn2): CrossAttention(\n",
      "        (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
      "        (to_k): Linear(in_features=768, out_features=320, bias=False)\n",
      "        (to_v): Linear(in_features=768, out_features=320, bias=False)\n",
      "        (to_out): Sequential(\n",
      "          (0): Linear(in_features=320, out_features=320, bias=True)\n",
      "          (1): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "      (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
      ")\n",
      "Module: GroupNorm(32, 320, eps=1e-06, affine=True)\n",
      "Module: Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
      "Module: ModuleList(\n",
      "  (0): BasicTransformerBlock(\n",
      "    (attn1): CrossAttention(\n",
      "      (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
      "      (to_k): Linear(in_features=320, out_features=320, bias=False)\n",
      "      (to_v): Linear(in_features=320, out_features=320, bias=False)\n",
      "      (to_out): Sequential(\n",
      "        (0): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (1): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (ff): FeedForward(\n",
      "      (net): Sequential(\n",
      "        (0): GEGLU(\n",
      "          (proj): Linear(in_features=320, out_features=2560, bias=True)\n",
      "        )\n",
      "        (1): Dropout(p=0.0, inplace=False)\n",
      "        (2): Linear(in_features=1280, out_features=320, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (attn2): CrossAttention(\n",
      "      (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
      "      (to_k): Linear(in_features=768, out_features=320, bias=False)\n",
      "      (to_v): Linear(in_features=768, out_features=320, bias=False)\n",
      "      (to_out): Sequential(\n",
      "        (0): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (1): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "    (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "    (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      ")\n",
      "Module: BasicTransformerBlock(\n",
      "  (attn1): CrossAttention(\n",
      "    (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
      "    (to_k): Linear(in_features=320, out_features=320, bias=False)\n",
      "    (to_v): Linear(in_features=320, out_features=320, bias=False)\n",
      "    (to_out): Sequential(\n",
      "      (0): Linear(in_features=320, out_features=320, bias=True)\n",
      "      (1): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (ff): FeedForward(\n",
      "    (net): Sequential(\n",
      "      (0): GEGLU(\n",
      "        (proj): Linear(in_features=320, out_features=2560, bias=True)\n",
      "      )\n",
      "      (1): Dropout(p=0.0, inplace=False)\n",
      "      (2): Linear(in_features=1280, out_features=320, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (attn2): CrossAttention(\n",
      "    (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
      "    (to_k): Linear(in_features=768, out_features=320, bias=False)\n",
      "    (to_v): Linear(in_features=768, out_features=320, bias=False)\n",
      "    (to_out): Sequential(\n",
      "      (0): Linear(in_features=320, out_features=320, bias=True)\n",
      "      (1): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "  (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "  (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      ")\n",
      "Module: CrossAttention(\n",
      "  (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
      "  (to_k): Linear(in_features=320, out_features=320, bias=False)\n",
      "  (to_v): Linear(in_features=320, out_features=320, bias=False)\n",
      "  (to_out): Sequential(\n",
      "    (0): Linear(in_features=320, out_features=320, bias=True)\n",
      "    (1): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      ")\n",
      "Module: Linear(in_features=320, out_features=320, bias=False)\n",
      "Module: Linear(in_features=320, out_features=320, bias=False)\n",
      "Module: Linear(in_features=320, out_features=320, bias=False)\n",
      "Module: Sequential(\n",
      "  (0): Linear(in_features=320, out_features=320, bias=True)\n",
      "  (1): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "Module: Linear(in_features=320, out_features=320, bias=True)\n",
      "Module: Dropout(p=0.0, inplace=False)\n",
      "Module: FeedForward(\n",
      "  (net): Sequential(\n",
      "    (0): GEGLU(\n",
      "      (proj): Linear(in_features=320, out_features=2560, bias=True)\n",
      "    )\n",
      "    (1): Dropout(p=0.0, inplace=False)\n",
      "    (2): Linear(in_features=1280, out_features=320, bias=True)\n",
      "  )\n",
      ")\n",
      "Module: Sequential(\n",
      "  (0): GEGLU(\n",
      "    (proj): Linear(in_features=320, out_features=2560, bias=True)\n",
      "  )\n",
      "  (1): Dropout(p=0.0, inplace=False)\n",
      "  (2): Linear(in_features=1280, out_features=320, bias=True)\n",
      ")\n",
      "Module: GEGLU(\n",
      "  (proj): Linear(in_features=320, out_features=2560, bias=True)\n",
      ")\n",
      "Module: Linear(in_features=320, out_features=2560, bias=True)\n",
      "Module: Dropout(p=0.0, inplace=False)\n",
      "Module: Linear(in_features=1280, out_features=320, bias=True)\n",
      "Module: CrossAttention(\n",
      "  (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
      "  (to_k): Linear(in_features=768, out_features=320, bias=False)\n",
      "  (to_v): Linear(in_features=768, out_features=320, bias=False)\n",
      "  (to_out): Sequential(\n",
      "    (0): Linear(in_features=320, out_features=320, bias=True)\n",
      "    (1): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      ")\n",
      "Module: Linear(in_features=320, out_features=320, bias=False)\n",
      "Module: Linear(in_features=768, out_features=320, bias=False)\n",
      "Module: Linear(in_features=768, out_features=320, bias=False)\n",
      "Module: Sequential(\n",
      "  (0): Linear(in_features=320, out_features=320, bias=True)\n",
      "  (1): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "Module: Linear(in_features=320, out_features=320, bias=True)\n",
      "Module: Dropout(p=0.0, inplace=False)\n",
      "Module: LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "Module: LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "Module: LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "Module: Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
      "Module: TimestepEmbedSequential(\n",
      "  (0): ResBlock(\n",
      "    (in_layers): Sequential(\n",
      "      (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
      "      (1): SiLU()\n",
      "      (2): Conv2d(640, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (h_upd): Identity()\n",
      "    (x_upd): Identity()\n",
      "    (emb_layers): Sequential(\n",
      "      (0): SiLU()\n",
      "      (1): Linear(in_features=1280, out_features=320, bias=True)\n",
      "    )\n",
      "    (out_layers): Sequential(\n",
      "      (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
      "      (1): SiLU()\n",
      "      (2): Dropout(p=0, inplace=False)\n",
      "      (3): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (skip_connection): Conv2d(640, 320, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (1): SpatialTransformer(\n",
      "    (norm): GroupNorm(32, 320, eps=1e-06, affine=True)\n",
      "    (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (transformer_blocks): ModuleList(\n",
      "      (0): BasicTransformerBlock(\n",
      "        (attn1): CrossAttention(\n",
      "          (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
      "          (to_k): Linear(in_features=320, out_features=320, bias=False)\n",
      "          (to_v): Linear(in_features=320, out_features=320, bias=False)\n",
      "          (to_out): Sequential(\n",
      "            (0): Linear(in_features=320, out_features=320, bias=True)\n",
      "            (1): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (ff): FeedForward(\n",
      "          (net): Sequential(\n",
      "            (0): GEGLU(\n",
      "              (proj): Linear(in_features=320, out_features=2560, bias=True)\n",
      "            )\n",
      "            (1): Dropout(p=0.0, inplace=False)\n",
      "            (2): Linear(in_features=1280, out_features=320, bias=True)\n",
      "          )\n",
      "        )\n",
      "        (attn2): CrossAttention(\n",
      "          (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
      "          (to_k): Linear(in_features=768, out_features=320, bias=False)\n",
      "          (to_v): Linear(in_features=768, out_features=320, bias=False)\n",
      "          (to_out): Sequential(\n",
      "            (0): Linear(in_features=320, out_features=320, bias=True)\n",
      "            (1): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n",
      "Module: ResBlock(\n",
      "  (in_layers): Sequential(\n",
      "    (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
      "    (1): SiLU()\n",
      "    (2): Conv2d(640, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (h_upd): Identity()\n",
      "  (x_upd): Identity()\n",
      "  (emb_layers): Sequential(\n",
      "    (0): SiLU()\n",
      "    (1): Linear(in_features=1280, out_features=320, bias=True)\n",
      "  )\n",
      "  (out_layers): Sequential(\n",
      "    (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
      "    (1): SiLU()\n",
      "    (2): Dropout(p=0, inplace=False)\n",
      "    (3): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (skip_connection): Conv2d(640, 320, kernel_size=(1, 1), stride=(1, 1))\n",
      ")\n",
      "Module: Sequential(\n",
      "  (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
      "  (1): SiLU()\n",
      "  (2): Conv2d(640, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")\n",
      "Module: GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
      "Module: SiLU()\n",
      "Module: Conv2d(640, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "Module: Identity()\n",
      "Module: Sequential(\n",
      "  (0): SiLU()\n",
      "  (1): Linear(in_features=1280, out_features=320, bias=True)\n",
      ")\n",
      "Module: SiLU()\n",
      "Module: Linear(in_features=1280, out_features=320, bias=True)\n",
      "Module: Sequential(\n",
      "  (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
      "  (1): SiLU()\n",
      "  (2): Dropout(p=0, inplace=False)\n",
      "  (3): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")\n",
      "Module: GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
      "Module: SiLU()\n",
      "Module: Dropout(p=0, inplace=False)\n",
      "Module: Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "Module: Conv2d(640, 320, kernel_size=(1, 1), stride=(1, 1))\n",
      "Module: SpatialTransformer(\n",
      "  (norm): GroupNorm(32, 320, eps=1e-06, affine=True)\n",
      "  (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (transformer_blocks): ModuleList(\n",
      "    (0): BasicTransformerBlock(\n",
      "      (attn1): CrossAttention(\n",
      "        (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
      "        (to_k): Linear(in_features=320, out_features=320, bias=False)\n",
      "        (to_v): Linear(in_features=320, out_features=320, bias=False)\n",
      "        (to_out): Sequential(\n",
      "          (0): Linear(in_features=320, out_features=320, bias=True)\n",
      "          (1): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (net): Sequential(\n",
      "          (0): GEGLU(\n",
      "            (proj): Linear(in_features=320, out_features=2560, bias=True)\n",
      "          )\n",
      "          (1): Dropout(p=0.0, inplace=False)\n",
      "          (2): Linear(in_features=1280, out_features=320, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (attn2): CrossAttention(\n",
      "        (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
      "        (to_k): Linear(in_features=768, out_features=320, bias=False)\n",
      "        (to_v): Linear(in_features=768, out_features=320, bias=False)\n",
      "        (to_out): Sequential(\n",
      "          (0): Linear(in_features=320, out_features=320, bias=True)\n",
      "          (1): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "      (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
      ")\n",
      "Module: GroupNorm(32, 320, eps=1e-06, affine=True)\n",
      "Module: Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
      "Module: ModuleList(\n",
      "  (0): BasicTransformerBlock(\n",
      "    (attn1): CrossAttention(\n",
      "      (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
      "      (to_k): Linear(in_features=320, out_features=320, bias=False)\n",
      "      (to_v): Linear(in_features=320, out_features=320, bias=False)\n",
      "      (to_out): Sequential(\n",
      "        (0): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (1): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (ff): FeedForward(\n",
      "      (net): Sequential(\n",
      "        (0): GEGLU(\n",
      "          (proj): Linear(in_features=320, out_features=2560, bias=True)\n",
      "        )\n",
      "        (1): Dropout(p=0.0, inplace=False)\n",
      "        (2): Linear(in_features=1280, out_features=320, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (attn2): CrossAttention(\n",
      "      (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
      "      (to_k): Linear(in_features=768, out_features=320, bias=False)\n",
      "      (to_v): Linear(in_features=768, out_features=320, bias=False)\n",
      "      (to_out): Sequential(\n",
      "        (0): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (1): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "    (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "    (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      ")\n",
      "Module: BasicTransformerBlock(\n",
      "  (attn1): CrossAttention(\n",
      "    (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
      "    (to_k): Linear(in_features=320, out_features=320, bias=False)\n",
      "    (to_v): Linear(in_features=320, out_features=320, bias=False)\n",
      "    (to_out): Sequential(\n",
      "      (0): Linear(in_features=320, out_features=320, bias=True)\n",
      "      (1): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (ff): FeedForward(\n",
      "    (net): Sequential(\n",
      "      (0): GEGLU(\n",
      "        (proj): Linear(in_features=320, out_features=2560, bias=True)\n",
      "      )\n",
      "      (1): Dropout(p=0.0, inplace=False)\n",
      "      (2): Linear(in_features=1280, out_features=320, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (attn2): CrossAttention(\n",
      "    (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
      "    (to_k): Linear(in_features=768, out_features=320, bias=False)\n",
      "    (to_v): Linear(in_features=768, out_features=320, bias=False)\n",
      "    (to_out): Sequential(\n",
      "      (0): Linear(in_features=320, out_features=320, bias=True)\n",
      "      (1): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "  (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "  (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      ")\n",
      "Module: CrossAttention(\n",
      "  (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
      "  (to_k): Linear(in_features=320, out_features=320, bias=False)\n",
      "  (to_v): Linear(in_features=320, out_features=320, bias=False)\n",
      "  (to_out): Sequential(\n",
      "    (0): Linear(in_features=320, out_features=320, bias=True)\n",
      "    (1): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      ")\n",
      "Module: Linear(in_features=320, out_features=320, bias=False)\n",
      "Module: Linear(in_features=320, out_features=320, bias=False)\n",
      "Module: Linear(in_features=320, out_features=320, bias=False)\n",
      "Module: Sequential(\n",
      "  (0): Linear(in_features=320, out_features=320, bias=True)\n",
      "  (1): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "Module: Linear(in_features=320, out_features=320, bias=True)\n",
      "Module: Dropout(p=0.0, inplace=False)\n",
      "Module: FeedForward(\n",
      "  (net): Sequential(\n",
      "    (0): GEGLU(\n",
      "      (proj): Linear(in_features=320, out_features=2560, bias=True)\n",
      "    )\n",
      "    (1): Dropout(p=0.0, inplace=False)\n",
      "    (2): Linear(in_features=1280, out_features=320, bias=True)\n",
      "  )\n",
      ")\n",
      "Module: Sequential(\n",
      "  (0): GEGLU(\n",
      "    (proj): Linear(in_features=320, out_features=2560, bias=True)\n",
      "  )\n",
      "  (1): Dropout(p=0.0, inplace=False)\n",
      "  (2): Linear(in_features=1280, out_features=320, bias=True)\n",
      ")\n",
      "Module: GEGLU(\n",
      "  (proj): Linear(in_features=320, out_features=2560, bias=True)\n",
      ")\n",
      "Module: Linear(in_features=320, out_features=2560, bias=True)\n",
      "Module: Dropout(p=0.0, inplace=False)\n",
      "Module: Linear(in_features=1280, out_features=320, bias=True)\n",
      "Module: CrossAttention(\n",
      "  (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
      "  (to_k): Linear(in_features=768, out_features=320, bias=False)\n",
      "  (to_v): Linear(in_features=768, out_features=320, bias=False)\n",
      "  (to_out): Sequential(\n",
      "    (0): Linear(in_features=320, out_features=320, bias=True)\n",
      "    (1): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      ")\n",
      "Module: Linear(in_features=320, out_features=320, bias=False)\n",
      "Module: Linear(in_features=768, out_features=320, bias=False)\n",
      "Module: Linear(in_features=768, out_features=320, bias=False)\n",
      "Module: Sequential(\n",
      "  (0): Linear(in_features=320, out_features=320, bias=True)\n",
      "  (1): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "Module: Linear(in_features=320, out_features=320, bias=True)\n",
      "Module: Dropout(p=0.0, inplace=False)\n",
      "Module: LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "Module: LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "Module: LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "Module: Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
      "Module: Sequential(\n",
      "  (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
      "  (1): SiLU()\n",
      "  (2): Conv2d(320, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")\n",
      "Module: GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
      "Module: SiLU()\n",
      "Module: Conv2d(320, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n"
     ]
    }
   ],
   "source": [
    "for m in env.generator.model.model.diffusion_model.modules():\n",
    "    print(f\"Module: {m}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "853af900-ec6d-41b8-8f5a-7ce19d4f543b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UNetModel(\n",
       "  (time_embed): Sequential(\n",
       "    (0): Linear(in_features=320, out_features=1280, bias=True)\n",
       "    (1): SiLU()\n",
       "    (2): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "  )\n",
       "  (input_blocks): ModuleList(\n",
       "    (0): TimestepEmbedSequential(\n",
       "      (0): Conv2d(8, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (1-2): 2 x TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=1280, out_features=320, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0, inplace=False)\n",
       "          (3): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Identity()\n",
       "      )\n",
       "      (1): SpatialTransformer(\n",
       "        (norm): GroupNorm(32, 320, eps=1e-06, affine=True)\n",
       "        (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (transformer_blocks): ModuleList(\n",
       "          (0): BasicTransformerBlock(\n",
       "            (attn1): CrossAttention(\n",
       "              (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "              (to_k): Linear(in_features=320, out_features=320, bias=False)\n",
       "              (to_v): Linear(in_features=320, out_features=320, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (ff): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): GEGLU(\n",
       "                  (proj): Linear(in_features=320, out_features=2560, bias=True)\n",
       "                )\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "                (2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (attn2): CrossAttention(\n",
       "              (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "              (to_k): Linear(in_features=768, out_features=320, bias=False)\n",
       "              (to_v): Linear(in_features=768, out_features=320, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (3): TimestepEmbedSequential(\n",
       "      (0): Downsample(\n",
       "        (op): Conv2d(320, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (4): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(320, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=1280, out_features=640, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0, inplace=False)\n",
       "          (3): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(320, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): SpatialTransformer(\n",
       "        (norm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
       "        (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (transformer_blocks): ModuleList(\n",
       "          (0): BasicTransformerBlock(\n",
       "            (attn1): CrossAttention(\n",
       "              (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "              (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
       "              (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (ff): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): GEGLU(\n",
       "                  (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
       "                )\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "                (2): Linear(in_features=2560, out_features=640, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (attn2): CrossAttention(\n",
       "              (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "              (to_k): Linear(in_features=768, out_features=640, bias=False)\n",
       "              (to_v): Linear(in_features=768, out_features=640, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (5): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=1280, out_features=640, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0, inplace=False)\n",
       "          (3): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Identity()\n",
       "      )\n",
       "      (1): SpatialTransformer(\n",
       "        (norm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
       "        (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (transformer_blocks): ModuleList(\n",
       "          (0): BasicTransformerBlock(\n",
       "            (attn1): CrossAttention(\n",
       "              (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "              (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
       "              (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (ff): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): GEGLU(\n",
       "                  (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
       "                )\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "                (2): Linear(in_features=2560, out_features=640, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (attn2): CrossAttention(\n",
       "              (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "              (to_k): Linear(in_features=768, out_features=640, bias=False)\n",
       "              (to_v): Linear(in_features=768, out_features=640, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (6): TimestepEmbedSequential(\n",
       "      (0): Downsample(\n",
       "        (op): Conv2d(640, 640, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (7): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(640, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0, inplace=False)\n",
       "          (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(640, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): SpatialTransformer(\n",
       "        (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
       "        (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (transformer_blocks): ModuleList(\n",
       "          (0): BasicTransformerBlock(\n",
       "            (attn1): CrossAttention(\n",
       "              (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "              (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "              (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (ff): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): GEGLU(\n",
       "                  (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
       "                )\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "                (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (attn2): CrossAttention(\n",
       "              (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "              (to_k): Linear(in_features=768, out_features=1280, bias=False)\n",
       "              (to_v): Linear(in_features=768, out_features=1280, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (8): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0, inplace=False)\n",
       "          (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Identity()\n",
       "      )\n",
       "      (1): SpatialTransformer(\n",
       "        (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
       "        (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (transformer_blocks): ModuleList(\n",
       "          (0): BasicTransformerBlock(\n",
       "            (attn1): CrossAttention(\n",
       "              (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "              (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "              (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (ff): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): GEGLU(\n",
       "                  (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
       "                )\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "                (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (attn2): CrossAttention(\n",
       "              (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "              (to_k): Linear(in_features=768, out_features=1280, bias=False)\n",
       "              (to_v): Linear(in_features=768, out_features=1280, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (9): TimestepEmbedSequential(\n",
       "      (0): Downsample(\n",
       "        (op): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (10-11): 2 x TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0, inplace=False)\n",
       "          (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Identity()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (middle_block): TimestepEmbedSequential(\n",
       "    (0): ResBlock(\n",
       "      (in_layers): Sequential(\n",
       "        (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "        (1): SiLU()\n",
       "        (2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (h_upd): Identity()\n",
       "      (x_upd): Identity()\n",
       "      (emb_layers): Sequential(\n",
       "        (0): SiLU()\n",
       "        (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "      )\n",
       "      (out_layers): Sequential(\n",
       "        (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "        (1): SiLU()\n",
       "        (2): Dropout(p=0, inplace=False)\n",
       "        (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (skip_connection): Identity()\n",
       "    )\n",
       "    (1): SpatialTransformer(\n",
       "      (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
       "      (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (transformer_blocks): ModuleList(\n",
       "        (0): BasicTransformerBlock(\n",
       "          (attn1): CrossAttention(\n",
       "            (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "            (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "            (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "            (to_out): Sequential(\n",
       "              (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "              (1): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (ff): FeedForward(\n",
       "            (net): Sequential(\n",
       "              (0): GEGLU(\n",
       "                (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
       "              )\n",
       "              (1): Dropout(p=0.0, inplace=False)\n",
       "              (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "            )\n",
       "          )\n",
       "          (attn2): CrossAttention(\n",
       "            (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "            (to_k): Linear(in_features=768, out_features=1280, bias=False)\n",
       "            (to_v): Linear(in_features=768, out_features=1280, bias=False)\n",
       "            (to_out): Sequential(\n",
       "              (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "              (1): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (2): ResBlock(\n",
       "      (in_layers): Sequential(\n",
       "        (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "        (1): SiLU()\n",
       "        (2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (h_upd): Identity()\n",
       "      (x_upd): Identity()\n",
       "      (emb_layers): Sequential(\n",
       "        (0): SiLU()\n",
       "        (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "      )\n",
       "      (out_layers): Sequential(\n",
       "        (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "        (1): SiLU()\n",
       "        (2): Dropout(p=0, inplace=False)\n",
       "        (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (skip_connection): Identity()\n",
       "    )\n",
       "  )\n",
       "  (output_blocks): ModuleList(\n",
       "    (0-1): 2 x TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 2560, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0, inplace=False)\n",
       "          (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (2): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 2560, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0, inplace=False)\n",
       "          (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): Upsample(\n",
       "        (conv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (3-4): 2 x TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 2560, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0, inplace=False)\n",
       "          (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): SpatialTransformer(\n",
       "        (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
       "        (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (transformer_blocks): ModuleList(\n",
       "          (0): BasicTransformerBlock(\n",
       "            (attn1): CrossAttention(\n",
       "              (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "              (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "              (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (ff): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): GEGLU(\n",
       "                  (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
       "                )\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "                (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (attn2): CrossAttention(\n",
       "              (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "              (to_k): Linear(in_features=768, out_features=1280, bias=False)\n",
       "              (to_v): Linear(in_features=768, out_features=1280, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (5): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 1920, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(1920, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0, inplace=False)\n",
       "          (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(1920, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): SpatialTransformer(\n",
       "        (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
       "        (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (transformer_blocks): ModuleList(\n",
       "          (0): BasicTransformerBlock(\n",
       "            (attn1): CrossAttention(\n",
       "              (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "              (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "              (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (ff): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): GEGLU(\n",
       "                  (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
       "                )\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "                (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (attn2): CrossAttention(\n",
       "              (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "              (to_k): Linear(in_features=768, out_features=1280, bias=False)\n",
       "              (to_v): Linear(in_features=768, out_features=1280, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (2): Upsample(\n",
       "        (conv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (6): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 1920, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(1920, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=1280, out_features=640, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0, inplace=False)\n",
       "          (3): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(1920, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): SpatialTransformer(\n",
       "        (norm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
       "        (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (transformer_blocks): ModuleList(\n",
       "          (0): BasicTransformerBlock(\n",
       "            (attn1): CrossAttention(\n",
       "              (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "              (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
       "              (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (ff): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): GEGLU(\n",
       "                  (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
       "                )\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "                (2): Linear(in_features=2560, out_features=640, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (attn2): CrossAttention(\n",
       "              (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "              (to_k): Linear(in_features=768, out_features=640, bias=False)\n",
       "              (to_v): Linear(in_features=768, out_features=640, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (7): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(1280, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=1280, out_features=640, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0, inplace=False)\n",
       "          (3): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(1280, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): SpatialTransformer(\n",
       "        (norm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
       "        (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (transformer_blocks): ModuleList(\n",
       "          (0): BasicTransformerBlock(\n",
       "            (attn1): CrossAttention(\n",
       "              (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "              (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
       "              (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (ff): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): GEGLU(\n",
       "                  (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
       "                )\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "                (2): Linear(in_features=2560, out_features=640, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (attn2): CrossAttention(\n",
       "              (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "              (to_k): Linear(in_features=768, out_features=640, bias=False)\n",
       "              (to_v): Linear(in_features=768, out_features=640, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (8): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 960, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(960, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=1280, out_features=640, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0, inplace=False)\n",
       "          (3): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(960, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): SpatialTransformer(\n",
       "        (norm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
       "        (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (transformer_blocks): ModuleList(\n",
       "          (0): BasicTransformerBlock(\n",
       "            (attn1): CrossAttention(\n",
       "              (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "              (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
       "              (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (ff): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): GEGLU(\n",
       "                  (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
       "                )\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "                (2): Linear(in_features=2560, out_features=640, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (attn2): CrossAttention(\n",
       "              (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "              (to_k): Linear(in_features=768, out_features=640, bias=False)\n",
       "              (to_v): Linear(in_features=768, out_features=640, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (2): Upsample(\n",
       "        (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (9): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 960, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(960, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=1280, out_features=320, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0, inplace=False)\n",
       "          (3): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): SpatialTransformer(\n",
       "        (norm): GroupNorm(32, 320, eps=1e-06, affine=True)\n",
       "        (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (transformer_blocks): ModuleList(\n",
       "          (0): BasicTransformerBlock(\n",
       "            (attn1): CrossAttention(\n",
       "              (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "              (to_k): Linear(in_features=320, out_features=320, bias=False)\n",
       "              (to_v): Linear(in_features=320, out_features=320, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (ff): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): GEGLU(\n",
       "                  (proj): Linear(in_features=320, out_features=2560, bias=True)\n",
       "                )\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "                (2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (attn2): CrossAttention(\n",
       "              (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "              (to_k): Linear(in_features=768, out_features=320, bias=False)\n",
       "              (to_v): Linear(in_features=768, out_features=320, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (10-11): 2 x TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(640, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=1280, out_features=320, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0, inplace=False)\n",
       "          (3): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(640, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): SpatialTransformer(\n",
       "        (norm): GroupNorm(32, 320, eps=1e-06, affine=True)\n",
       "        (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (transformer_blocks): ModuleList(\n",
       "          (0): BasicTransformerBlock(\n",
       "            (attn1): CrossAttention(\n",
       "              (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "              (to_k): Linear(in_features=320, out_features=320, bias=False)\n",
       "              (to_v): Linear(in_features=320, out_features=320, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (ff): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): GEGLU(\n",
       "                  (proj): Linear(in_features=320, out_features=2560, bias=True)\n",
       "                )\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "                (2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (attn2): CrossAttention(\n",
       "              (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "              (to_k): Linear(in_features=768, out_features=320, bias=False)\n",
       "              (to_v): Linear(in_features=768, out_features=320, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (out): Sequential(\n",
       "    (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
       "    (1): SiLU()\n",
       "    (2): Conv2d(320, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4fccbe1-b2a6-4846-b754-791a6d643c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:00, 97541.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "a = [1,2,3,4,5]\n",
    "import tqdm\n",
    "for b,c in tqdm.tqdm(zip(a,a)):\n",
    "    print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8827a71b-da42-4242-a672-70f7f95792ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
